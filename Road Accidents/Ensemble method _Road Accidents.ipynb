{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e6f393",
   "metadata": {},
   "source": [
    "# Ensemble (XGBoost + CatBoost + LightGBM) prediction for road accident "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7581d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/Users/gopeami/OneDrive - Vesuvius/Desktop/PhD13- 2025-2026/ML Practice/Kaggle Compettition/Road Accidents/train.csv')\n",
    "test_df = pd.read_csv('/C:/Users/gopeami/OneDrive - Vesuvius/Desktop/PhD13- 2025-2026/ML Practice/Kaggle Compettition/Road Accidents/test.csv')\n",
    "\n",
    "print(train_df.info())\n",
    "print(\"\\nMissing values in train:\", train_df.isnull().sum().sum())\n",
    "print(\"Missing values in test:\", test_df.isnull().sum().sum())\n",
    "\n",
    "# basic statistics\n",
    "print(train_df['accident_risk'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb6aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Basic interactions from your original features\n",
    "    df_copy['speed_curvature'] = df_copy['speed_limit'] * df_copy['curvature']\n",
    "    df_copy['lanes_speed'] = df_copy['num_lanes'] * df_copy['speed_limit']\n",
    "    \n",
    "    # Risk encodings\n",
    "    weather_risk = {'clear': 0, 'rainy': 1, 'foggy': 2}\n",
    "    lighting_risk = {'daylight': 0, 'dim': 1, 'night': 2}\n",
    "    time_risk = {'morning': 0, 'afternoon': 1, 'evening': 2, 'night': 3}\n",
    "    \n",
    "    df_copy['weather_risk'] = df_copy['weather'].map(weather_risk)\n",
    "    df_copy['lighting_risk'] = df_copy['lighting'].map(lighting_risk)\n",
    "    df_copy['time_risk'] = df_copy['time_of_day'].map(time_risk)\n",
    "    \n",
    "    # Combined risk score\n",
    "    df_copy['environment_risk'] = df_copy['weather_risk'] + df_copy['lighting_risk'] + df_copy['time_risk']\n",
    "    \n",
    "    # Advanced features\n",
    "    df_copy['complexity_score'] = (df_copy['curvature'] * df_copy['speed_limit'] * \n",
    "                                 df_copy['num_lanes']) / 100\n",
    "    \n",
    "    # Visibility risk (combination of lighting + weather)\n",
    "    lighting_scores = {'daylight': 0, 'dim': 2, 'night': 3}\n",
    "    weather_scores = {'clear': 0, 'rainy': 2, 'foggy': 3}\n",
    "    df_copy['visibility_risk'] = (df_copy['lighting'].map(lighting_scores) + \n",
    "                                df_copy['weather'].map(weather_scores))\n",
    "    \n",
    "    # Time risk amplification\n",
    "    time_scores = {'morning': 1, 'afternoon': 1.2, 'evening': 1.5, 'night': 2}\n",
    "    df_copy['time_amplifier'] = df_copy['time_of_day'].map(time_scores)\n",
    "    \n",
    "    # Road type encoding\n",
    "    road_scores = {'urban': 1, 'rural': 1.5, 'highway': 2}\n",
    "    df_copy['road_type_encoded'] = df_copy['road_type'].map(road_scores)\n",
    "    \n",
    "    # Combined risk score\n",
    "    df_copy['composite_risk'] = (\n",
    "        df_copy['complexity_score'] * \n",
    "        df_copy['visibility_risk'] * \n",
    "        df_copy['time_amplifier'] * \n",
    "        df_copy['road_type_encoded']\n",
    "    ) / 10\n",
    "    \n",
    "    # Peak hour flag\n",
    "    df_copy['peak_hour'] = ((df_copy['time_of_day'].isin(['morning', 'evening'])) & \n",
    "                           (df_copy['holiday'] == 'False')).astype(int)\n",
    "    \n",
    "    # Dangerous combinations\n",
    "    df_copy['high_risk_combo'] = (\n",
    "        (df_copy['weather'].isin(['foggy', 'rainy'])) &\n",
    "        (df_copy['lighting'].isin(['dim', 'night'])) &\n",
    "        (df_copy['curvature'] > 0.5)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "train_df = create_advanced_features(train_df)\n",
    "test_df = create_advanced_features(test_df)\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated features list with advanced features\n",
    "features_to_use = [\n",
    "    'road_type', 'num_lanes', 'curvature', 'speed_limit', 'lighting', \n",
    "    'weather', 'road_signs_present', 'public_road', 'time_of_day', \n",
    "    'holiday', 'school_season', 'num_reported_accidents',\n",
    "    'speed_curvature', 'lanes_speed', 'weather_risk', \n",
    "    'lighting_risk', 'time_risk', 'environment_risk',\n",
    "    'complexity_score', 'visibility_risk', 'time_amplifier',\n",
    "    'road_type_encoded', 'composite_risk', 'peak_hour', 'high_risk_combo'\n",
    "]\n",
    "\n",
    "X = train_df[features_to_use]\n",
    "y = train_df['accident_risk']\n",
    "X_test = test_df[features_to_use]\n",
    "\n",
    "# Identifying categorical features for CatBoost\n",
    "categorical_features = [\n",
    "    'road_type', 'lighting', 'weather', 'road_signs_present', \n",
    "    'public_road', 'time_of_day', 'holiday', 'school_season'\n",
    "]\n",
    "\n",
    "# Converting boolean columns to strings for proper handling\n",
    "for col in ['road_signs_present', 'public_road', 'holiday', 'school_season']:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "print(f\"Total features: {len(features_to_use)}\")\n",
    "print(f\"Categorical features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd88b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xgboost_features_simple(X, X_test=None):\n",
    "    \"\"\"Simpler version - converting everything to numeric\"\"\"\n",
    "    X_xgb = X.copy()\n",
    "    \n",
    "    if X_test is not None:\n",
    "        X_test_xgb = X_test.copy()\n",
    "    else:\n",
    "        X_test_xgb = None\n",
    "    \n",
    "    # Converting all categorical columns using label encoding\n",
    "    categorical_cols = ['road_type', 'lighting', 'weather', 'time_of_day', \n",
    "                       'road_signs_present', 'public_road', 'holiday', 'school_season']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_xgb[col] = le.fit_transform(X_xgb[col].astype(str))\n",
    "        if X_test is not None:\n",
    "            # Handling unseen labels in test set\n",
    "            unique_train = set(le.classes_)\n",
    "            X_test_xgb[col] = X_test_xgb[col].astype(str).apply(\n",
    "                lambda x: le.transform([x])[0] if x in unique_train else -1\n",
    "            )\n",
    "    \n",
    "    if X_test is not None:\n",
    "        return X_xgb, X_test_xgb\n",
    "    return X_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_val.shape[0]}\")\n",
    "\n",
    "# Preparing data for all models\n",
    "X_train_cat = X_train.copy()\n",
    "X_val_cat = X_val.copy()\n",
    "X_test_cat = X_test.copy()\n",
    "\n",
    "# Preparing XGBoost features (label encoded)\n",
    "X_train_xgb, X_val_xgb = prepare_xgboost_features_simple(X_train, X_val)\n",
    "X_test_xgb = prepare_xgboost_features_simple(X_test)\n",
    "\n",
    "# For LightGBM model\n",
    "X_train_lgb, X_val_lgb = prepare_xgboost_features_simple(X_train, X_val)\n",
    "X_test_lgb = prepare_xgboost_features_simple(X_test)\n",
    "\n",
    "# CatBoost model\n",
    "cat_model = CatBoostRegressor(\n",
    "    cat_features=categorical_features,\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    "    iterations=800,  \n",
    "    learning_rate=0.03,  \n",
    "    depth=8,  \n",
    "    l2_leaf_reg=3,  \n",
    "    random_strength=0.5, \n",
    "    bagging_temperature=0.8,  \n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=800,  \n",
    "    learning_rate=0.03,\n",
    "    max_depth=8, \n",
    "    subsample=0.85,  \n",
    "    colsample_bytree=0.8,\n",
    "    colsample_bylevel=0.8,  \n",
    "    reg_alpha=0.2,  \n",
    "    reg_lambda=0.3,  \n",
    "    gamma=0.1,  \n",
    "    eval_metric='rmse',\n",
    "    early_stopping_rounds=50,\n",
    "    verbosity=0  \n",
    ")\n",
    "\n",
    "# LightGBM model\n",
    "lgb_model = LGBMRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=800,  \n",
    "    learning_rate=0.03,  \n",
    "    max_depth=8,  \n",
    "    num_leaves=45,  \n",
    "    subsample=0.85,  \n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.2,  \n",
    "    reg_lambda=0.3,  \n",
    "    min_child_samples=25,  \n",
    "    min_child_weight=0.001, \n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "\n",
    "# Model training\n",
    "print(\"Training models...\")\n",
    "\n",
    "print(\"Training CatBoost...\", end=\" \")\n",
    "cat_model.fit(X_train_cat, y_train, eval_set=[(X_val_cat, y_val)], verbose=False)\n",
    "print(\"✓\")\n",
    "\n",
    "print(\"Training XGBoost...\", end=\" \")\n",
    "xgb_model.fit(X_train_xgb, y_train, eval_set=[(X_val_xgb, y_val)], verbose=False)\n",
    "print(\"✓\")\n",
    "\n",
    "print(\"Training LightGBM...\", end=\" \")\n",
    "lgb_model.fit(X_train_lgb, y_train)\n",
    "print(\"✓\")\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")\n",
    "\n",
    "# Predictions\n",
    "cat_val_pred = cat_model.predict(X_val_cat)\n",
    "xgb_val_pred = xgb_model.predict(X_val_xgb)\n",
    "lgb_val_pred = lgb_model.predict(X_val_lgb)\n",
    "\n",
    "cat_test_pred = cat_model.predict(X_test_cat)\n",
    "xgb_test_pred = xgb_model.predict(X_test_xgb)\n",
    "lgb_test_pred = lgb_model.predict(X_test_lgb)\n",
    "\n",
    "print(\"Predictions ready for ensemble!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"Creating stacking ensemble...\")\n",
    "\n",
    "# Getting predictions from all models\n",
    "cat_train_pred = cat_model.predict(X_train_cat)\n",
    "cat_val_pred = cat_model.predict(X_val_cat)\n",
    "cat_test_pred = cat_model.predict(X_test_cat)\n",
    "\n",
    "xgb_train_pred = xgb_model.predict(X_train_xgb)\n",
    "xgb_val_pred = xgb_model.predict(X_val_xgb)\n",
    "xgb_test_pred = xgb_model.predict(X_test_xgb)\n",
    "\n",
    "lgb_train_pred = lgb_model.predict(X_train_lgb)\n",
    "lgb_val_pred = lgb_model.predict(X_val_lgb)\n",
    "lgb_test_pred = lgb_model.predict(X_test_lgb)\n",
    "\n",
    "# Create stacking features (use all 3 models)\n",
    "level1_train = np.column_stack([cat_train_pred, xgb_train_pred, lgb_train_pred])\n",
    "level1_val = np.column_stack([cat_val_pred, xgb_val_pred, lgb_val_pred])\n",
    "level1_test = np.column_stack([cat_test_pred, xgb_test_pred, lgb_test_pred])\n",
    "\n",
    "print(f\"Stacking feature shapes:\")\n",
    "print(f\"Train: {level1_train.shape}\")\n",
    "print(f\"Val: {level1_val.shape}\") \n",
    "print(f\"Test: {level1_test.shape}\")\n",
    "\n",
    "# Train meta-model\n",
    "meta_model = Ridge(alpha=0.1)\n",
    "meta_model.fit(level1_train, y_train)\n",
    "\n",
    "# Make stacking predictions\n",
    "stacking_val_pred = meta_model.predict(level1_val)\n",
    "stacking_test_pred = meta_model.predict(level1_test)\n",
    "\n",
    "print(\"Stacking ensemble training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate individual model performances with multiple metrics\n",
    "cat_val_rmse = np.sqrt(mean_squared_error(y_val, cat_val_pred))\n",
    "xgb_val_rmse = np.sqrt(mean_squared_error(y_val, xgb_val_pred))\n",
    "lgb_val_rmse = np.sqrt(mean_squared_error(y_val, lgb_val_pred))\n",
    "stack_val_rmse = np.sqrt(mean_squared_error(y_val, stacking_val_pred))\n",
    "\n",
    "cat_mae = mean_absolute_error(y_val, cat_val_pred)\n",
    "xgb_mae = mean_absolute_error(y_val, xgb_val_pred)\n",
    "lgb_mae = mean_absolute_error(y_val, lgb_val_pred)\n",
    "\n",
    "# Combined score (RMSE + MAE)\n",
    "def combined_score(rmse, mae):\n",
    "    return 0.7 * rmse + 0.3 * mae  # Weight RMSE more heavily\n",
    "\n",
    "cat_score = combined_score(cat_val_rmse, cat_mae)\n",
    "xgb_score = combined_score(xgb_val_rmse, xgb_mae)\n",
    "lgb_score = combined_score(lgb_val_rmse, lgb_mae)\n",
    "stack_score = combined_score(stack_val_rmse, 0)\n",
    "\n",
    "# Performance-based weights with exponential decay (better models get much higher weight)\n",
    "models_scores = {\n",
    "    'CatBoost': cat_score,\n",
    "    'XGBoost': xgb_score,\n",
    "    'LightGBM': lgb_score,\n",
    "    'Stacking': stack_score\n",
    "}\n",
    "\n",
    "# Exponential weighting (emphasizes differences between models)\n",
    "weights = {}\n",
    "total_weight = 0\n",
    "for name, score in models_scores.items():\n",
    "    weights[name] = np.exp(-score * 5) \n",
    "    total_weight += weights[name]\n",
    "\n",
    "# Normalize weights\n",
    "for name in weights:\n",
    "    weights[name] /= total_weight\n",
    "\n",
    "print(\"\\nSmart Model Weights:\")\n",
    "for name, weight in weights.items():\n",
    "    print(f\"{name}: {weight:.3f}\")\n",
    "\n",
    "# Super ensemble with smart weighting\n",
    "super_ensemble_val = (\n",
    "    weights['CatBoost'] * cat_val_pred +\n",
    "    weights['XGBoost'] * xgb_val_pred +\n",
    "    weights['LightGBM'] * lgb_val_pred +\n",
    "    weights['Stacking'] * stacking_val_pred\n",
    ")\n",
    "\n",
    "super_ensemble_test = (\n",
    "    weights['CatBoost'] * cat_test_pred +\n",
    "    weights['XGBoost'] * xgb_test_pred +\n",
    "    weights['LightGBM'] * lgb_test_pred +\n",
    "    weights['Stacking'] * stacking_test_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_ensemble_val_rmse = np.sqrt(mean_squared_error(y_val, super_ensemble_val))\n",
    "super_ensemble_val_mae = mean_absolute_error(y_val, super_ensemble_val)\n",
    "\n",
    "print(f\"\\n=== SUPER ENSEMBLE PERFORMANCE ===\")\n",
    "print(f\"Super Ensemble RMSE: {super_ensemble_val_rmse:.4f}\")\n",
    "print(f\"Super Ensemble MAE: {super_ensemble_val_mae:.4f}\")\n",
    "\n",
    "# Individual model performance for comparison\n",
    "print(f\"\\nCatBoost RMSE: {cat_val_rmse:.4f}\")\n",
    "print(f\"XGBoost RMSE: {xgb_val_rmse:.4f}\")\n",
    "print(f\"LightGBM RMSE: {lgb_val_rmse:.4f}\")\n",
    "print(f\"Stacking RMSE: {stack_val_rmse:.4f}\")\n",
    "\n",
    "# Calculating improvement\n",
    "improvement = ((min(cat_val_rmse, xgb_val_rmse) - super_ensemble_val_rmse) / \n",
    "               min(cat_val_rmse, xgb_val_rmse) * 100)\n",
    "print(f\"Improvement over best single model: {improvement:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM importance\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "})\n",
    "lgb_importance['importance'] = lgb_importance['importance'] / lgb_importance['importance'].max()\n",
    "\n",
    "cat_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': cat_model.get_feature_importance()\n",
    "})\n",
    "cat_importance['importance'] = cat_importance['importance'] / cat_importance['importance'].max()\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns, \n",
    "    'importance': xgb_model.feature_importances_\n",
    "})\n",
    "xgb_importance['importance'] = xgb_importance['importance'] / xgb_importance['importance'].max()\n",
    "\n",
    "# Combining all three models\n",
    "combined_importance = pd.merge(\n",
    "    pd.merge(cat_importance, xgb_importance, on='feature', suffixes=('_cat', '_xgb')),\n",
    "    lgb_importance, on='feature'\n",
    ")\n",
    "combined_importance['importance_avg'] = (\n",
    "    combined_importance['importance_cat'] + \n",
    "    combined_importance['importance_xgb'] + \n",
    "    combined_importance['importance']\n",
    ") / 3\n",
    "combined_importance = combined_importance.sort_values('importance_avg', ascending=False)\n",
    "\n",
    "# Plotting combined importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=combined_importance.head(15), x='importance_avg', y='feature')\n",
    "plt.title('Top 15 Feature Importance - Super Ensemble (CatBoost + XGBoost + LightGBM)')\n",
    "plt.xlabel('Normalized Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"                      Super Ensemble Feature Importance               \")\n",
    "print(combined_importance.head(10)[['feature', 'importance_avg', 'importance_cat', 'importance_xgb', 'importance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performance = {\n",
    "    'CatBoost': cat_val_rmse,\n",
    "    'XGBoost': xgb_val_rmse,\n",
    "    'LightGBM': lgb_val_rmse,\n",
    "    'Stacking': stack_val_rmse,\n",
    "    'Super Ensemble': super_ensemble_val_rmse\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "plt.bar(models_performance.keys(), models_performance.values(), color=colors, alpha=0.8)\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model Performance Comparison (Lower is Better)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding value labels on bars\n",
    "for i, (model, rmse) in enumerate(models_performance.items()):\n",
    "    plt.text(i, rmse + 0.001, f'{rmse:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.kdeplot(y_val, label='Actual', fill=True, alpha=0.5)\n",
    "sns.kdeplot(cat_val_pred, label='CatBoost', fill=True, alpha=0.5)\n",
    "plt.xlabel('Accident Risk')\n",
    "plt.ylabel('Density')\n",
    "plt.title('CatBoost vs Actual')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.kdeplot(y_val, label='Actual', fill=True, alpha=0.5)\n",
    "sns.kdeplot(xgb_val_pred, label='XGBoost', fill=True, alpha=0.5)\n",
    "plt.xlabel('Accident Risk')\n",
    "plt.ylabel('Density')\n",
    "plt.title('XGBoost vs Actual')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.kdeplot(y_val, label='Actual', fill=True, alpha=0.5)\n",
    "sns.kdeplot(lgb_val_pred, label='LightGBM', fill=True, alpha=0.5)\n",
    "plt.xlabel('Accident Risk')\n",
    "plt.ylabel('Density')\n",
    "plt.title('LightGBM vs Actual')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.kdeplot(y_val, label='Actual', fill=True, alpha=0.5)\n",
    "sns.kdeplot(stacking_val_pred, label='Stacking', fill=True, alpha=0.5)\n",
    "plt.xlabel('Accident Risk')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Stacking vs Actual')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.kdeplot(y_val, label='Actual', fill=True, alpha=0.5)\n",
    "sns.kdeplot(super_ensemble_val, label='Super Ensemble', fill=True, alpha=0.5)\n",
    "plt.xlabel('Accident Risk')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Super Ensemble vs Actual')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.kdeplot(cat_val_pred, label='CatBoost', fill=True, alpha=0.3)\n",
    "sns.kdeplot(xgb_val_pred, label='XGBoost', fill=True, alpha=0.3)\n",
    "sns.kdeplot(lgb_val_pred, label='LightGBM', fill=True, alpha=0.3)\n",
    "sns.kdeplot(super_ensemble_val, label='Super Ensemble', fill=True, alpha=0.3)\n",
    "plt.xlabel('Accident Risk')\n",
    "plt.ylabel('Density')\n",
    "plt.title('All Models Distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis by important features\n",
    "feature_analysis_df = pd.DataFrame({\n",
    "    'actual': y_val,\n",
    "    'predicted': super_ensemble_val,  \n",
    "    'error': super_ensemble_val - y_val, \n",
    "    'abs_error': np.abs(super_ensemble_val - y_val) \n",
    "})\n",
    "\n",
    "# Addding important features for analysis (using advanced features)\n",
    "important_features = ['speed_limit', 'curvature', 'num_lanes', 'composite_risk', 'visibility_risk', 'complexity_score']\n",
    "for feature in important_features:\n",
    "    if feature in X_val.columns:\n",
    "        feature_analysis_df[feature] = X_val[feature].values\n",
    "    else:\n",
    "        print(f\"Warning: {feature} not found in features, using fallback\")\n",
    "        # Fallback to basic features if advanced ones are missing\n",
    "        important_features = ['speed_limit', 'curvature', 'num_lanes', 'weather_risk', 'time_risk', 'environment_risk']\n",
    "        break\n",
    "\n",
    "# Plotting error vs important features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(important_features[:6]):\n",
    "    if feature in feature_analysis_df.columns:\n",
    "        axes[i].scatter(feature_analysis_df[feature], feature_analysis_df['abs_error'], \n",
    "                       alpha=0.6, s=20, color='purple')\n",
    "        # Adding trend line\n",
    "        z = np.polyfit(feature_analysis_df[feature], feature_analysis_df['abs_error'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[i].plot(feature_analysis_df[feature], p(feature_analysis_df[feature]), \n",
    "                    \"r--\", alpha=0.8, linewidth=2)\n",
    "        \n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel('Absolute Error')\n",
    "        axes[i].set_title(f'Error vs {feature}\\nSuper Ensemble')\n",
    "        axes[i].grid(alpha=0.3)\n",
    "    else:\n",
    "        axes[i].text(0.5, 0.5, f'{feature} not available', \n",
    "                    ha='center', va='center', transform=axes[i].transAxes)\n",
    "        axes[i].set_title(f'Missing: {feature}')\n",
    "\n",
    "# Removing empty subplots\n",
    "for i in range(len(important_features), 6):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The red horizontal line in the plot is a trend line (linear regression line) that shows the relationship between feature values and prediction errors.\")\n",
    "print(\"\\n\")\n",
    "# Print error statistics by feature ranges\n",
    "print(\"\\nError Analysis Summary:\")\n",
    "for feature in important_features[:3]:  # Shows top 3 features\n",
    "    if feature in feature_analysis_df.columns:\n",
    "        feature_analysis_df[f'{feature}_bin'] = pd.cut(feature_analysis_df[feature], bins=4)\n",
    "        error_by_bin = feature_analysis_df.groupby(f'{feature}_bin')['abs_error'].mean()\n",
    "        print(f\"\\n{feature} - Mean Absolute Error by range:\")\n",
    "        for bin_range, error in error_by_bin.items():\n",
    "            print(f\"  {bin_range}: {error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Row 1: Actual vs Predicted plots for all models\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.scatter(y_val, cat_val_pred, alpha=0.6, label='CatBoost', s=20, color='#FF6B6B')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.8, linewidth=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title(f'CatBoost\\nRMSE: {cat_val_rmse:.4f}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.scatter(y_val, xgb_val_pred, alpha=0.6, label='XGBoost', s=20, color='#4ECDC4')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.8, linewidth=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title(f'XGBoost\\nRMSE: {xgb_val_rmse:.4f}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.scatter(y_val, lgb_val_pred, alpha=0.6, label='LightGBM', s=20, color='#45B7D1')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.8, linewidth=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title(f'LightGBM\\nRMSE: {lgb_val_rmse:.4f}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.scatter(y_val, super_ensemble_val, alpha=0.6, label='Super Ensemble', s=20, color='#96CEB4')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.8, linewidth=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title(f'Super Ensemble\\nRMSE: {super_ensemble_val_rmse:.4f}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Row 2: Residual plots for all models\n",
    "plt.subplot(2, 4, 5)\n",
    "cat_residuals = y_val - cat_val_pred\n",
    "plt.scatter(cat_val_pred, cat_residuals, alpha=0.6, s=20, color='#FF6B6B')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('CatBoost Residuals')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "xgb_residuals = y_val - xgb_val_pred\n",
    "plt.scatter(xgb_val_pred, xgb_residuals, alpha=0.6, s=20, color='#4ECDC4')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('XGBoost Residuals')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "lgb_residuals = y_val - lgb_val_pred\n",
    "plt.scatter(lgb_val_pred, lgb_residuals, alpha=0.6, s=20, color='#45B7D1')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('LightGBM Residuals')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "super_ensemble_residuals = y_val - super_ensemble_val\n",
    "plt.scatter(super_ensemble_val, super_ensemble_residuals, alpha=0.6, s=20, color='#96CEB4')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Super Ensemble Residuals')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Test predictions distribution\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.hist(cat_test_pred, bins=30, alpha=0.7, edgecolor='black', color='#FF6B6B', label='CatBoost')\n",
    "plt.xlabel('Predicted Accident Risk')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('CatBoost Test Predictions')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.hist(xgb_test_pred, bins=30, alpha=0.7, edgecolor='black', color='#4ECDC4', label='XGBoost')\n",
    "plt.xlabel('Predicted Accident Risk')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('XGBoost Test Predictions')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.hist(lgb_test_pred, bins=30, alpha=0.7, edgecolor='black', color='#45B7D1', label='LightGBM')\n",
    "plt.xlabel('Predicted Accident Risk')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LightGBM Test Predictions')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.hist(super_ensemble_test, bins=30, alpha=0.7, edgecolor='black', color='#96CEB4', label='Super Ensemble')\n",
    "plt.xlabel('Predicted Accident Risk')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Super Ensemble Test Predictions')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combined density plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(cat_test_pred, label='CatBoost', fill=True, alpha=0.3, color='#FF6B6B')\n",
    "sns.kdeplot(xgb_test_pred, label='XGBoost', fill=True, alpha=0.3, color='#4ECDC4')\n",
    "sns.kdeplot(lgb_test_pred, label='LightGBM', fill=True, alpha=0.3, color='#45B7D1')\n",
    "sns.kdeplot(super_ensemble_test, label='Super Ensemble', fill=True, alpha=0.3, color='#96CEB4')\n",
    "plt.xlabel('Predicted Accident Risk')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Test Predictions Distribution - All Models')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'].values,\n",
    "    'accident_risk': super_ensemble_test\n",
    "})\n",
    "\n",
    "submission_df['accident_risk'] = submission_df['accident_risk'].clip(0, 1)\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nSuper Ensemble predictions saved!\")\n",
    "print(f\"Prediction range: [{submission_df['accident_risk'].min():.3f}, {submission_df['accident_risk'].max():.3f}]\")\n",
    "print(f\"Mean prediction: {submission_df['accident_risk'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e17bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d9bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632588a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091829c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf807b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2c0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbf1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1935a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb907c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49041a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838b2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2fe91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1c48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221088c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739020a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb2ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be315079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364f340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba091d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d81b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
