{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f4e8fa",
   "metadata": {},
   "source": [
    "# Real-time Corrosion Detection System with RF-DETR\n",
    "## Advanced Computer Vision Pipeline for R&D Material Science Monitoring\n",
    "\n",
    "This notebook implements a comprehensive real-time computer vision system designed to help R&D researchers monitor corrosion patterns through intelligent behavior analysis. The system features:\n",
    "\n",
    "üîß **Core Pipeline:**\n",
    "- RF-DETR (Real-time Fine-grained Detection Transformer) for corrosion pattern detection\n",
    "- YOLOv11 for real-time object detection\n",
    "- SAM2 for precise segmentation & refined bounding boxes\n",
    "\n",
    "üìä **Dashboard Insights:**\n",
    "- System performance (FPS, processing time, live trends)\n",
    "- Corrosion severity ranking & progression stats\n",
    "- Material health score, alerts, and corrosion type distribution\n",
    "- Activity breakdown: Active Corrosion, Passive Corrosion, Pitting, Crevice Corrosion, Stress Corrosion\n",
    "\n",
    "üß™ **Impact for R&D:**\n",
    "- Early corrosion detection\n",
    "- Automated 24/7 monitoring\n",
    "- Reduced material failure\n",
    "- Data-driven research and operational decisions\n",
    "\n",
    "üß† **Tech Stack:** Python ¬∑ PyTorch ¬∑ OpenCV ¬∑ Ultralytics YOLO ¬∑ SAM2 ¬∑ Supervision ¬∑ NumPy ¬∑ Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for the corrosion detection system\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install ultralytics\n",
    "# !pip install segment-anything\n",
    "# !pip install supervision\n",
    "# !pip install streamlit\n",
    "# !pip install plotly\n",
    "# !pip install albumentations\n",
    "# !pip install timm\n",
    "\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    import supervision as sv\n",
    "    print(\"‚úÖ Ultralytics and Supervision imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install ultralytics and supervision: pip install ultralytics supervision\")\n",
    "\n",
    "try:\n",
    "    import streamlit as st\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    print(\"‚úÖ Streamlit and Plotly imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install streamlit and plotly: pip install streamlit plotly\")\n",
    "\n",
    "try:\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch import ToTensorV2\n",
    "    print(\"‚úÖ Albumentations imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Please install albumentations: pip install albumentations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration and Path Setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure dataset paths\n",
    "DATASET_ROOT = Path(r\"C:\\Users\\gopeami\\OneDrive - Vesuvius\\Desktop\\PhD13- 2025-2026\\ML Practice\\Material property Design\\Corrosion detection\\Dataset\")\n",
    "IMAGES_DIR = DATASET_ROOT / \"images\"\n",
    "ANNOTATIONS_DIR = DATASET_ROOT / \"annotations\"\n",
    "TRAIN_DIR = DATASET_ROOT / \"train\"\n",
    "VAL_DIR = DATASET_ROOT / \"validation\" \n",
    "TEST_DIR = DATASET_ROOT / \"test\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [DATASET_ROOT, IMAGES_DIR, ANNOTATIONS_DIR, TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Dataset Configuration:\")\n",
    "print(f\"  ‚Ä¢ Dataset Root: {DATASET_ROOT}\")\n",
    "print(f\"  ‚Ä¢ Images Directory: {IMAGES_DIR}\")\n",
    "print(f\"  ‚Ä¢ Annotations Directory: {ANNOTATIONS_DIR}\")\n",
    "print(f\"  ‚Ä¢ Training Directory: {TRAIN_DIR}\")\n",
    "print(f\"  ‚Ä¢ Validation Directory: {VAL_DIR}\")\n",
    "print(f\"  ‚Ä¢ Test Directory: {TEST_DIR}\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if DATASET_ROOT.exists():\n",
    "    print(\"‚úÖ Dataset directory exists\")\n",
    "    \n",
    "    # List subdirectories and files\n",
    "    subdirs = [d for d in DATASET_ROOT.iterdir() if d.is_dir()]\n",
    "    files = [f for f in DATASET_ROOT.iterdir() if f.is_file()]\n",
    "    \n",
    "    print(f\"  ‚Ä¢ Subdirectories: {len(subdirs)}\")\n",
    "    for subdir in subdirs[:5]:  # Show first 5\n",
    "        print(f\"    - {subdir.name}\")\n",
    "    if len(subdirs) > 5:\n",
    "        print(f\"    ... and {len(subdirs) - 5} more\")\n",
    "    \n",
    "    print(f\"  ‚Ä¢ Files: {len(files)}\")\n",
    "    for file in files[:5]:  # Show first 5\n",
    "        print(f\"    - {file.name}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"    ... and {len(files) - 5} more\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataset directory does not exist\")\n",
    "    print(\"   Please ensure the dataset is available at the specified path\")\n",
    "\n",
    "# Dataset structure expected:\n",
    "\"\"\"\n",
    "Dataset/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_001.jpg\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_002.jpg\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ img_001.txt (YOLO format)\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ img_002.txt\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ validation/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "‚îú‚îÄ‚îÄ test/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "‚îú‚îÄ‚îÄ classes.names\n",
    "‚îî‚îÄ‚îÄ dataset.yaml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c637569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loading and Management Functions\n",
    "class CorrosionDatasetLoader:\n",
    "    \"\"\"Dataset loader for corrosion detection data\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_root=DATASET_ROOT):\n",
    "        self.dataset_root = Path(dataset_root)\n",
    "        self.train_dir = self.dataset_root / \"train\"\n",
    "        self.val_dir = self.dataset_root / \"validation\" \n",
    "        self.test_dir = self.dataset_root / \"test\"\n",
    "        \n",
    "        # Class mapping for corrosion types\n",
    "        self.class_names = [\n",
    "            'uniform_corrosion',\n",
    "            'pitting_corrosion', \n",
    "            'crevice_corrosion',\n",
    "            'stress_corrosion',\n",
    "            'galvanic_corrosion',\n",
    "            'erosion_corrosion'\n",
    "        ]\n",
    "        \n",
    "    def scan_dataset(self):\n",
    "        \"\"\"Scan dataset and return statistics\"\"\"\n",
    "        stats = {\n",
    "            'train': self._scan_split('train'),\n",
    "            'validation': self._scan_split('validation'),\n",
    "            'test': self._scan_split('test')\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _scan_split(self, split_name):\n",
    "        \"\"\"Scan a specific data split\"\"\"\n",
    "        split_dir = self.dataset_root / split_name\n",
    "        images_dir = split_dir / \"images\"\n",
    "        labels_dir = split_dir / \"labels\"\n",
    "        \n",
    "        stats = {\n",
    "            'images_count': 0,\n",
    "            'labels_count': 0,\n",
    "            'image_formats': {},\n",
    "            'missing_labels': [],\n",
    "            'missing_images': []\n",
    "        }\n",
    "        \n",
    "        if not split_dir.exists():\n",
    "            return stats\n",
    "            \n",
    "        # Count images\n",
    "        if images_dir.exists():\n",
    "            image_files = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']:\n",
    "                image_files.extend(images_dir.glob(ext))\n",
    "            \n",
    "            stats['images_count'] = len(image_files)\n",
    "            \n",
    "            # Count formats\n",
    "            for img_file in image_files:\n",
    "                ext = img_file.suffix.lower()\n",
    "                stats['image_formats'][ext] = stats['image_formats'].get(ext, 0) + 1\n",
    "        \n",
    "        # Count labels\n",
    "        if labels_dir.exists():\n",
    "            label_files = list(labels_dir.glob('*.txt'))\n",
    "            stats['labels_count'] = len(label_files)\n",
    "            \n",
    "            # Check for missing correspondences\n",
    "            if images_dir.exists():\n",
    "                for img_file in image_files:\n",
    "                    label_file = labels_dir / f\"{img_file.stem}.txt\"\n",
    "                    if not label_file.exists():\n",
    "                        stats['missing_labels'].append(img_file.name)\n",
    "                \n",
    "                for label_file in label_files:\n",
    "                    # Check if corresponding image exists\n",
    "                    img_exists = False\n",
    "                    for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:\n",
    "                        img_file = images_dir / f\"{label_file.stem}{ext}\"\n",
    "                        if img_file.exists():\n",
    "                            img_exists = True\n",
    "                            break\n",
    "                    if not img_exists:\n",
    "                        stats['missing_images'].append(label_file.name)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def create_yolo_yaml(self, output_path=None):\n",
    "        \"\"\"Create YOLO dataset configuration file\"\"\"\n",
    "        if output_path is None:\n",
    "            output_path = self.dataset_root / \"dataset.yaml\"\n",
    "        \n",
    "        yaml_content = f\"\"\"# Corrosion Detection Dataset Configuration\n",
    "# Dataset root path\n",
    "path: {str(self.dataset_root).replace(os.sep, '/')}\n",
    "\n",
    "# Train, validation, and test sets\n",
    "train: train/images\n",
    "val: validation/images\n",
    "test: test/images\n",
    "\n",
    "# Number of classes\n",
    "nc: {len(self.class_names)}\n",
    "\n",
    "# Class names\n",
    "names: {self.class_names}\n",
    "\n",
    "# Class descriptions\n",
    "descriptions:\n",
    "  0: \"Uniform corrosion - widespread surface corrosion\"\n",
    "  1: \"Pitting corrosion - localized holes in metal surface\"\n",
    "  2: \"Crevice corrosion - corrosion in confined spaces\"\n",
    "  3: \"Stress corrosion - cracking due to stress and environment\"\n",
    "  4: \"Galvanic corrosion - corrosion due to different metals\"\n",
    "  5: \"Erosion corrosion - corrosion enhanced by fluid flow\"\n",
    "\"\"\"\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(yaml_content)\n",
    "        \n",
    "        print(f\"‚úÖ YOLO dataset configuration created: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    def load_image_paths(self, split='train'):\n",
    "        \"\"\"Load image paths for a specific split\"\"\"\n",
    "        split_dir = self.dataset_root / split / \"images\"\n",
    "        \n",
    "        if not split_dir.exists():\n",
    "            print(f\"‚ùå {split} images directory does not exist: {split_dir}\")\n",
    "            return []\n",
    "        \n",
    "        image_paths = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']:\n",
    "            image_paths.extend(split_dir.glob(ext))\n",
    "        \n",
    "        return [str(path) for path in image_paths]\n",
    "    \n",
    "    def load_annotations(self, split='train'):\n",
    "        \"\"\"Load annotations for a specific split\"\"\"\n",
    "        labels_dir = self.dataset_root / split / \"labels\"\n",
    "        \n",
    "        if not labels_dir.exists():\n",
    "            print(f\"‚ùå {split} labels directory does not exist: {labels_dir}\")\n",
    "            return []\n",
    "        \n",
    "        annotations = []\n",
    "        label_files = list(labels_dir.glob('*.txt'))\n",
    "        \n",
    "        for label_file in label_files:\n",
    "            annotation = self._parse_yolo_annotation(label_file)\n",
    "            if annotation:\n",
    "                annotations.append(annotation)\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def _parse_yolo_annotation(self, label_file):\n",
    "        \"\"\"Parse YOLO format annotation file\"\"\"\n",
    "        try:\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            boxes = []\n",
    "            labels = []\n",
    "            \n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                    \n",
    "                    # Convert YOLO format (center, width, height) to (x1, y1, x2, y2)\n",
    "                    x1 = x_center - width / 2\n",
    "                    y1 = y_center - height / 2\n",
    "                    x2 = x_center + width / 2\n",
    "                    y2 = y_center + height / 2\n",
    "                    \n",
    "                    boxes.append([x1, y1, x2, y2])\n",
    "                    labels.append(class_id)\n",
    "            \n",
    "            return {\n",
    "                'file': str(label_file),\n",
    "                'boxes': boxes,\n",
    "                'labels': labels\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error parsing {label_file}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def print_dataset_summary(self):\n",
    "        \"\"\"Print comprehensive dataset summary\"\"\"\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"CORROSION DATASET SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        stats = self.scan_dataset()\n",
    "        \n",
    "        total_images = sum(split['images_count'] for split in stats.values())\n",
    "        total_labels = sum(split['labels_count'] for split in stats.values())\n",
    "        \n",
    "        print(f\"\\\\nDataset Root: {self.dataset_root}\")\n",
    "        print(f\"Total Images: {total_images}\")\n",
    "        print(f\"Total Labels: {total_labels}\")\n",
    "        \n",
    "        for split_name, split_stats in stats.items():\n",
    "            print(f\"\\\\nüìä {split_name.upper()} SET:\")\n",
    "            print(f\"  ‚Ä¢ Images: {split_stats['images_count']}\")\n",
    "            print(f\"  ‚Ä¢ Labels: {split_stats['labels_count']}\")\n",
    "            \n",
    "            if split_stats['image_formats']:\n",
    "                print(\"  ‚Ä¢ Image formats:\")\n",
    "                for fmt, count in split_stats['image_formats'].items():\n",
    "                    print(f\"    - {fmt}: {count}\")\n",
    "            \n",
    "            if split_stats['missing_labels']:\n",
    "                print(f\"  ‚ö†Ô∏è Missing labels: {len(split_stats['missing_labels'])}\")\n",
    "                if len(split_stats['missing_labels']) <= 5:\n",
    "                    for missing in split_stats['missing_labels']:\n",
    "                        print(f\"    - {missing}\")\n",
    "                else:\n",
    "                    for missing in split_stats['missing_labels'][:3]:\n",
    "                        print(f\"    - {missing}\")\n",
    "                    print(f\"    ... and {len(split_stats['missing_labels']) - 3} more\")\n",
    "            \n",
    "            if split_stats['missing_images']:\n",
    "                print(f\"  ‚ö†Ô∏è Missing images: {len(split_stats['missing_images'])}\")\n",
    "                if len(split_stats['missing_images']) <= 5:\n",
    "                    for missing in split_stats['missing_images']:\n",
    "                        print(f\"    - {missing}\")\n",
    "                else:\n",
    "                    for missing in split_stats['missing_images'][:3]:\n",
    "                        print(f\"    - {missing}\")\n",
    "                    print(f\"    ... and {len(split_stats['missing_images']) - 3} more\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "\n",
    "# Initialize dataset loader and scan the dataset\n",
    "dataset_loader = CorrosionDatasetLoader()\n",
    "dataset_loader.print_dataset_summary()\n",
    "\n",
    "# Create YOLO configuration file\n",
    "try:\n",
    "    yaml_path = dataset_loader.create_yolo_yaml()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create YOLO config: {e}\")\n",
    "\n",
    "print(f\"\\\\nüîç Dataset loader initialized and ready to use!\")\n",
    "print(f\"üìù Use 'dataset_loader.load_image_paths(\\\"train\\\")' to get training image paths\")\n",
    "print(f\"üìù Use 'dataset_loader.load_annotations(\\\"train\\\")' to get training annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF-DETR: Real-time Fine-grained Detection Transformer Implementation\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding for transformer architecture\"\"\"\n",
    "    def __init__(self, d_model=256, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention mechanism for RF-DETR\"\"\"\n",
    "    def __init__(self, d_model=256, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "        seq_len = q.size(1)\n",
    "        \n",
    "        # Linear transformations\n",
    "        Q = self.query(q).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.key(k).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.value(v).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_dim)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attention, V)\n",
    "        \n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        output = self.out(context)\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Block for RF-DETR\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Transformer block with multi-head attention and feed-forward network\"\"\"\n",
    "    def __init__(self, d_model=256, num_heads=8, d_ff=1024, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # Multi-head attention with residual connection\n",
    "        attn_output, attention_weights = self.attention(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + ff_output)\n",
    "        \n",
    "        return x, attention_weights\n",
    "\n",
    "# Backbone feature extractor for RF-DETR\n",
    "class CorrosionBackbone(nn.Module):\n",
    "    \"\"\"Feature extraction backbone using ResNet50\"\"\"\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(CorrosionBackbone, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        resnet = resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Remove final layers\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        \n",
    "        # Feature projection layer\n",
    "        self.proj = nn.Conv2d(2048, 256, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)  # [B, 2048, H/32, W/32]\n",
    "        features = self.proj(features)  # [B, 256, H/32, W/32]\n",
    "        \n",
    "        # Flatten spatial dimensions for transformer\n",
    "        B, C, H, W = features.shape\n",
    "        features = features.flatten(2).transpose(1, 2)  # [B, H*W, 256]\n",
    "        \n",
    "        return features, (H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06659932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF-DETR Main Architecture\n",
    "class RFDETR(nn.Module):\n",
    "    \"\"\"\n",
    "    Real-time Fine-grained Detection Transformer for Corrosion Detection\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=6, num_queries=100, d_model=256, num_heads=8, \n",
    "                 num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super(RFDETR, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_queries = num_queries\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Backbone feature extractor\n",
    "        self.backbone = CorrosionBackbone()\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads) for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        # Object queries (learnable embeddings)\n",
    "        self.object_queries = nn.Embedding(num_queries, d_model)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads) for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "        \n",
    "        # Prediction heads\n",
    "        self.class_embed = nn.Linear(d_model, num_classes + 1)  # +1 for background\n",
    "        self.bbox_embed = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 4)  # x, y, w, h\n",
    "        )\n",
    "        \n",
    "        # Corrosion severity prediction head\n",
    "        self.severity_embed = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model // 2, 5)  # 5 severity levels\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Extract features from backbone\n",
    "        features, (H, W) = self.backbone(x)  # [B, H*W, 256]\n",
    "        \n",
    "        # Add positional encoding\n",
    "        features = self.pos_encoding(features)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_output = features\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoder_output, _ = encoder_layer(encoder_output)\n",
    "        \n",
    "        # Object queries for decoder\n",
    "        queries = self.object_queries.weight.unsqueeze(0).repeat(batch_size, 1, 1)  # [B, num_queries, 256]\n",
    "        \n",
    "        # Transformer decoder\n",
    "        decoder_output = queries\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            decoder_output, _ = decoder_layer(decoder_output)\n",
    "        \n",
    "        # Prediction heads\n",
    "        class_logits = self.class_embed(decoder_output)  # [B, num_queries, num_classes+1]\n",
    "        bbox_coords = self.bbox_embed(decoder_output)    # [B, num_queries, 4]\n",
    "        bbox_coords = torch.sigmoid(bbox_coords)         # Normalize to [0, 1]\n",
    "        severity_logits = self.severity_embed(decoder_output)  # [B, num_queries, 5]\n",
    "        \n",
    "        return {\n",
    "            'class_logits': class_logits,\n",
    "            'bbox_coords': bbox_coords,\n",
    "            'severity_logits': severity_logits,\n",
    "            'features': encoder_output\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions for RF-DETR Training\n",
    "class RFDETRLoss(nn.Module):\n",
    "    \"\"\"Custom loss function for RF-DETR training\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, cost_class=1.0, cost_bbox=5.0, cost_giou=2.0, cost_severity=1.0):\n",
    "        super(RFDETRLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.cost_class = cost_class\n",
    "        self.cost_bbox = cost_bbox\n",
    "        self.cost_giou = cost_giou\n",
    "        self.cost_severity = cost_severity\n",
    "        \n",
    "        # Loss functions\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.l1_loss = nn.L1Loss(reduction='none')\n",
    "        self.severity_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def box_iou(self, boxes1, boxes2):\n",
    "        \"\"\"Calculate IoU between two sets of boxes\"\"\"\n",
    "        # Convert from (cx, cy, w, h) to (x1, y1, x2, y2)\n",
    "        boxes1_corners = self.box_cxcywh_to_xyxy(boxes1)\n",
    "        boxes2_corners = self.box_cxcywh_to_xyxy(boxes2)\n",
    "        \n",
    "        # Calculate intersection\n",
    "        lt = torch.max(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "        rb = torch.min(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
    "        \n",
    "        wh = (rb - lt).clamp(min=0)\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1]\n",
    "        \n",
    "        # Calculate areas\n",
    "        area1 = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "        area2 = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "        \n",
    "        # Calculate union and IoU\n",
    "        union = area1[:, None] + area2 - inter\n",
    "        iou = inter / union\n",
    "        \n",
    "        return iou\n",
    "    \n",
    "    def box_cxcywh_to_xyxy(self, boxes):\n",
    "        \"\"\"Convert center format to corner format\"\"\"\n",
    "        cx, cy, w, h = boxes.unbind(-1)\n",
    "        x1 = cx - 0.5 * w\n",
    "        y1 = cy - 0.5 * h\n",
    "        x2 = cx + 0.5 * w\n",
    "        y2 = cy + 0.5 * h\n",
    "        return torch.stack([x1, y1, x2, y2], dim=-1)\n",
    "    \n",
    "    def generalized_box_iou(self, boxes1, boxes2):\n",
    "        \"\"\"Calculate Generalized IoU\"\"\"\n",
    "        iou = self.box_iou(boxes1, boxes2)\n",
    "        \n",
    "        boxes1_corners = self.box_cxcywh_to_xyxy(boxes1)\n",
    "        boxes2_corners = self.box_cxcywh_to_xyxy(boxes2)\n",
    "        \n",
    "        # Calculate enclosing box\n",
    "        lt = torch.min(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "        rb = torch.max(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
    "        \n",
    "        wh = (rb - lt).clamp(min=0)\n",
    "        area_c = wh[:, :, 0] * wh[:, :, 1]\n",
    "        \n",
    "        # Calculate areas\n",
    "        area1 = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "        area2 = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "        union = area1[:, None] + area2 - iou * area1[:, None]\n",
    "        \n",
    "        # Generalized IoU\n",
    "        giou = iou - (area_c - union) / area_c\n",
    "        \n",
    "        return giou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Corrosion Dataset Class with Configured Paths\n",
    "class CorrosionDataset(Dataset):\n",
    "    \"\"\"Dataset class for corrosion detection training with configured paths\"\"\"\n",
    "    \n",
    "    def __init__(self, split='train', transforms=None, is_train=True, dataset_root=None):\n",
    "        if dataset_root is None:\n",
    "            dataset_root = DATASET_ROOT\n",
    "        \n",
    "        self.dataset_root = Path(dataset_root)\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Load data using the dataset loader\n",
    "        loader = CorrosionDatasetLoader(dataset_root)\n",
    "        self.image_paths = loader.load_image_paths(split)\n",
    "        self.annotations = loader.load_annotations(split)\n",
    "        \n",
    "        # Ensure image paths and annotations match\n",
    "        self._validate_data()\n",
    "        \n",
    "        # Corrosion type mapping\n",
    "        self.corrosion_types = {\n",
    "            0: 'uniform_corrosion',\n",
    "            1: 'pitting_corrosion', \n",
    "            2: 'crevice_corrosion',\n",
    "            3: 'stress_corrosion',\n",
    "            4: 'galvanic_corrosion',\n",
    "            5: 'erosion_corrosion'\n",
    "        }\n",
    "        \n",
    "        # Severity levels\n",
    "        self.severity_levels = {\n",
    "            0: 'none',\n",
    "            1: 'mild',\n",
    "            2: 'moderate', \n",
    "            3: 'severe',\n",
    "            4: 'critical'\n",
    "        }\n",
    "        \n",
    "        print(f\"üìä {split.upper()} dataset: {len(self.image_paths)} images, {len(self.annotations)} annotations\")\n",
    "    \n",
    "    def _validate_data(self):\n",
    "        \"\"\"Validate that images and annotations match\"\"\"\n",
    "        if len(self.image_paths) != len(self.annotations):\n",
    "            print(f\"‚ö†Ô∏è Warning: {len(self.image_paths)} images but {len(self.annotations)} annotations\")\n",
    "            \n",
    "            # Try to match by filename\n",
    "            image_stems = [Path(img_path).stem for img_path in self.image_paths]\n",
    "            matched_annotations = []\n",
    "            \n",
    "            for img_path in self.image_paths:\n",
    "                img_stem = Path(img_path).stem\n",
    "                # Find corresponding annotation\n",
    "                matching_annotation = None\n",
    "                for ann in self.annotations:\n",
    "                    ann_stem = Path(ann['file']).stem\n",
    "                    if ann_stem == img_stem:\n",
    "                        matching_annotation = ann\n",
    "                        break\n",
    "                \n",
    "                if matching_annotation:\n",
    "                    matched_annotations.append(matching_annotation)\n",
    "                else:\n",
    "                    # Create empty annotation\n",
    "                    matched_annotations.append({\n",
    "                        'file': img_path,\n",
    "                        'boxes': [],\n",
    "                        'labels': []\n",
    "                    })\n",
    "            \n",
    "            self.annotations = matched_annotations\n",
    "            print(f\"‚úÖ Matched {len(self.annotations)} annotations to images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Could not load image: {image_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading image {image_path}: {e}\")\n",
    "            # Return a dummy image\n",
    "            image = np.zeros((512, 512, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Get annotations\n",
    "        annotation = self.annotations[idx]\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transforms:\n",
    "            if self.is_train and len(annotation['boxes']) > 0:\n",
    "                # Training augmentations with bounding boxes\n",
    "                try:\n",
    "                    transformed = self.transforms(\n",
    "                        image=image,\n",
    "                        bboxes=annotation['boxes'],\n",
    "                        category_ids=annotation['labels']\n",
    "                    )\n",
    "                    image = transformed['image']\n",
    "                    boxes = transformed['bboxes']\n",
    "                    labels = transformed['category_ids']\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Transform error for {image_path}: {e}\")\n",
    "                    # Fallback to original data\n",
    "                    boxes = annotation['boxes']\n",
    "                    labels = annotation['labels']\n",
    "                    if len(image.shape) == 3:\n",
    "                        image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
    "                    else:\n",
    "                        image = torch.from_numpy(image).float() / 255.0\n",
    "            else:\n",
    "                # Validation transforms without bbox augmentation\n",
    "                try:\n",
    "                    if hasattr(self.transforms, 'transforms'):\n",
    "                        # Handle albumentations compose\n",
    "                        transformed = self.transforms(image=image)\n",
    "                        image = transformed['image']\n",
    "                    else:\n",
    "                        # Handle torchvision transforms\n",
    "                        image = self.transforms(image)\n",
    "                    boxes = annotation['boxes']\n",
    "                    labels = annotation['labels']\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Transform error for {image_path}: {e}\")\n",
    "                    boxes = annotation['boxes']\n",
    "                    labels = annotation['labels']\n",
    "                    if len(image.shape) == 3:\n",
    "                        image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
    "                    else:\n",
    "                        image = torch.from_numpy(image).float() / 255.0\n",
    "        else:\n",
    "            boxes = annotation['boxes']\n",
    "            labels = annotation['labels']\n",
    "            # Normalize image\n",
    "            image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
    "        \n",
    "        # Convert to tensors\n",
    "        if len(boxes) > 0:\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "            # Generate random severity for demo (in real scenario, this would come from annotations)\n",
    "            severity = torch.tensor([np.random.randint(1, 5) for _ in labels], dtype=torch.long)\n",
    "        else:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.long)\n",
    "            severity = torch.zeros((0,), dtype=torch.long)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'severity': severity,\n",
    "            'image_id': idx,\n",
    "            'image_path': image_path\n",
    "        }\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# Updated data loading functions using configured paths\n",
    "def create_corrosion_dataloaders(batch_size=4, num_workers=2, dataset_root=None):\n",
    "    \"\"\"Create train and validation dataloaders from configured dataset\"\"\"\n",
    "    \n",
    "    if dataset_root is None:\n",
    "        dataset_root = DATASET_ROOT\n",
    "    \n",
    "    print(f\"üîÑ Creating dataloaders from {dataset_root}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = CorrosionDataset(\n",
    "        split='train',\n",
    "        transforms=get_train_transforms(),\n",
    "        is_train=True,\n",
    "        dataset_root=dataset_root\n",
    "    )\n",
    "    \n",
    "    val_dataset = CorrosionDataset(\n",
    "        split='validation',\n",
    "        transforms=get_val_transforms(),\n",
    "        is_train=False,\n",
    "        dataset_root=dataset_root\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Custom collate function for variable-sized annotations\"\"\"\n",
    "        images = []\n",
    "        targets = []\n",
    "        \n",
    "        for image, target in batch:\n",
    "            images.append(image)\n",
    "            targets.append(target)\n",
    "        \n",
    "        # Stack images\n",
    "        try:\n",
    "            images = torch.stack(images, 0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error stacking images: {e}\")\n",
    "            # Fallback: pad to same size\n",
    "            max_h = max(img.shape[1] for img in images)\n",
    "            max_w = max(img.shape[2] for img in images)\n",
    "            \n",
    "            padded_images = []\n",
    "            for img in images:\n",
    "                h, w = img.shape[1], img.shape[2]\n",
    "                padded = torch.zeros(3, max_h, max_w)\n",
    "                padded[:, :h, :w] = img\n",
    "                padded_images.append(padded)\n",
    "            images = torch.stack(padded_images, 0)\n",
    "        \n",
    "        return images, targets\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Created dataloaders:\")\n",
    "    print(f\"  ‚Ä¢ Train: {len(train_dataset)} samples, {len(train_loader)} batches\")\n",
    "    print(f\"  ‚Ä¢ Validation: {len(val_dataset)} samples, {len(val_loader)} batches\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Updated data augmentation transforms with better error handling\n",
    "def get_train_transforms():\n",
    "    \"\"\"Training data augmentations with error handling\"\"\"\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.3),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5, brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.HueSaturationValue(p=0.3, hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10),\n",
    "        A.GaussNoise(p=0.3, var_limit=(0, 50)),\n",
    "        A.Blur(blur_limit=3, p=0.3),\n",
    "        A.CLAHE(p=0.3),\n",
    "        A.Resize(512, 512, always_apply=True),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], always_apply=True),\n",
    "        ToTensorV2(always_apply=True)\n",
    "    ], bbox_params=A.BboxParams(\n",
    "        format='albumentations', \n",
    "        label_fields=['category_ids'],\n",
    "        min_visibility=0.1,\n",
    "        min_area=100\n",
    "    ))\n",
    "\n",
    "def get_val_transforms():\n",
    "    \"\"\"Validation data transforms with error handling\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(512, 512, always_apply=True),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], always_apply=True),\n",
    "        ToTensorV2(always_apply=True)\n",
    "    ])\n",
    "\n",
    "# Test dataset loading with configured paths\n",
    "try:\n",
    "    print(\"\\\\nüß™ Testing dataset loading...\")\n",
    "    train_loader, val_loader = create_corrosion_dataloaders(batch_size=2, num_workers=0)\n",
    "    \n",
    "    # Test loading one batch\n",
    "    try:\n",
    "        train_batch = next(iter(train_loader))\n",
    "        images, targets = train_batch\n",
    "        print(f\"‚úÖ Successfully loaded training batch:\")\n",
    "        print(f\"  ‚Ä¢ Images shape: {images.shape}\")\n",
    "        print(f\"  ‚Ä¢ Number of targets: {len(targets)}\")\n",
    "        \n",
    "        # Show target info\n",
    "        for i, target in enumerate(targets[:2]):  # Show first 2\n",
    "            print(f\"  ‚Ä¢ Sample {i}: {target['boxes'].shape[0]} boxes, labels: {target['labels'].tolist()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error loading training batch: {e}\")\n",
    "        print(\"   This might be expected if no dataset is available yet\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create dataloaders: {e}\")\n",
    "    print(\"   This is expected if the dataset directory is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated YOLOv11 Integration with Configured Dataset Paths\n",
    "class YOLOCorrosionDetector:\n",
    "    \"\"\"YOLOv11-based corrosion detector with configured dataset paths\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path=None, conf_threshold=0.5, iou_threshold=0.4, dataset_root=None):\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        \n",
    "        # Set dataset root\n",
    "        if dataset_root is None:\n",
    "            self.dataset_root = DATASET_ROOT\n",
    "        else:\n",
    "            self.dataset_root = Path(dataset_root)\n",
    "        \n",
    "        # Initialize YOLOv11 model\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            self.model = YOLO(model_path)\n",
    "            print(f\"‚úÖ Loaded custom YOLO model: {model_path}\")\n",
    "        else:\n",
    "            # Use pretrained YOLOv11 and fine-tune for corrosion\n",
    "            self.model = YOLO('yolo11n.pt')  # Start with nano version for speed\n",
    "            print(\"‚úÖ Loaded pretrained YOLOv11n model\")\n",
    "        \n",
    "        # Corrosion class names\n",
    "        self.class_names = [\n",
    "            'uniform_corrosion', 'pitting_corrosion', 'crevice_corrosion',\n",
    "            'stress_corrosion', 'galvanic_corrosion', 'erosion_corrosion'\n",
    "        ]\n",
    "        \n",
    "        # Color palette for visualization\n",
    "        self.colors = [\n",
    "            (255, 0, 0),    # Red - Uniform\n",
    "            (0, 255, 0),    # Green - Pitting  \n",
    "            (0, 0, 255),    # Blue - Crevice\n",
    "            (255, 255, 0),  # Yellow - Stress\n",
    "            (255, 0, 255),  # Magenta - Galvanic\n",
    "            (0, 255, 255)   # Cyan - Erosion\n",
    "        ]\n",
    "        \n",
    "        print(f\"üéØ Configured for corrosion detection with {len(self.class_names)} classes\")\n",
    "        print(f\"üìÅ Dataset root: {self.dataset_root}\")\n",
    "    \n",
    "    def prepare_dataset_for_yolo(self):\n",
    "        \"\"\"Prepare dataset structure and YAML file for YOLO training\"\"\"\n",
    "        \n",
    "        print(\"üìã Preparing dataset for YOLO training...\")\n",
    "        \n",
    "        # Create YAML configuration\n",
    "        loader = CorrosionDatasetLoader(self.dataset_root)\n",
    "        yaml_path = loader.create_yolo_yaml()\n",
    "        \n",
    "        # Validate dataset structure\n",
    "        stats = loader.scan_dataset()\n",
    "        \n",
    "        print(\"üìä Dataset validation:\")\n",
    "        for split, split_stats in stats.items():\n",
    "            if split_stats['images_count'] > 0:\n",
    "                print(f\"  ‚úÖ {split}: {split_stats['images_count']} images, {split_stats['labels_count']} labels\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è {split}: No data found\")\n",
    "        \n",
    "        # Check if dataset is ready for training\n",
    "        train_ready = stats['train']['images_count'] > 0 and stats['train']['labels_count'] > 0\n",
    "        val_ready = stats['validation']['images_count'] > 0 and stats['validation']['labels_count'] > 0\n",
    "        \n",
    "        if train_ready and val_ready:\n",
    "            print(\"‚úÖ Dataset is ready for YOLO training!\")\n",
    "            return str(yaml_path)\n",
    "        else:\n",
    "            print(\"‚ùå Dataset is not ready for training:\")\n",
    "            if not train_ready:\n",
    "                print(\"   - Missing training data\")\n",
    "            if not val_ready:\n",
    "                print(\"   - Missing validation data\")\n",
    "            return None\n",
    "    \n",
    "    def train_model(self, epochs=100, batch_size=16, image_size=640, device_id=None):\n",
    "        \"\"\"Train YOLOv11 model on corrosion dataset\"\"\"\n",
    "        \n",
    "        # Prepare dataset\n",
    "        yaml_path = self.prepare_dataset_for_yolo()\n",
    "        if yaml_path is None:\n",
    "            print(\"‚ùå Cannot train: Dataset not ready\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"üöÄ Starting YOLO training...\")\n",
    "        print(f\"  ‚Ä¢ Dataset config: {yaml_path}\")\n",
    "        print(f\"  ‚Ä¢ Epochs: {epochs}\")\n",
    "        print(f\"  ‚Ä¢ Batch size: {batch_size}\")\n",
    "        print(f\"  ‚Ä¢ Image size: {image_size}\")\n",
    "        print(f\"  ‚Ä¢ Device: {device if device_id is None else device_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Configure training parameters\n",
    "            results = self.model.train(\n",
    "                data=yaml_path,\n",
    "                epochs=epochs,\n",
    "                batch=batch_size,\n",
    "                imgsz=image_size,\n",
    "                device=device if device_id is None else device_id,\n",
    "                project=str(self.dataset_root.parent / 'runs' / 'corrosion_detection'),\n",
    "                name=f'yolo11_corrosion_{int(time.time())}',\n",
    "                save=True,\n",
    "                plots=True,\n",
    "                verbose=True,\n",
    "                patience=50,  # Early stopping patience\n",
    "                save_period=10,  # Save checkpoint every 10 epochs\n",
    "                workers=4,  # Number of worker threads\n",
    "                cos_lr=True,  # Use cosine learning rate schedule\n",
    "                close_mosaic=10,  # Close mosaic augmentation in last 10 epochs\n",
    "                amp=True,  # Use automatic mixed precision\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Training completed successfully!\")\n",
    "            \n",
    "            # Update model to the best trained weights\n",
    "            best_model_path = results.save_dir / 'weights' / 'best.pt'\n",
    "            if best_model_path.exists():\n",
    "                self.model = YOLO(str(best_model_path))\n",
    "                print(f\"‚úÖ Model updated to best weights: {best_model_path}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def predict(self, image, return_annotated=True, save_results=False):\n",
    "        \"\"\"Predict corrosion in image with enhanced error handling\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Ensure image is in correct format\n",
    "            if isinstance(image, str):\n",
    "                # Load image from path\n",
    "                image = cv2.imread(image)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            elif len(image.shape) == 4:\n",
    "                # Remove batch dimension if present\n",
    "                image = image[0]\n",
    "            \n",
    "            # Run inference\n",
    "            results = self.model(\n",
    "                image,\n",
    "                conf=self.conf_threshold,\n",
    "                iou=self.iou_threshold,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            detections = []\n",
    "            annotated_image = image.copy() if return_annotated else None\n",
    "            \n",
    "            for result in results:\n",
    "                boxes = result.boxes\n",
    "                if boxes is not None and len(boxes) > 0:\n",
    "                    for box in boxes:\n",
    "                        # Extract detection info\n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                        conf = box.conf[0].cpu().numpy()\n",
    "                        cls = int(box.cls[0].cpu().numpy())\n",
    "                        \n",
    "                        # Validate class index\n",
    "                        if cls >= len(self.class_names):\n",
    "                            print(f\"‚ö†Ô∏è Invalid class index: {cls}\")\n",
    "                            continue\n",
    "                        \n",
    "                        detection = {\n",
    "                            'bbox': [float(x1), float(y1), float(x2), float(y2)],\n",
    "                            'confidence': float(conf),\n",
    "                            'class': cls,\n",
    "                            'class_name': self.class_names[cls],\n",
    "                            'area': float((x2 - x1) * (y2 - y1))\n",
    "                        }\n",
    "                        detections.append(detection)\n",
    "                        \n",
    "                        if return_annotated:\n",
    "                            # Draw bounding box\n",
    "                            color = self.colors[cls % len(self.colors)]\n",
    "                            cv2.rectangle(annotated_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "                            \n",
    "                            # Draw label\n",
    "                            label = f\"{detection['class_name'].replace('_', ' ').title()}: {conf:.2f}\"\n",
    "                            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "                            \n",
    "                            # Background for label\n",
    "                            cv2.rectangle(annotated_image, \n",
    "                                        (int(x1), int(y1) - label_size[1] - 10), \n",
    "                                        (int(x1) + label_size[0], int(y1)), \n",
    "                                        color, -1)\n",
    "                            \n",
    "                            # Label text\n",
    "                            cv2.putText(annotated_image, label, (int(x1), int(y1) - 5), \n",
    "                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "            # Save results if requested\n",
    "            if save_results and detections:\n",
    "                timestamp = int(time.time())\n",
    "                results_dir = self.dataset_root.parent / 'results' / f'detection_{timestamp}'\n",
    "                results_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                if return_annotated:\n",
    "                    cv2.imwrite(str(results_dir / 'annotated.jpg'), \n",
    "                               cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "                \n",
    "                # Save detection data\n",
    "                import json\n",
    "                with open(results_dir / 'detections.json', 'w') as f:\n",
    "                    json.dump(detections, f, indent=2)\n",
    "                \n",
    "                print(f\"üíæ Results saved to: {results_dir}\")\n",
    "            \n",
    "            return detections, annotated_image if return_annotated else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Prediction error: {e}\")\n",
    "            return [], image if return_annotated else None\n",
    "    \n",
    "    def evaluate_on_test_set(self):\n",
    "        \"\"\"Evaluate model on test set if available\"\"\"\n",
    "        \n",
    "        loader = CorrosionDatasetLoader(self.dataset_root)\n",
    "        stats = loader.scan_dataset()\n",
    "        \n",
    "        if stats['test']['images_count'] == 0:\n",
    "            print(\"‚ö†Ô∏è No test set available for evaluation\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"üß™ Evaluating on test set ({stats['test']['images_count']} images)...\")\n",
    "        \n",
    "        try:\n",
    "            # Run validation on test set\n",
    "            test_images_dir = self.dataset_root / 'test' / 'images'\n",
    "            \n",
    "            results = self.model.val(\n",
    "                data=str(self.dataset_root / 'dataset.yaml'),\n",
    "                split='test',\n",
    "                save=True,\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Evaluation completed!\")\n",
    "            print(f\"  ‚Ä¢ mAP50: {results.box.map50:.3f}\")\n",
    "            print(f\"  ‚Ä¢ mAP50-95: {results.box.map:.3f}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Evaluation failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize YOLO detector with configured dataset\n",
    "print(\"ü§ñ Initializing YOLO Corrosion Detector...\")\n",
    "yolo_detector = YOLOCorrosionDetector(dataset_root=DATASET_ROOT)\n",
    "\n",
    "# Test with a sample if dataset exists\n",
    "try:\n",
    "    loader = CorrosionDatasetLoader()\n",
    "    train_images = loader.load_image_paths('train')\n",
    "    \n",
    "    if train_images:\n",
    "        print(f\"\\\\nüîç Testing detection on sample image...\")\n",
    "        sample_image = train_images[0]\n",
    "        \n",
    "        if os.path.exists(sample_image):\n",
    "            detections, annotated = yolo_detector.predict(sample_image, return_annotated=True)\n",
    "            print(f\"‚úÖ Detection test completed: {len(detections)} detections found\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Sample image path does not exist\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No training images found for testing\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è Could not test detection: {e}\")\n",
    "\n",
    "print(\"\\\\nüí° Ready for training! Use:\")\n",
    "print(\"   yolo_detector.train_model(epochs=50, batch_size=8)\")\n",
    "print(\"   yolo_detector.predict(image_path)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Workflow and Dataset Management\n",
    "class CorrosionTrainingWorkflow:\n",
    "    \"\"\"Complete training workflow for corrosion detection system\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_root=None):\n",
    "        self.dataset_root = Path(dataset_root) if dataset_root else DATASET_ROOT\n",
    "        self.yolo_detector = None\n",
    "        self.rfdetr_model = None\n",
    "        \n",
    "        print(f\"üöÄ Corrosion Training Workflow initialized\")\n",
    "        print(f\"üìÅ Dataset root: {self.dataset_root}\")\n",
    "    \n",
    "    def setup_training_environment(self):\n",
    "        \"\"\"Setup complete training environment\"\"\"\n",
    "        \n",
    "        print(\"‚öôÔ∏è Setting up training environment...\")\n",
    "        \n",
    "        # 1. Validate dataset\n",
    "        loader = CorrosionDatasetLoader(self.dataset_root)\n",
    "        stats = loader.scan_dataset()\n",
    "        \n",
    "        print(\"\\\\nüìä Dataset Status:\")\n",
    "        for split, split_stats in stats.items():\n",
    "            status = \"‚úÖ\" if split_stats['images_count'] > 0 else \"‚ùå\"\n",
    "            print(f\"  {status} {split.title()}: {split_stats['images_count']} images, {split_stats['labels_count']} labels\")\n",
    "        \n",
    "        # 2. Create YOLO configuration\n",
    "        try:\n",
    "            yaml_path = loader.create_yolo_yaml()\n",
    "            print(f\"‚úÖ YOLO config created: {yaml_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to create YOLO config: {e}\")\n",
    "        \n",
    "        # 3. Initialize models\n",
    "        try:\n",
    "            self.yolo_detector = YOLOCorrosionDetector(dataset_root=self.dataset_root)\n",
    "            print(\"‚úÖ YOLO detector initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå YOLO initialization failed: {e}\")\n",
    "        \n",
    "        try:\n",
    "            self.rfdetr_model = RFDETR(num_classes=6, num_queries=100)\n",
    "            print(f\"‚úÖ RF-DETR initialized ({sum(p.numel() for p in self.rfdetr_model.parameters()):,} parameters)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå RF-DETR initialization failed: {e}\")\n",
    "        \n",
    "        # 4. Check GPU availability\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "            print(f\"‚úÖ GPU available: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No GPU available - training will be slower\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def start_yolo_training(self, epochs=100, batch_size=16, image_size=640):\n",
    "        \"\"\"Start YOLO training with optimal parameters\"\"\"\n",
    "        \n",
    "        if self.yolo_detector is None:\n",
    "            print(\"‚ùå YOLO detector not initialized\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"üöÄ Starting YOLO training workflow...\")\n",
    "        \n",
    "        # Optimize batch size based on available memory\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "            if gpu_memory < 8:\n",
    "                batch_size = min(batch_size, 8)\n",
    "                print(f\"‚ö° Adjusted batch size to {batch_size} for GPU memory\")\n",
    "        else:\n",
    "            batch_size = min(batch_size, 4)\n",
    "            print(f\"‚ö° Adjusted batch size to {batch_size} for CPU training\")\n",
    "        \n",
    "        # Start training\n",
    "        results = self.yolo_detector.train_model(\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            image_size=image_size\n",
    "        )\n",
    "        \n",
    "        if results:\n",
    "            print(\"‚úÖ YOLO training completed successfully!\")\n",
    "            return results\n",
    "        else:\n",
    "            print(\"‚ùå YOLO training failed\")\n",
    "            return None\n",
    "    \n",
    "    def start_rfdetr_training(self, epochs=50, batch_size=4):\n",
    "        \"\"\"Start RF-DETR training\"\"\"\n",
    "        \n",
    "        if self.rfdetr_model is None:\n",
    "            print(\"‚ùå RF-DETR model not initialized\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"üöÄ Starting RF-DETR training workflow...\")\n",
    "        \n",
    "        try:\n",
    "            # Create dataloaders\n",
    "            train_loader, val_loader = create_corrosion_dataloaders(\n",
    "                batch_size=batch_size, \n",
    "                num_workers=0,  # Set to 0 to avoid multiprocessing issues\n",
    "                dataset_root=self.dataset_root\n",
    "            )\n",
    "            \n",
    "            # Initialize trainer\n",
    "            trainer = RFDETRTrainer(\n",
    "                self.rfdetr_model, \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                num_epochs=epochs\n",
    "            )\n",
    "            \n",
    "            # Start training\n",
    "            train_losses, val_losses = trainer.train()\n",
    "            \n",
    "            print(\"‚úÖ RF-DETR training completed!\")\n",
    "            \n",
    "            # Plot training curves\n",
    "            plot_training_history(train_losses, val_losses)\n",
    "            \n",
    "            return train_losses, val_losses\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå RF-DETR training failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate all trained models\"\"\"\n",
    "        \n",
    "        print(\"üß™ Evaluating trained models...\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Evaluate YOLO\n",
    "        if self.yolo_detector:\n",
    "            print(\"\\\\nüìä Evaluating YOLO model...\")\n",
    "            yolo_results = self.yolo_detector.evaluate_on_test_set()\n",
    "            if yolo_results:\n",
    "                results['yolo'] = {\n",
    "                    'mAP50': yolo_results.box.map50,\n",
    "                    'mAP50-95': yolo_results.box.map\n",
    "                }\n",
    "        \n",
    "        # Evaluate RF-DETR (if test data available)\n",
    "        if self.rfdetr_model:\n",
    "            try:\n",
    "                print(\"\\\\nüìä Evaluating RF-DETR model...\")\n",
    "                test_loader, _ = create_corrosion_dataloaders(\n",
    "                    batch_size=4,\n",
    "                    dataset_root=self.dataset_root\n",
    "                )\n",
    "                \n",
    "                if len(test_loader) > 0:\n",
    "                    evaluator = CorrosionEvaluator(self.rfdetr_model, test_loader)\n",
    "                    eval_results = evaluator.evaluate_model()\n",
    "                    evaluator.print_evaluation_report(eval_results)\n",
    "                    results['rfdetr'] = eval_results\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è RF-DETR evaluation skipped: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def export_models(self):\n",
    "        \"\"\"Export trained models for deployment\"\"\"\n",
    "        \n",
    "        print(\"üì¶ Exporting models for deployment...\")\n",
    "        \n",
    "        timestamp = int(time.time())\n",
    "        export_dir = self.dataset_root.parent / 'models' / f'export_{timestamp}'\n",
    "        export_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Export YOLO model\n",
    "        if self.yolo_detector and hasattr(self.yolo_detector.model, 'save'):\n",
    "            yolo_path = export_dir / 'yolo_corrosion.pt'\n",
    "            self.yolo_detector.model.save(str(yolo_path))\n",
    "            print(f\"‚úÖ YOLO model exported: {yolo_path}\")\n",
    "        \n",
    "        # Export RF-DETR model\n",
    "        if self.rfdetr_model:\n",
    "            export_model_for_production(self.rfdetr_model, str(export_dir / 'rfdetr_corrosion'))\n",
    "            print(f\"‚úÖ RF-DETR model exported: {export_dir}\")\n",
    "        \n",
    "        return export_dir\n",
    "    \n",
    "    def generate_training_report(self):\n",
    "        \"\"\"Generate comprehensive training report\"\"\"\n",
    "        \n",
    "        report_path = self.dataset_root.parent / f'training_report_{int(time.time())}.md'\n",
    "        \n",
    "        report_content = f\"\"\"# Corrosion Detection Training Report\n",
    "\n",
    "## Dataset Information\n",
    "- **Dataset Path**: `{self.dataset_root}`\n",
    "- **Generated**: {pd.Timestamp.now()}\n",
    "\n",
    "## Model Architecture\n",
    "- **YOLOv11**: Real-time object detection\n",
    "- **RF-DETR**: Fine-grained detection transformer\n",
    "- **SAM2**: Precise segmentation (post-processing)\n",
    "\n",
    "## Training Configuration\n",
    "- **Device**: {\"GPU\" if torch.cuda.is_available() else \"CPU\"}\n",
    "- **Framework**: PyTorch {torch.__version__}\n",
    "\n",
    "## Class Labels\n",
    "{chr(10).join(f\"{i}. {name.replace('_', ' ').title()}\" for i, name in enumerate(self.yolo_detector.class_names) if self.yolo_detector)}\n",
    "\n",
    "## Usage Instructions\n",
    "\n",
    "### For Inference:\n",
    "```python\n",
    "# Initialize detector\n",
    "detector = YOLOCorrosionDetector(\"{self.dataset_root.parent / 'models' / 'best.pt'}\")\n",
    "\n",
    "# Run detection\n",
    "detections, annotated = detector.predict(\"path/to/image.jpg\")\n",
    "\n",
    "# Print results\n",
    "for det in detections:\n",
    "    print(f\"Found: {{det['class_name']}} (confidence: {{det['confidence']:.2f}})\")\n",
    "```\n",
    "\n",
    "### For Dashboard:\n",
    "```bash\n",
    "streamlit run streamlit_corrosion_app.py\n",
    "```\n",
    "\n",
    "Generated by Corrosion Detection Training Workflow\n",
    "\"\"\"\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report_content)\n",
    "        \n",
    "        print(f\"üìã Training report generated: {report_path}\")\n",
    "        return report_path\n",
    "\n",
    "# Initialize training workflow\n",
    "print(\"üîß Initializing Corrosion Training Workflow...\")\n",
    "workflow = CorrosionTrainingWorkflow()\n",
    "\n",
    "# Setup training environment\n",
    "dataset_stats = workflow.setup_training_environment()\n",
    "\n",
    "print(\"\\\\nüéØ Training Workflow Ready!\")\n",
    "print(\"\\\\nQuick Start Commands:\")\n",
    "print(\"  üìä Check dataset: workflow.setup_training_environment()\")\n",
    "print(\"  üöÄ Train YOLO: workflow.start_yolo_training(epochs=50, batch_size=8)\")  \n",
    "print(\"  ü§ñ Train RF-DETR: workflow.start_rfdetr_training(epochs=30, batch_size=4)\")\n",
    "print(\"  üß™ Evaluate: workflow.evaluate_models()\")\n",
    "print(\"  üì¶ Export: workflow.export_models()\")\n",
    "print(\"  üìã Report: workflow.generate_training_report()\")\n",
    "\n",
    "# Show next steps based on dataset status\n",
    "train_available = dataset_stats['train']['images_count'] > 0\n",
    "val_available = dataset_stats['validation']['images_count'] > 0\n",
    "\n",
    "if train_available and val_available:\n",
    "    print(\"\\\\n‚úÖ Dataset is ready! You can start training immediately.\")\n",
    "    print(\"\\\\nRecommended workflow:\")\n",
    "    print(\"  1. workflow.start_yolo_training(epochs=50)  # Fast training\")\n",
    "    print(\"  2. workflow.evaluate_models()              # Check performance\") \n",
    "    print(\"  3. workflow.export_models()                # Save for deployment\")\n",
    "else:\n",
    "    print(\"\\\\n‚ö†Ô∏è Dataset setup required:\")\n",
    "    if not train_available:\n",
    "        print(\"  - Add training images to: train/images/\")\n",
    "        print(\"  - Add training labels to: train/labels/\")\n",
    "    if not val_available:\n",
    "        print(\"  - Add validation images to: validation/images/\")\n",
    "        print(\"  - Add validation labels to: validation/labels/\")\n",
    "    print(\"\\\\nDataset structure should be:\")\n",
    "    print(\"  Dataset/train/images/*.jpg\")\n",
    "    print(\"  Dataset/train/labels/*.txt (YOLO format)\")\n",
    "    print(\"  Dataset/validation/images/*.jpg\") \n",
    "    print(\"  Dataset/validation/labels/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM2 Integration for Precise Segmentation\n",
    "class SAMCorrosionSegmenter:\n",
    "    \"\"\"SAM2-based corrosion segmentation for refined analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path=None):\n",
    "        try:\n",
    "            from segment_anything import sam_model_registry, SamPredictor\n",
    "            \n",
    "            # Initialize SAM model\n",
    "            model_type = \"vit_h\"  # or \"vit_l\", \"vit_b\"\n",
    "            if model_path and os.path.exists(model_path):\n",
    "                sam = sam_model_registry[model_type](checkpoint=model_path)\n",
    "            else:\n",
    "                print(\"SAM model path not provided. Please download SAM weights.\")\n",
    "                sam = None\n",
    "            \n",
    "            if sam:\n",
    "                sam.to(device=device)\n",
    "                self.predictor = SamPredictor(sam)\n",
    "            else:\n",
    "                self.predictor = None\n",
    "                \n",
    "        except ImportError:\n",
    "            print(\"Segment Anything not installed. Install with: pip install segment-anything\")\n",
    "            self.predictor = None\n",
    "    \n",
    "    def segment_corrosion(self, image, detections):\n",
    "        \"\"\"Segment corrosion areas using SAM2\"\"\"\n",
    "        if self.predictor is None:\n",
    "            return []\n",
    "        \n",
    "        segmentations = []\n",
    "        self.predictor.set_image(image)\n",
    "        \n",
    "        for detection in detections:\n",
    "            x1, y1, x2, y2 = detection['bbox']\n",
    "            \n",
    "            # Use bounding box as prompt for SAM\n",
    "            input_box = np.array([x1, y1, x2, y2])\n",
    "            \n",
    "            try:\n",
    "                masks, scores, logits = self.predictor.predict(\n",
    "                    point_coords=None,\n",
    "                    point_labels=None,\n",
    "                    box=input_box[None, :],\n",
    "                    multimask_output=False,\n",
    "                )\n",
    "                \n",
    "                if len(masks) > 0:\n",
    "                    mask = masks[0]\n",
    "                    score = scores[0]\n",
    "                    \n",
    "                    # Calculate mask properties\n",
    "                    mask_area = np.sum(mask)\n",
    "                    bbox_area = (x2 - x1) * (y2 - y1)\n",
    "                    fill_ratio = mask_area / bbox_area if bbox_area > 0 else 0\n",
    "                    \n",
    "                    segmentation = {\n",
    "                        'mask': mask,\n",
    "                        'score': score,\n",
    "                        'area': mask_area,\n",
    "                        'fill_ratio': fill_ratio,\n",
    "                        'bbox': detection['bbox'],\n",
    "                        'class': detection['class'],\n",
    "                        'confidence': detection['confidence']\n",
    "                    }\n",
    "                    segmentations.append(segmentation)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Segmentation failed for detection: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return segmentations\n",
    "    \n",
    "    def refine_detections(self, image, detections):\n",
    "        \"\"\"Refine bounding boxes using segmentation masks\"\"\"\n",
    "        segmentations = self.segment_corrosion(image, detections)\n",
    "        refined_detections = []\n",
    "        \n",
    "        for seg in segmentations:\n",
    "            mask = seg['mask']\n",
    "            \n",
    "            # Find tight bounding box around mask\n",
    "            y_indices, x_indices = np.where(mask)\n",
    "            if len(x_indices) > 0 and len(y_indices) > 0:\n",
    "                x_min, x_max = x_indices.min(), x_indices.max()\n",
    "                y_min, y_max = y_indices.min(), y_indices.max()\n",
    "                \n",
    "                refined_detection = {\n",
    "                    'bbox': [x_min, y_min, x_max, y_max],\n",
    "                    'refined_bbox': [x_min, y_min, x_max, y_max],\n",
    "                    'original_bbox': seg['bbox'],\n",
    "                    'mask': mask,\n",
    "                    'confidence': seg['confidence'],\n",
    "                    'class': seg['class'],\n",
    "                    'area': seg['area'],\n",
    "                    'fill_ratio': seg['fill_ratio'],\n",
    "                    'segmentation_score': seg['score']\n",
    "                }\n",
    "                refined_detections.append(refined_detection)\n",
    "        \n",
    "        return refined_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8721e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Processing Pipeline\n",
    "class RealTimeCorrosionPipeline:\n",
    "    \"\"\"Complete real-time corrosion detection and analysis pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, yolo_model_path=None, sam_model_path=None, rfdetr_model_path=None):\n",
    "        # Initialize detection models\n",
    "        self.yolo_detector = YOLOCorrosionDetector(yolo_model_path)\n",
    "        self.sam_segmenter = SAMCorrosionSegmenter(sam_model_path)\n",
    "        \n",
    "        # Initialize RF-DETR if available\n",
    "        if rfdetr_model_path and os.path.exists(rfdetr_model_path):\n",
    "            self.rfdetr = RFDETR()\n",
    "            self.rfdetr.load_state_dict(torch.load(rfdetr_model_path, map_location=device))\n",
    "            self.rfdetr.to(device)\n",
    "            self.rfdetr.eval()\n",
    "        else:\n",
    "            self.rfdetr = None\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.fps_counter = 0\n",
    "        self.start_time = time.time()\n",
    "        self.processing_times = []\n",
    "        \n",
    "        # Corrosion tracking\n",
    "        self.corrosion_history = []\n",
    "        self.severity_tracker = {}\n",
    "        \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process single frame through the complete pipeline\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: YOLO Detection\n",
    "        detections, annotated_frame = self.yolo_detector.predict(frame, return_annotated=True)\n",
    "        \n",
    "        # Step 2: SAM Segmentation (if detections found)\n",
    "        refined_detections = []\n",
    "        if detections and self.sam_segmenter.predictor:\n",
    "            refined_detections = self.sam_segmenter.refine_detections(frame, detections)\n",
    "        \n",
    "        # Step 3: RF-DETR Analysis (if model available)\n",
    "        rfdetr_results = None\n",
    "        if self.rfdetr and detections:\n",
    "            rfdetr_results = self.analyze_with_rfdetr(frame)\n",
    "        \n",
    "        # Step 4: Comprehensive Analysis\n",
    "        analysis_results = self.analyze_corrosion_patterns(\n",
    "            detections, refined_detections, rfdetr_results\n",
    "        )\n",
    "        \n",
    "        # Update tracking\n",
    "        processing_time = time.time() - start_time\n",
    "        self.processing_times.append(processing_time)\n",
    "        self.fps_counter += 1\n",
    "        \n",
    "        # Calculate FPS\n",
    "        current_time = time.time()\n",
    "        elapsed = current_time - self.start_time\n",
    "        fps = self.fps_counter / elapsed if elapsed > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'annotated_frame': annotated_frame,\n",
    "            'detections': detections,\n",
    "            'refined_detections': refined_detections,\n",
    "            'analysis': analysis_results,\n",
    "            'performance': {\n",
    "                'fps': fps,\n",
    "                'processing_time': processing_time,\n",
    "                'avg_processing_time': np.mean(self.processing_times[-30:]) if self.processing_times else 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_with_rfdetr(self, frame):\n",
    "        \"\"\"Analyze frame using RF-DETR model\"\"\"\n",
    "        if self.rfdetr is None:\n",
    "            return None\n",
    "        \n",
    "        # Preprocess frame\n",
    "        transform = get_val_transforms()\n",
    "        input_tensor = transform(image=frame)['image'].unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.rfdetr(input_tensor)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def analyze_corrosion_patterns(self, detections, refined_detections, rfdetr_results):\n",
    "        \"\"\"Comprehensive corrosion pattern analysis\"\"\"\n",
    "        analysis = {\n",
    "            'total_corrosion_areas': len(detections),\n",
    "            'corrosion_types': {},\n",
    "            'severity_distribution': {},\n",
    "            'coverage_percentage': 0,\n",
    "            'risk_assessment': 'low',\n",
    "            'recommendations': []\n",
    "        }\n",
    "        \n",
    "        if not detections:\n",
    "            return analysis\n",
    "        \n",
    "        # Analyze corrosion types\n",
    "        for detection in detections:\n",
    "            class_name = detection['class_name']\n",
    "            analysis['corrosion_types'][class_name] = analysis['corrosion_types'].get(class_name, 0) + 1\n",
    "        \n",
    "        # Calculate coverage if refined detections available\n",
    "        if refined_detections:\n",
    "            total_area = 0\n",
    "            for refined in refined_detections:\n",
    "                total_area += refined['area']\n",
    "            \n",
    "            # Assume frame dimensions for coverage calculation\n",
    "            frame_area = 640 * 640  # Default YOLO input size\n",
    "            analysis['coverage_percentage'] = (total_area / frame_area) * 100\n",
    "        \n",
    "        # Risk assessment\n",
    "        if analysis['coverage_percentage'] > 20:\n",
    "            analysis['risk_assessment'] = 'critical'\n",
    "            analysis['recommendations'].append('Immediate intervention required')\n",
    "        elif analysis['coverage_percentage'] > 10:\n",
    "            analysis['risk_assessment'] = 'high'\n",
    "            analysis['recommendations'].append('Schedule maintenance within 24 hours')\n",
    "        elif analysis['coverage_percentage'] > 5:\n",
    "            analysis['risk_assessment'] = 'medium'\n",
    "            analysis['recommendations'].append('Monitor closely, schedule inspection')\n",
    "        else:\n",
    "            analysis['risk_assessment'] = 'low'\n",
    "            analysis['recommendations'].append('Continue regular monitoring')\n",
    "        \n",
    "        # Check for critical corrosion types\n",
    "        critical_types = ['stress_corrosion', 'crevice_corrosion']\n",
    "        for ctype in critical_types:\n",
    "            if ctype in analysis['corrosion_types']:\n",
    "                if analysis['risk_assessment'] not in ['critical', 'high']:\n",
    "                    analysis['risk_assessment'] = 'high'\n",
    "                analysis['recommendations'].append(f'Critical {ctype.replace(\"_\", \" \")} detected')\n",
    "        \n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdabc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four-Panel Dashboard Implementation\n",
    "class CorrosionDashboard:\n",
    "    \"\"\"Real-time dashboard for corrosion monitoring system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.performance_data = []\n",
    "        self.corrosion_history = []\n",
    "        self.alerts = []\n",
    "        self.system_stats = {\n",
    "            'total_frames_processed': 0,\n",
    "            'total_detections': 0,\n",
    "            'uptime': 0,\n",
    "            'last_critical_alert': None\n",
    "        }\n",
    "        \n",
    "    def update_performance_data(self, fps, processing_time, detections_count):\n",
    "        \"\"\"Update performance metrics\"\"\"\n",
    "        timestamp = time.time()\n",
    "        self.performance_data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'fps': fps,\n",
    "            'processing_time': processing_time,\n",
    "            'detections_count': detections_count\n",
    "        })\n",
    "        \n",
    "        # Keep only last 100 data points\n",
    "        if len(self.performance_data) > 100:\n",
    "            self.performance_data.pop(0)\n",
    "    \n",
    "    def update_corrosion_analysis(self, analysis_results):\n",
    "        \"\"\"Update corrosion analysis data\"\"\"\n",
    "        timestamp = time.time()\n",
    "        self.corrosion_history.append({\n",
    "            'timestamp': timestamp,\n",
    "            'total_areas': analysis_results['total_corrosion_areas'],\n",
    "            'coverage_percentage': analysis_results['coverage_percentage'],\n",
    "            'risk_level': analysis_results['risk_assessment'],\n",
    "            'corrosion_types': analysis_results['corrosion_types'].copy()\n",
    "        })\n",
    "        \n",
    "        # Generate alerts for critical conditions\n",
    "        if analysis_results['risk_assessment'] in ['critical', 'high']:\n",
    "            alert = {\n",
    "                'timestamp': timestamp,\n",
    "                'level': analysis_results['risk_assessment'],\n",
    "                'message': f\"High corrosion activity detected: {analysis_results['coverage_percentage']:.1f}% coverage\",\n",
    "                'recommendations': analysis_results['recommendations']\n",
    "            }\n",
    "            self.alerts.append(alert)\n",
    "            self.system_stats['last_critical_alert'] = timestamp\n",
    "        \n",
    "        # Keep only last 50 history points\n",
    "        if len(self.corrosion_history) > 50:\n",
    "            self.corrosion_history.pop(0)\n",
    "        \n",
    "        # Keep only last 20 alerts\n",
    "        if len(self.alerts) > 20:\n",
    "            self.alerts.pop(0)\n",
    "    \n",
    "    def create_dashboard_plots(self):\n",
    "        \"\"\"Create all four dashboard panels\"\"\"\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                'System Performance Metrics',\n",
    "                'Corrosion Detection Trends', \n",
    "                'Material Health Score & Alerts',\n",
    "                'Corrosion Type Distribution'\n",
    "            ),\n",
    "            specs=[\n",
    "                [{\"secondary_y\": True}, {\"secondary_y\": True}],\n",
    "                [{\"secondary_y\": False}, {\"type\": \"pie\"}]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Panel 1: System Performance\n",
    "        if self.performance_data:\n",
    "            timestamps = [pd.to_datetime(p['timestamp'], unit='s') for p in self.performance_data]\n",
    "            fps_values = [p['fps'] for p in self.performance_data]\n",
    "            processing_times = [p['processing_time'] * 1000 for p in self.performance_data]  # Convert to ms\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=fps_values, name=\"FPS\", line=dict(color='blue')),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=processing_times, name=\"Processing Time (ms)\", \n",
    "                          line=dict(color='red'), yaxis=\"y2\"),\n",
    "                row=1, col=1, secondary_y=True\n",
    "            )\n",
    "        \n",
    "        # Panel 2: Corrosion Trends\n",
    "        if self.corrosion_history:\n",
    "            timestamps = [pd.to_datetime(h['timestamp'], unit='s') for h in self.corrosion_history]\n",
    "            coverage_values = [h['coverage_percentage'] for h in self.corrosion_history]\n",
    "            total_areas = [h['total_areas'] for h in self.corrosion_history]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=coverage_values, name=\"Coverage %\", \n",
    "                          line=dict(color='orange'), fill='tonexty'),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=total_areas, name=\"Detection Count\", \n",
    "                          line=dict(color='green'), yaxis=\"y4\"),\n",
    "                row=1, col=2, secondary_y=True\n",
    "            )\n",
    "        \n",
    "        # Panel 3: Health Score and Alerts\n",
    "        if self.corrosion_history:\n",
    "            # Calculate health score (inverse of risk)\n",
    "            risk_mapping = {'low': 85, 'medium': 65, 'high': 35, 'critical': 10}\n",
    "            health_scores = [risk_mapping.get(h['risk_level'], 50) for h in self.corrosion_history]\n",
    "            timestamps = [pd.to_datetime(h['timestamp'], unit='s') for h in self.corrosion_history]\n",
    "            \n",
    "            # Color based on health score\n",
    "            colors = ['green' if score > 70 else 'yellow' if score > 40 else 'red' for score in health_scores]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=timestamps, y=health_scores, mode='lines+markers',\n",
    "                          name=\"Material Health Score\", \n",
    "                          line=dict(color='purple', width=3),\n",
    "                          marker=dict(size=8)),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # Panel 4: Corrosion Type Distribution\n",
    "        if self.corrosion_history and self.corrosion_history[-1]['corrosion_types']:\n",
    "            latest_types = self.corrosion_history[-1]['corrosion_types']\n",
    "            labels = list(latest_types.keys())\n",
    "            values = list(latest_types.values())\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Pie(labels=labels, values=values, name=\"Corrosion Types\",\n",
    "                      hole=0.3, textinfo='label+percent'),\n",
    "                row=2, col=2\n",
    "            )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=\"Real-time Corrosion Monitoring Dashboard\",\n",
    "            height=800,\n",
    "            showlegend=True,\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        \n",
    "        # Update axes labels\n",
    "        fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"FPS\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Processing Time (ms)\", row=1, col=1, secondary_y=True)\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Time\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Coverage %\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Detection Count\", row=1, col=2, secondary_y=True)\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Health Score\", row=2, col=1)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def get_current_stats(self):\n",
    "        \"\"\"Get current system statistics\"\"\"\n",
    "        current_stats = self.system_stats.copy()\n",
    "        \n",
    "        if self.performance_data:\n",
    "            current_stats['current_fps'] = self.performance_data[-1]['fps']\n",
    "            current_stats['avg_processing_time'] = np.mean([p['processing_time'] for p in self.performance_data[-10:]])\n",
    "        \n",
    "        if self.corrosion_history:\n",
    "            current_stats['current_coverage'] = self.corrosion_history[-1]['coverage_percentage']\n",
    "            current_stats['current_risk'] = self.corrosion_history[-1]['risk_level']\n",
    "            current_stats['health_score'] = {'low': 85, 'medium': 65, 'high': 35, 'critical': 10}.get(\n",
    "                self.corrosion_history[-1]['risk_level'], 50)\n",
    "        \n",
    "        current_stats['active_alerts'] = len([a for a in self.alerts if time.time() - a['timestamp'] < 3600])  # Last hour\n",
    "        \n",
    "        return current_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d678de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Dashboard Application\n",
    "def create_streamlit_dashboard():\n",
    "    \"\"\"Create Streamlit web dashboard for real-time monitoring\"\"\"\n",
    "    \n",
    "    st.set_page_config(\n",
    "        page_title=\"Corrosion Detection Dashboard\",\n",
    "        page_icon=\"üî¨\",\n",
    "        layout=\"wide\",\n",
    "        initial_sidebar_state=\"expanded\"\n",
    "    )\n",
    "    \n",
    "    st.title(\"üî¨ Real-time Corrosion Detection System\")\n",
    "    st.markdown(\"### Advanced Computer Vision Pipeline for R&D Material Science Monitoring\")\n",
    "    \n",
    "    # Initialize session state\n",
    "    if 'pipeline' not in st.session_state:\n",
    "        st.session_state.pipeline = RealTimeCorrosionPipeline()\n",
    "        st.session_state.dashboard = CorrosionDashboard()\n",
    "        st.session_state.is_running = False\n",
    "        st.session_state.video_source = None\n",
    "    \n",
    "    # Sidebar configuration\n",
    "    st.sidebar.header(\"‚öôÔ∏è System Configuration\")\n",
    "    \n",
    "    # Video source selection\n",
    "    source_type = st.sidebar.selectbox(\n",
    "        \"Select Video Source\",\n",
    "        [\"Webcam\", \"Video File\", \"Image File\", \"Demo Mode\"]\n",
    "    )\n",
    "    \n",
    "    if source_type == \"Video File\":\n",
    "        uploaded_video = st.sidebar.file_uploader(\"Upload Video\", type=['mp4', 'avi', 'mov'])\n",
    "        if uploaded_video:\n",
    "            st.session_state.video_source = uploaded_video\n",
    "    elif source_type == \"Image File\":\n",
    "        uploaded_image = st.sidebar.file_uploader(\"Upload Image\", type=['jpg', 'jpeg', 'png'])\n",
    "        if uploaded_image:\n",
    "            st.session_state.video_source = uploaded_image\n",
    "    elif source_type == \"Webcam\":\n",
    "        st.session_state.video_source = 0\n",
    "    else:  # Demo Mode\n",
    "        st.session_state.video_source = \"demo\"\n",
    "    \n",
    "    # Model configuration\n",
    "    st.sidebar.subheader(\"ü§ñ Model Settings\")\n",
    "    confidence_threshold = st.sidebar.slider(\"Confidence Threshold\", 0.1, 1.0, 0.5, 0.1)\n",
    "    iou_threshold = st.sidebar.slider(\"IoU Threshold\", 0.1, 1.0, 0.4, 0.1)\n",
    "    \n",
    "    # Update thresholds\n",
    "    st.session_state.pipeline.yolo_detector.conf_threshold = confidence_threshold\n",
    "    st.session_state.pipeline.yolo_detector.iou_threshold = iou_threshold\n",
    "    \n",
    "    # Control buttons\n",
    "    col1, col2, col3 = st.sidebar.columns(3)\n",
    "    with col1:\n",
    "        if st.button(\"‚ñ∂Ô∏è Start\"):\n",
    "            st.session_state.is_running = True\n",
    "    with col2:\n",
    "        if st.button(\"‚è∏Ô∏è Pause\"):\n",
    "            st.session_state.is_running = False\n",
    "    with col3:\n",
    "        if st.button(\"üîÑ Reset\"):\n",
    "            st.session_state.dashboard = CorrosionDashboard()\n",
    "    \n",
    "    # Main dashboard layout\n",
    "    if st.session_state.is_running and st.session_state.video_source is not None:\n",
    "        \n",
    "        # Create main content area\n",
    "        video_col, stats_col = st.columns([2, 1])\n",
    "        \n",
    "        with video_col:\n",
    "            st.subheader(\"üìπ Live Video Feed\")\n",
    "            video_placeholder = st.empty()\n",
    "            \n",
    "            # Process video/image\n",
    "            if source_type == \"Image File\" and st.session_state.video_source:\n",
    "                # Single image processing\n",
    "                image = np.array(Image.open(st.session_state.video_source))\n",
    "                results = st.session_state.pipeline.process_frame(image)\n",
    "                \n",
    "                # Update dashboard\n",
    "                st.session_state.dashboard.update_performance_data(\n",
    "                    results['performance']['fps'],\n",
    "                    results['performance']['processing_time'],\n",
    "                    len(results['detections'])\n",
    "                )\n",
    "                st.session_state.dashboard.update_corrosion_analysis(results['analysis'])\n",
    "                \n",
    "                # Display annotated image\n",
    "                video_placeholder.image(results['annotated_frame'], channels=\"RGB\", use_column_width=True)\n",
    "            \n",
    "            elif source_type == \"Demo Mode\":\n",
    "                # Demo with synthetic data\n",
    "                demo_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "                results = {\n",
    "                    'annotated_frame': demo_image,\n",
    "                    'detections': [\n",
    "                        {'class_name': 'pitting_corrosion', 'confidence': 0.85, 'bbox': [100, 100, 200, 200]},\n",
    "                        {'class_name': 'uniform_corrosion', 'confidence': 0.72, 'bbox': [300, 150, 400, 250]}\n",
    "                    ],\n",
    "                    'analysis': {\n",
    "                        'total_corrosion_areas': 2,\n",
    "                        'coverage_percentage': 12.5,\n",
    "                        'risk_assessment': 'high',\n",
    "                        'corrosion_types': {'pitting_corrosion': 1, 'uniform_corrosion': 1},\n",
    "                        'recommendations': ['Schedule maintenance within 24 hours']\n",
    "                    },\n",
    "                    'performance': {'fps': 24.5, 'processing_time': 0.041}\n",
    "                }\n",
    "                \n",
    "                st.session_state.dashboard.update_performance_data(24.5, 0.041, 2)\n",
    "                st.session_state.dashboard.update_corrosion_analysis(results['analysis'])\n",
    "                video_placeholder.image(demo_image, channels=\"RGB\", use_column_width=True)\n",
    "        \n",
    "        with stats_col:\n",
    "            st.subheader(\"üìä Real-time Stats\")\n",
    "            \n",
    "            # Current statistics\n",
    "            current_stats = st.session_state.dashboard.get_current_stats()\n",
    "            \n",
    "            # Metrics display\n",
    "            col1, col2 = st.columns(2)\n",
    "            with col1:\n",
    "                st.metric(\"FPS\", f\"{current_stats.get('current_fps', 0):.1f}\")\n",
    "                st.metric(\"Health Score\", f\"{current_stats.get('health_score', 50)}\")\n",
    "            with col2:\n",
    "                st.metric(\"Coverage %\", f\"{current_stats.get('current_coverage', 0):.1f}%\")\n",
    "                st.metric(\"Active Alerts\", current_stats.get('active_alerts', 0))\n",
    "            \n",
    "            # Risk assessment\n",
    "            risk_level = current_stats.get('current_risk', 'unknown')\n",
    "            risk_color = {\n",
    "                'low': 'green', 'medium': 'orange', \n",
    "                'high': 'red', 'critical': 'darkred'\n",
    "            }.get(risk_level, 'gray')\n",
    "            \n",
    "            st.markdown(f\"**Risk Level:** <span style='color: {risk_color}'>{risk_level.upper()}</span>\", \n",
    "                       unsafe_allow_html=True)\n",
    "        \n",
    "        # Four-panel dashboard\n",
    "        st.subheader(\"üìà Analysis Dashboard\")\n",
    "        \n",
    "        # Generate and display plots\n",
    "        dashboard_fig = st.session_state.dashboard.create_dashboard_plots()\n",
    "        st.plotly_chart(dashboard_fig, use_container_width=True)\n",
    "        \n",
    "        # Recent alerts\n",
    "        if st.session_state.dashboard.alerts:\n",
    "            st.subheader(\"üö® Recent Alerts\")\n",
    "            for alert in st.session_state.dashboard.alerts[-5:]:  # Show last 5 alerts\n",
    "                alert_time = pd.to_datetime(alert['timestamp'], unit='s').strftime('%H:%M:%S')\n",
    "                alert_color = 'red' if alert['level'] == 'critical' else 'orange'\n",
    "                st.markdown(\n",
    "                    f\"**{alert_time}** - <span style='color: {alert_color}'>{alert['level'].upper()}</span>: {alert['message']}\",\n",
    "                    unsafe_allow_html=True\n",
    "                )\n",
    "                for rec in alert['recommendations']:\n",
    "                    st.markdown(f\"  ‚Ä¢ {rec}\")\n",
    "    \n",
    "    else:\n",
    "        # Welcome screen\n",
    "        st.info(\"üëÜ Configure your video source in the sidebar and click 'Start' to begin monitoring\")\n",
    "        \n",
    "        # Show system capabilities\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        with col1:\n",
    "            st.markdown(\"\"\"\n",
    "            ### üîß Core Pipeline\n",
    "            - RF-DETR for fine-grained detection\n",
    "            - YOLOv11 for real-time processing  \n",
    "            - SAM2 for precise segmentation\n",
    "            \"\"\")\n",
    "        with col2:\n",
    "            st.markdown(\"\"\"\n",
    "            ### üìä Dashboard Features\n",
    "            - Real-time performance metrics\n",
    "            - Corrosion trend analysis\n",
    "            - Health score monitoring\n",
    "            - Alert management system\n",
    "            \"\"\")\n",
    "        with col3:\n",
    "            st.markdown(\"\"\"\n",
    "            ### üß™ R&D Benefits\n",
    "            - Early corrosion detection\n",
    "            - 24/7 automated monitoring\n",
    "            - Data-driven insights\n",
    "            - Predictive maintenance\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f280dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Pipeline for RF-DETR\n",
    "class RFDETRTrainer:\n",
    "    \"\"\"Training pipeline for RF-DETR model\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, val_loader, num_epochs=100, learning_rate=1e-4):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        # Optimizer and scheduler\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(), \n",
    "            lr=learning_rate, \n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=num_epochs\n",
    "        )\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = RFDETRLoss(num_classes=6)\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_val_loss = float('inf')\n",
    "        \n",
    "    def hungarian_matching(self, pred_boxes, pred_classes, target_boxes, target_classes):\n",
    "        \"\"\"Hungarian matching for object detection\"\"\"\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        \n",
    "        batch_size = pred_boxes.shape[0]\n",
    "        indices = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            # Compute cost matrix\n",
    "            pred_b = pred_boxes[b]  # [num_queries, 4]\n",
    "            target_b = target_boxes[b]  # [num_targets, 4]\n",
    "            pred_cls_b = pred_classes[b]  # [num_queries, num_classes]\n",
    "            target_cls_b = target_classes[b]  # [num_targets]\n",
    "            \n",
    "            if len(target_b) == 0:\n",
    "                indices.append((torch.tensor([]), torch.tensor([])))\n",
    "                continue\n",
    "            \n",
    "            # Classification cost\n",
    "            pred_probs = F.softmax(pred_cls_b, dim=-1)\n",
    "            cls_cost = -pred_probs[:, target_cls_b]\n",
    "            \n",
    "            # L1 cost\n",
    "            l1_cost = torch.cdist(pred_b, target_b, p=1)\n",
    "            \n",
    "            # IoU cost (approximate with GIoU)\n",
    "            giou_cost = -self.criterion.generalized_box_iou(pred_b, target_b)\n",
    "            \n",
    "            # Combined cost\n",
    "            cost = (self.criterion.cost_class * cls_cost + \n",
    "                   self.criterion.cost_bbox * l1_cost + \n",
    "                   self.criterion.cost_giou * giou_cost)\n",
    "            \n",
    "            # Hungarian algorithm\n",
    "            pred_idx, target_idx = linear_sum_assignment(cost.cpu().numpy())\n",
    "            indices.append((torch.tensor(pred_idx), torch.tensor(target_idx)))\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    def compute_loss(self, outputs, targets):\n",
    "        \"\"\"Compute RF-DETR loss with Hungarian matching\"\"\"\n",
    "        pred_boxes = outputs['bbox_coords']  # [B, num_queries, 4]\n",
    "        pred_classes = outputs['class_logits']  # [B, num_queries, num_classes+1]\n",
    "        pred_severity = outputs['severity_logits']  # [B, num_queries, 5]\n",
    "        \n",
    "        batch_size = pred_boxes.shape[0]\n",
    "        total_loss = 0\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            target = targets[b]\n",
    "            target_boxes = target['boxes']\n",
    "            target_classes = target['labels']\n",
    "            target_severity = target.get('severity', torch.ones_like(target_classes))\n",
    "            \n",
    "            if len(target_boxes) == 0:\n",
    "                # No targets, only classification loss for background\n",
    "                bg_loss = F.cross_entropy(\n",
    "                    pred_classes[b], \n",
    "                    torch.zeros(pred_classes[b].shape[0], dtype=torch.long, device=device)\n",
    "                )\n",
    "                total_loss += bg_loss\n",
    "                continue\n",
    "            \n",
    "            # Hungarian matching\n",
    "            indices = self.hungarian_matching(\n",
    "                pred_boxes[b:b+1], pred_classes[b:b+1], \n",
    "                target_boxes.unsqueeze(0), target_classes.unsqueeze(0)\n",
    "            )\n",
    "            pred_idx, target_idx = indices[0]\n",
    "            \n",
    "            if len(pred_idx) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Selected predictions and targets\n",
    "            selected_pred_boxes = pred_boxes[b][pred_idx]\n",
    "            selected_pred_classes = pred_classes[b][pred_idx]\n",
    "            selected_pred_severity = pred_severity[b][pred_idx]\n",
    "            selected_target_boxes = target_boxes[target_idx]\n",
    "            selected_target_classes = target_classes[target_idx]\n",
    "            selected_target_severity = target_severity[target_idx]\n",
    "            \n",
    "            # Classification loss\n",
    "            cls_loss = F.cross_entropy(selected_pred_classes, selected_target_classes)\n",
    "            \n",
    "            # Bounding box loss\n",
    "            bbox_loss = F.l1_loss(selected_pred_boxes, selected_target_boxes)\n",
    "            \n",
    "            # GIoU loss\n",
    "            giou_loss = 1 - self.criterion.generalized_box_iou(\n",
    "                selected_pred_boxes, selected_target_boxes\n",
    "            ).diag().mean()\n",
    "            \n",
    "            # Severity loss\n",
    "            severity_loss = F.cross_entropy(selected_pred_severity, selected_target_severity)\n",
    "            \n",
    "            # Background classification loss for unmatched predictions\n",
    "            unmatched_mask = torch.ones(pred_classes[b].shape[0], dtype=torch.bool, device=device)\n",
    "            unmatched_mask[pred_idx] = False\n",
    "            if unmatched_mask.any():\n",
    "                bg_loss = F.cross_entropy(\n",
    "                    pred_classes[b][unmatched_mask],\n",
    "                    torch.zeros(unmatched_mask.sum(), dtype=torch.long, device=device)\n",
    "                )\n",
    "            else:\n",
    "                bg_loss = 0\n",
    "            \n",
    "            # Combine losses\n",
    "            sample_loss = (cls_loss + \n",
    "                          self.criterion.cost_bbox * bbox_loss + \n",
    "                          self.criterion.cost_giou * giou_loss + \n",
    "                          self.criterion.cost_severity * severity_loss + \n",
    "                          0.1 * bg_loss)\n",
    "            \n",
    "            total_loss += sample_loss\n",
    "        \n",
    "        return total_loss / batch_size\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (images, targets) in enumerate(self.train_loader):\n",
    "            images = images.to(device)\n",
    "            targets = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.compute_loss(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.1)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return epoch_loss / num_batches\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in self.val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.compute_loss(outputs, targets)\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                num_batches += 1\n",
    "        \n",
    "        return epoch_loss / num_batches\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Complete training loop\"\"\"\n",
    "        print(\"Starting RF-DETR training...\")\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.num_epochs}\")\n",
    "            \n",
    "            # Training\n",
    "            train_loss = self.train_epoch()\n",
    "            self.train_losses.append(train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss = self.validate_epoch()\n",
    "            self.val_losses.append(val_loss)\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), 'best_rfdetr_model.pth')\n",
    "                print(\"üíæ New best model saved!\")\n",
    "        \n",
    "        print(\"Training completed!\")\n",
    "        return self.train_losses, self.val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Metrics\n",
    "class CorrosionEvaluator:\n",
    "    \"\"\"Evaluation metrics for corrosion detection models\"\"\"\n",
    "    \n",
    "    def __init__(self, model, dataloader, iou_threshold=0.5):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.class_names = [\n",
    "            'background', 'uniform_corrosion', 'pitting_corrosion', \n",
    "            'crevice_corrosion', 'stress_corrosion', 'galvanic_corrosion', 'erosion_corrosion'\n",
    "        ]\n",
    "    \n",
    "    def calculate_ap(self, precisions, recalls):\n",
    "        \"\"\"Calculate Average Precision using 11-point interpolation\"\"\"\n",
    "        ap = 0\n",
    "        for t in np.arange(0, 1.1, 0.1):\n",
    "            if np.sum(recalls >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(precisions[recalls >= t])\n",
    "            ap += p / 11\n",
    "        return ap\n",
    "    \n",
    "    def evaluate_detection(self, pred_boxes, pred_scores, pred_classes, target_boxes, target_classes):\n",
    "        \"\"\"Evaluate detection performance for single image\"\"\"\n",
    "        if len(pred_boxes) == 0:\n",
    "            return {'tp': 0, 'fp': 0, 'fn': len(target_boxes)}\n",
    "        \n",
    "        if len(target_boxes) == 0:\n",
    "            return {'tp': 0, 'fp': len(pred_boxes), 'fn': 0}\n",
    "        \n",
    "        # Calculate IoU matrix\n",
    "        iou_matrix = self.box_iou(pred_boxes, target_boxes)\n",
    "        \n",
    "        # Find best matches\n",
    "        tp = 0\n",
    "        matched_targets = set()\n",
    "        matched_preds = set()\n",
    "        \n",
    "        # Sort predictions by score (descending)\n",
    "        sorted_indices = np.argsort(pred_scores)[::-1]\n",
    "        \n",
    "        for pred_idx in sorted_indices:\n",
    "            best_iou = 0\n",
    "            best_target_idx = -1\n",
    "            \n",
    "            for target_idx in range(len(target_boxes)):\n",
    "                if target_idx in matched_targets:\n",
    "                    continue\n",
    "                \n",
    "                # Check class match and IoU\n",
    "                if (pred_classes[pred_idx] == target_classes[target_idx] and \n",
    "                    iou_matrix[pred_idx, target_idx] >= self.iou_threshold and\n",
    "                    iou_matrix[pred_idx, target_idx] > best_iou):\n",
    "                    best_iou = iou_matrix[pred_idx, target_idx]\n",
    "                    best_target_idx = target_idx\n",
    "            \n",
    "            if best_target_idx != -1:\n",
    "                tp += 1\n",
    "                matched_targets.add(best_target_idx)\n",
    "                matched_preds.add(pred_idx)\n",
    "        \n",
    "        fp = len(pred_boxes) - tp\n",
    "        fn = len(target_boxes) - tp\n",
    "        \n",
    "        return {'tp': tp, 'fp': fp, 'fn': fn}\n",
    "    \n",
    "    def box_iou(self, boxes1, boxes2):\n",
    "        \"\"\"Calculate IoU between two sets of boxes\"\"\"\n",
    "        def box_area(boxes):\n",
    "            return (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "        \n",
    "        area1 = box_area(boxes1)\n",
    "        area2 = box_area(boxes2)\n",
    "        \n",
    "        lt = np.maximum(boxes1[:, None, :2], boxes2[:, :2])\n",
    "        rb = np.minimum(boxes1[:, None, 2:], boxes2[:, 2:])\n",
    "        \n",
    "        wh = np.clip(rb - lt, 0, None)\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1]\n",
    "        \n",
    "        iou = inter / (area1[:, None] + area2 - inter)\n",
    "        return iou\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        all_detections = []\n",
    "        all_targets = []\n",
    "        class_metrics = {cls: {'tp': 0, 'fp': 0, 'fn': 0} for cls in range(len(self.class_names))}\n",
    "        \n",
    "        print(\"Evaluating model...\")\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, targets) in enumerate(self.dataloader):\n",
    "                images = images.to(device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                \n",
    "                # Process each image in batch\n",
    "                for i in range(len(images)):\n",
    "                    # Extract predictions\n",
    "                    pred_boxes = outputs['bbox_coords'][i].cpu().numpy()\n",
    "                    pred_classes_logits = outputs['class_logits'][i].cpu().numpy()\n",
    "                    pred_classes = np.argmax(pred_classes_logits, axis=1)\n",
    "                    pred_scores = np.max(F.softmax(torch.tensor(pred_classes_logits), dim=1).numpy(), axis=1)\n",
    "                    \n",
    "                    # Filter out background predictions and low confidence\n",
    "                    valid_mask = (pred_classes != 0) & (pred_scores > 0.1)\n",
    "                    pred_boxes = pred_boxes[valid_mask]\n",
    "                    pred_classes = pred_classes[valid_mask]\n",
    "                    pred_scores = pred_scores[valid_mask]\n",
    "                    \n",
    "                    # Convert normalized boxes to pixel coordinates (assuming 512x512)\n",
    "                    pred_boxes = pred_boxes * 512\n",
    "                    pred_boxes[:, [0, 2]] = np.clip(pred_boxes[:, [0, 2]], 0, 512)\n",
    "                    pred_boxes[:, [1, 3]] = np.clip(pred_boxes[:, [1, 3]], 0, 512)\n",
    "                    \n",
    "                    # Extract targets\n",
    "                    target = targets[i]\n",
    "                    target_boxes = target['boxes'].cpu().numpy() * 512\n",
    "                    target_classes = target['labels'].cpu().numpy()\n",
    "                    \n",
    "                    # Evaluate detection for this image\n",
    "                    result = self.evaluate_detection(pred_boxes, pred_scores, pred_classes, \n",
    "                                                   target_boxes, target_classes)\n",
    "                    \n",
    "                    # Update class-wise metrics\n",
    "                    for cls in np.unique(np.concatenate([pred_classes, target_classes])):\n",
    "                        if cls in class_metrics:\n",
    "                            class_metrics[cls]['tp'] += result['tp']\n",
    "                            class_metrics[cls]['fp'] += result['fp']\n",
    "                            class_metrics[cls]['fn'] += result['fn']\n",
    "                \n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(f\"Processed {batch_idx}/{len(self.dataloader)} batches\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        results = self.calculate_metrics(class_metrics)\n",
    "        return results\n",
    "    \n",
    "    def calculate_metrics(self, class_metrics):\n",
    "        \"\"\"Calculate precision, recall, F1, and mAP\"\"\"\n",
    "        results = {}\n",
    "        total_tp = total_fp = total_fn = 0\n",
    "        \n",
    "        for cls_id, cls_name in enumerate(self.class_names):\n",
    "            if cls_id == 0:  # Skip background\n",
    "                continue\n",
    "            \n",
    "            metrics = class_metrics[cls_id]\n",
    "            tp, fp, fn = metrics['tp'], metrics['fp'], metrics['fn']\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            results[cls_name] = {\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'tp': tp,\n",
    "                'fp': fp,\n",
    "                'fn': fn\n",
    "            }\n",
    "            \n",
    "            total_tp += tp\n",
    "            total_fp += fp\n",
    "            total_fn += fn\n",
    "        \n",
    "        # Overall metrics\n",
    "        overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "        overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "        overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
    "        \n",
    "        results['overall'] = {\n",
    "            'precision': overall_precision,\n",
    "            'recall': overall_recall,\n",
    "            'f1': overall_f1,\n",
    "            'tp': total_tp,\n",
    "            'fp': total_fp,\n",
    "            'fn': total_fn\n",
    "        }\n",
    "        \n",
    "        # mAP calculation (simplified)\n",
    "        map_score = np.mean([results[cls]['f1'] for cls in results if cls != 'overall'])\n",
    "        results['mAP'] = map_score\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_evaluation_report(self, results):\n",
    "        \"\"\"Print detailed evaluation report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CORROSION DETECTION MODEL EVALUATION REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nOverall Performance:\")\n",
    "        print(f\"  Precision: {results['overall']['precision']:.3f}\")\n",
    "        print(f\"  Recall:    {results['overall']['recall']:.3f}\")\n",
    "        print(f\"  F1-Score:  {results['overall']['f1']:.3f}\")\n",
    "        print(f\"  mAP:       {results['mAP']:.3f}\")\n",
    "        \n",
    "        print(f\"\\nPer-Class Performance:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Class':<20} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'TP':<5} {'FP':<5} {'FN':<5}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for cls_name, metrics in results.items():\n",
    "            if cls_name in ['overall', 'mAP']:\n",
    "                continue\n",
    "            print(f\"{cls_name:<20} {metrics['precision']:<10.3f} {metrics['recall']:<10.3f} \"\n",
    "                  f\"{metrics['f1']:<10.3f} {metrics['tp']:<5d} {metrics['fp']:<5d} {metrics['fn']:<5d}\")\n",
    "        \n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62866160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo and Visualization Functions\n",
    "def create_demo_data():\n",
    "    \"\"\"Create synthetic demo data for testing the pipeline\"\"\"\n",
    "    \n",
    "    # Generate synthetic corrosion images\n",
    "    demo_images = []\n",
    "    demo_annotations = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Create base image with texture\n",
    "        image = np.random.randint(100, 150, (512, 512, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add corrosion patterns\n",
    "        annotations = {\n",
    "            'boxes': [],\n",
    "            'labels': [],\n",
    "            'severity': []\n",
    "        }\n",
    "        \n",
    "        # Add random corrosion spots\n",
    "        num_spots = np.random.randint(1, 5)\n",
    "        for _ in range(num_spots):\n",
    "            # Random position and size\n",
    "            x = np.random.randint(50, 450)\n",
    "            y = np.random.randint(50, 450)\n",
    "            w = np.random.randint(30, 100)\n",
    "            h = np.random.randint(30, 100)\n",
    "            \n",
    "            # Ensure within bounds\n",
    "            x2 = min(x + w, 512)\n",
    "            y2 = min(y + h, 512)\n",
    "            \n",
    "            # Add corrosion pattern to image\n",
    "            corrosion_type = np.random.randint(1, 7)  # 1-6 corrosion types\n",
    "            \n",
    "            if corrosion_type == 1:  # Uniform corrosion - reddish brown\n",
    "                image[y:y2, x:x2] = [139, 69, 19]  # Brown\n",
    "            elif corrosion_type == 2:  # Pitting - dark spots\n",
    "                cv2.circle(image, (x + w//2, y + h//2), min(w, h)//2, (50, 50, 50), -1)\n",
    "            elif corrosion_type == 3:  # Crevice - linear patterns\n",
    "                for j in range(y, y2, 5):\n",
    "                    cv2.line(image, (x, j), (x2, j), (80, 80, 80), 2)\n",
    "            elif corrosion_type == 4:  # Stress corrosion - crack-like\n",
    "                cv2.line(image, (x, y), (x2, y2), (60, 60, 60), 3)\n",
    "                cv2.line(image, (x, y2), (x2, y), (60, 60, 60), 3)\n",
    "            elif corrosion_type == 5:  # Galvanic - metallic appearance\n",
    "                image[y:y2, x:x2] = [192, 192, 192]  # Silver\n",
    "            else:  # Erosion - rough texture\n",
    "                noise = np.random.randint(-30, 30, (y2-y, x2-x, 3))\n",
    "                image[y:y2, x:x2] = np.clip(image[y:y2, x:x2] + noise, 0, 255)\n",
    "            \n",
    "            # Add to annotations (normalize coordinates)\n",
    "            annotations['boxes'].append([x/512, y/512, x2/512, y2/512])\n",
    "            annotations['labels'].append(corrosion_type)\n",
    "            annotations['severity'].append(np.random.randint(1, 5))  # 1-4 severity\n",
    "        \n",
    "        demo_images.append(image)\n",
    "        demo_annotations.append(annotations)\n",
    "    \n",
    "    return demo_images, demo_annotations\n",
    "\n",
    "def visualize_detections(image, detections, title=\"Corrosion Detection Results\"):\n",
    "    \"\"\"Visualize detection results with bounding boxes and labels\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Color mapping for different corrosion types\n",
    "    colors = {\n",
    "        'uniform_corrosion': 'red',\n",
    "        'pitting_corrosion': 'blue', \n",
    "        'crevice_corrosion': 'green',\n",
    "        'stress_corrosion': 'yellow',\n",
    "        'galvanic_corrosion': 'magenta',\n",
    "        'erosion_corrosion': 'cyan'\n",
    "    }\n",
    "    \n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2 = detection['bbox']\n",
    "        class_name = detection['class_name']\n",
    "        confidence = detection['confidence']\n",
    "        \n",
    "        # Draw bounding box\n",
    "        color = colors.get(class_name, 'white')\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                           fill=False, color=color, linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        label = f\"{class_name.replace('_', ' ').title()}\\n{confidence:.2f}\"\n",
    "        plt.text(x1, y1-10, label, color=color, fontsize=10, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='black', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history(train_losses, val_losses):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='red')\n",
    "    plt.title('Model Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(np.array(train_losses) - np.array(val_losses), \n",
    "             label='Train-Val Gap', color='green')\n",
    "    plt.title('Overfitting Analysis')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Difference')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_confusion_matrix(true_labels, pred_labels, class_names):\n",
    "    \"\"\"Create and plot confusion matrix\"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Corrosion Detection Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Test the Complete System\n",
    "def initialize_system():\n",
    "    \"\"\"Initialize the complete corrosion detection system\"\"\"\n",
    "    \n",
    "    print(\"üîß Initializing Corrosion Detection System...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Initialize models\n",
    "    print(\"üì• Loading RF-DETR model...\")\n",
    "    rfdetr_model = RFDETR(num_classes=6, num_queries=100)\n",
    "    print(f\"‚úÖ RF-DETR initialized with {sum(p.numel() for p in rfdetr_model.parameters()):,} parameters\")\n",
    "    \n",
    "    # Initialize YOLO detector\n",
    "    print(\"üì• Loading YOLO detector...\")\n",
    "    yolo_detector = YOLOCorrosionDetector()\n",
    "    print(\"‚úÖ YOLOv11 detector initialized\")\n",
    "    \n",
    "    # Initialize SAM segmenter\n",
    "    print(\"üì• Loading SAM segmenter...\")\n",
    "    sam_segmenter = SAMCorrosionSegmenter()\n",
    "    if sam_segmenter.predictor:\n",
    "        print(\"‚úÖ SAM2 segmenter initialized\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è SAM2 segmenter not available (requires model weights)\")\n",
    "    \n",
    "    # Initialize complete pipeline\n",
    "    print(\"üîó Initializing complete pipeline...\")\n",
    "    pipeline = RealTimeCorrosionPipeline()\n",
    "    print(\"‚úÖ Real-time pipeline initialized\")\n",
    "    \n",
    "    # Initialize dashboard\n",
    "    print(\"üìä Initializing dashboard...\")\n",
    "    dashboard = CorrosionDashboard()\n",
    "    print(\"‚úÖ Dashboard initialized\")\n",
    "    \n",
    "    print(\"\\nüéâ System initialization complete!\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'rfdetr': rfdetr_model,\n",
    "        'yolo': yolo_detector,\n",
    "        'sam': sam_segmenter,\n",
    "        'pipeline': pipeline,\n",
    "        'dashboard': dashboard\n",
    "    }\n",
    "\n",
    "# Create demo test\n",
    "print(\"üöÄ Testing Corrosion Detection System\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize system\n",
    "system_components = initialize_system()\n",
    "\n",
    "# Create demo data\n",
    "print(\"\\nüìä Creating demo data...\")\n",
    "demo_images, demo_annotations = create_demo_data()\n",
    "print(f\"‚úÖ Created {len(demo_images)} demo images with annotations\")\n",
    "\n",
    "# Test with first demo image\n",
    "test_image = demo_images[0]\n",
    "print(f\"\\nüîç Testing with demo image (shape: {test_image.shape})\")\n",
    "\n",
    "# Process through pipeline\n",
    "results = system_components['pipeline'].process_frame(test_image)\n",
    "\n",
    "print(f\"\\nüìà Processing Results:\")\n",
    "print(f\"  ‚Ä¢ Detections found: {len(results['detections'])}\")\n",
    "print(f\"  ‚Ä¢ Processing time: {results['performance']['processing_time']:.3f}s\")\n",
    "print(f\"  ‚Ä¢ FPS: {results['performance']['fps']:.1f}\")\n",
    "print(f\"  ‚Ä¢ Coverage: {results['analysis']['coverage_percentage']:.1f}%\")\n",
    "print(f\"  ‚Ä¢ Risk level: {results['analysis']['risk_assessment']}\")\n",
    "\n",
    "# Visualize results\n",
    "if results['detections']:\n",
    "    print(f\"\\nüé® Detected corrosion types:\")\n",
    "    for detection in results['detections']:\n",
    "        print(f\"  ‚Ä¢ {detection['class_name']} (confidence: {detection['confidence']:.2f})\")\n",
    "    \n",
    "    # Show visualization\n",
    "    visualize_detections(test_image, results['detections'], \n",
    "                        \"Demo: Real-time Corrosion Detection\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No corrosion detected in demo image\")\n",
    "\n",
    "print(f\"\\nüí° System Status: Ready for deployment!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6355f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Example with Demo Data\n",
    "def train_rfdetr_demo():\n",
    "    \"\"\"Demonstrate RF-DETR training with synthetic data\"\"\"\n",
    "    \n",
    "    print(\"üéì RF-DETR Training Demonstration\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create larger demo dataset\n",
    "    print(\"üìä Generating training dataset...\")\n",
    "    demo_images, demo_annotations = create_demo_data()\n",
    "    \n",
    "    # Extend dataset for training demonstration\n",
    "    extended_images = []\n",
    "    extended_annotations = []\n",
    "    \n",
    "    for _ in range(50):  # Create 50 training samples\n",
    "        demo_imgs, demo_anns = create_demo_data()\n",
    "        extended_images.extend(demo_imgs)\n",
    "        extended_annotations.extend(demo_anns)\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(extended_images)} training samples\")\n",
    "    \n",
    "    # Split data\n",
    "    train_images = extended_images[:40]\n",
    "    train_annotations = extended_annotations[:40] \n",
    "    val_images = extended_images[40:]\n",
    "    val_annotations = extended_annotations[40:]\n",
    "    \n",
    "    print(f\"üìä Train samples: {len(train_images)}, Val samples: {len(val_images)}\")\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = CorrosionDataset(\n",
    "        image_paths=list(range(len(train_images))),  # Using indices as paths for demo\n",
    "        annotations=train_annotations,\n",
    "        transforms=get_train_transforms(),\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = CorrosionDataset(\n",
    "        image_paths=list(range(len(val_images))),\n",
    "        annotations=val_annotations,\n",
    "        transforms=get_val_transforms(),\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # Note: This is a simplified demo. In practice, you'd need proper DataLoaders\n",
    "    # that handle the actual image loading from paths\n",
    "    \n",
    "    print(\"‚úÖ Datasets created\")\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    print(\"ü§ñ Initializing RF-DETR model...\")\n",
    "    model = RFDETR(num_classes=6, num_queries=50)  # Smaller for demo\n",
    "    \n",
    "    # For demonstration purposes, we'll show the training setup\n",
    "    # without actually running the full training loop\n",
    "    \n",
    "    print(\"üéØ Training Configuration:\")\n",
    "    print(f\"  ‚Ä¢ Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"  ‚Ä¢ Training samples: {len(train_images)}\")\n",
    "    print(f\"  ‚Ä¢ Validation samples: {len(val_images)}\")\n",
    "    print(f\"  ‚Ä¢ Batch size: 4 (recommended)\")\n",
    "    print(f\"  ‚Ä¢ Learning rate: 1e-4\")\n",
    "    print(f\"  ‚Ä¢ Epochs: 100 (recommended)\")\n",
    "    \n",
    "    # Simulate training metrics\n",
    "    simulated_train_losses = np.linspace(2.5, 0.8, 20) + np.random.normal(0, 0.1, 20)\n",
    "    simulated_val_losses = np.linspace(2.3, 1.0, 20) + np.random.normal(0, 0.15, 20)\n",
    "    \n",
    "    print(\"\\nüìà Simulated training progress:\")\n",
    "    for epoch in range(0, 20, 5):\n",
    "        print(f\"  Epoch {epoch+1:2d}: Train Loss = {simulated_train_losses[epoch]:.3f}, \"\n",
    "              f\"Val Loss = {simulated_val_losses[epoch]:.3f}\")\n",
    "    \n",
    "    # Plot simulated training curves\n",
    "    plot_training_history(simulated_train_losses, simulated_val_losses)\n",
    "    \n",
    "    print(\"\\n‚úÖ Training demonstration completed!\")\n",
    "    print(\"üí° To run actual training, uncomment the training loop in the trainer class\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run training demo\n",
    "trained_model = train_rfdetr_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf115e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time Webcam Demo\n",
    "def run_webcam_demo():\n",
    "    \"\"\"Run real-time corrosion detection on webcam feed\"\"\"\n",
    "    \n",
    "    print(\"üìπ Starting Real-time Webcam Demo\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize system\n",
    "    pipeline = RealTimeCorrosionPipeline()\n",
    "    dashboard = CorrosionDashboard()\n",
    "    \n",
    "    # Try to open webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Could not open webcam. Using demo mode instead.\")\n",
    "        run_demo_mode(pipeline, dashboard)\n",
    "        return\n",
    "    \n",
    "    print(\"‚úÖ Webcam opened successfully\")\n",
    "    print(\"üéÆ Controls:\")\n",
    "    print(\"  ‚Ä¢ Press 'q' to quit\")\n",
    "    print(\"  ‚Ä¢ Press 's' to save screenshot\")\n",
    "    print(\"  ‚Ä¢ Press 'r' to reset statistics\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    screenshot_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Failed to read frame from webcam\")\n",
    "                break\n",
    "            \n",
    "            # Resize frame for processing\n",
    "            frame_resized = cv2.resize(frame, (640, 480))\n",
    "            \n",
    "            # Process frame\n",
    "            results = pipeline.process_frame(frame_resized)\n",
    "            \n",
    "            # Update dashboard\n",
    "            dashboard.update_performance_data(\n",
    "                results['performance']['fps'],\n",
    "                results['performance']['processing_time'],\n",
    "                len(results['detections'])\n",
    "            )\n",
    "            dashboard.update_corrosion_analysis(results['analysis'])\n",
    "            \n",
    "            # Draw results on frame\n",
    "            display_frame = results['annotated_frame'].copy()\n",
    "            \n",
    "            # Add performance info\n",
    "            fps_text = f\"FPS: {results['performance']['fps']:.1f}\"\n",
    "            cv2.putText(display_frame, fps_text, (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            process_time_text = f\"Process: {results['performance']['processing_time']*1000:.1f}ms\"\n",
    "            cv2.putText(display_frame, process_time_text, (10, 70), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            detections_text = f\"Detections: {len(results['detections'])}\"\n",
    "            cv2.putText(display_frame, detections_text, (10, 110), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            coverage_text = f\"Coverage: {results['analysis']['coverage_percentage']:.1f}%\"\n",
    "            cv2.putText(display_frame, coverage_text, (10, 150), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            risk_text = f\"Risk: {results['analysis']['risk_assessment'].upper()}\"\n",
    "            risk_color = {'low': (0, 255, 0), 'medium': (0, 255, 255), \n",
    "                         'high': (0, 165, 255), 'critical': (0, 0, 255)}.get(\n",
    "                         results['analysis']['risk_assessment'], (255, 255, 255))\n",
    "            cv2.putText(display_frame, risk_text, (10, 190), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, risk_color, 2)\n",
    "            \n",
    "            # Show frame\n",
    "            cv2.imshow('Real-time Corrosion Detection', display_frame)\n",
    "            \n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                screenshot_path = f'screenshot_{screenshot_count:03d}.jpg'\n",
    "                cv2.imwrite(screenshot_path, display_frame)\n",
    "                print(f\"üì∏ Screenshot saved: {screenshot_path}\")\n",
    "                screenshot_count += 1\n",
    "            elif key == ord('r'):\n",
    "                dashboard = CorrosionDashboard()\n",
    "                print(\"üîÑ Statistics reset\")\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Demo stopped by user\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Print final statistics\n",
    "        stats = dashboard.get_current_stats()\n",
    "        print(f\"\\nüìä Session Summary:\")\n",
    "        print(f\"  ‚Ä¢ Frames processed: {frame_count}\")\n",
    "        print(f\"  ‚Ä¢ Average FPS: {stats.get('current_fps', 0):.1f}\")\n",
    "        print(f\"  ‚Ä¢ Screenshots saved: {screenshot_count}\")\n",
    "        print(f\"  ‚Ä¢ Active alerts: {stats.get('active_alerts', 0)}\")\n",
    "\n",
    "def run_demo_mode(pipeline, dashboard):\n",
    "    \"\"\"Run demo mode with synthetic data\"\"\"\n",
    "    \n",
    "    print(\"üéÆ Running Demo Mode\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    demo_images, _ = create_demo_data()\n",
    "    \n",
    "    for i, demo_image in enumerate(demo_images):\n",
    "        print(f\"Processing demo image {i+1}/{len(demo_images)}\")\n",
    "        \n",
    "        # Process image\n",
    "        results = pipeline.process_frame(demo_image)\n",
    "        \n",
    "        # Update dashboard\n",
    "        dashboard.update_performance_data(\n",
    "            results['performance']['fps'],\n",
    "            results['performance']['processing_time'],\n",
    "            len(results['detections'])\n",
    "        )\n",
    "        dashboard.update_corrosion_analysis(results['analysis'])\n",
    "        \n",
    "        # Show results\n",
    "        if results['detections']:\n",
    "            print(f\"  ‚úÖ Found {len(results['detections'])} corrosion areas\")\n",
    "            for det in results['detections']:\n",
    "                print(f\"    ‚Ä¢ {det['class_name']} (conf: {det['confidence']:.2f})\")\n",
    "        else:\n",
    "            print(f\"  ‚ÑπÔ∏è No corrosion detected\")\n",
    "        \n",
    "        time.sleep(1)  # Simulate processing time\n",
    "    \n",
    "    print(\"‚úÖ Demo mode completed\")\n",
    "\n",
    "# Uncomment to run webcam demo\n",
    "# run_webcam_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb100a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit App Launcher\n",
    "def launch_streamlit_app():\n",
    "    \"\"\"Launch the Streamlit dashboard application\"\"\"\n",
    "    \n",
    "    # Create the Streamlit app file\n",
    "    app_code = '''\n",
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# Import our custom classes (assumes they're in the same environment)\n",
    "# from corrosion_detection import RealTimeCorrosionPipeline, CorrosionDashboard\n",
    "\n",
    "# Note: In a real deployment, you would import the actual classes\n",
    "# For demo purposes, we'll create simplified versions\n",
    "\n",
    "class SimplePipeline:\n",
    "    def process_frame(self, frame):\n",
    "        # Simulate processing\n",
    "        time.sleep(0.1)  # Simulate processing time\n",
    "        \n",
    "        # Generate fake detections for demo\n",
    "        detections = []\n",
    "        if np.random.random() > 0.5:\n",
    "            detections.append({\n",
    "                'class_name': np.random.choice(['pitting_corrosion', 'uniform_corrosion', 'stress_corrosion']),\n",
    "                'confidence': np.random.uniform(0.6, 0.95),\n",
    "                'bbox': [100, 100, 200, 200]\n",
    "            })\n",
    "        \n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        return {\n",
    "            'annotated_frame': annotated_frame,\n",
    "            'detections': detections,\n",
    "            'analysis': {\n",
    "                'total_corrosion_areas': len(detections),\n",
    "                'coverage_percentage': np.random.uniform(0, 15),\n",
    "                'risk_assessment': np.random.choice(['low', 'medium', 'high']),\n",
    "                'corrosion_types': {'pitting_corrosion': 1} if detections else {},\n",
    "                'recommendations': ['Monitor closely'] if detections else []\n",
    "            },\n",
    "            'performance': {\n",
    "                'fps': np.random.uniform(20, 30),\n",
    "                'processing_time': np.random.uniform(0.03, 0.08)\n",
    "            }\n",
    "        }\n",
    "\n",
    "class SimpleDashboard:\n",
    "    def __init__(self):\n",
    "        self.performance_data = []\n",
    "        self.corrosion_history = []\n",
    "        self.alerts = []\n",
    "    \n",
    "    def update_performance_data(self, fps, processing_time, detections_count):\n",
    "        timestamp = time.time()\n",
    "        self.performance_data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'fps': fps,\n",
    "            'processing_time': processing_time,\n",
    "            'detections_count': detections_count\n",
    "        })\n",
    "        if len(self.performance_data) > 50:\n",
    "            self.performance_data.pop(0)\n",
    "    \n",
    "    def update_corrosion_analysis(self, analysis):\n",
    "        timestamp = time.time()\n",
    "        self.corrosion_history.append({\n",
    "            'timestamp': timestamp,\n",
    "            'coverage_percentage': analysis['coverage_percentage'],\n",
    "            'risk_level': analysis['risk_assessment']\n",
    "        })\n",
    "        if len(self.corrosion_history) > 50:\n",
    "            self.corrosion_history.pop(0)\n",
    "    \n",
    "    def get_current_stats(self):\n",
    "        return {\n",
    "            'current_fps': self.performance_data[-1]['fps'] if self.performance_data else 0,\n",
    "            'current_coverage': self.corrosion_history[-1]['coverage_percentage'] if self.corrosion_history else 0,\n",
    "            'current_risk': self.corrosion_history[-1]['risk_level'] if self.corrosion_history else 'low',\n",
    "            'health_score': 75,\n",
    "            'active_alerts': 0\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"Corrosion Detection Dashboard\",\n",
    "        page_icon=\"üî¨\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "    \n",
    "    st.title(\"üî¨ Real-time Corrosion Detection System\")\n",
    "    st.markdown(\"### Advanced Computer Vision Pipeline for R&D Material Science Monitoring\")\n",
    "    \n",
    "    # Initialize session state\n",
    "    if 'pipeline' not in st.session_state:\n",
    "        st.session_state.pipeline = SimplePipeline()\n",
    "        st.session_state.dashboard = SimpleDashboard()\n",
    "        st.session_state.is_running = False\n",
    "    \n",
    "    # Sidebar\n",
    "    st.sidebar.header(\"‚öôÔ∏è System Configuration\")\n",
    "    \n",
    "    source_type = st.sidebar.selectbox(\n",
    "        \"Select Input Source\",\n",
    "        [\"Demo Mode\", \"Image Upload\"]\n",
    "    )\n",
    "    \n",
    "    if source_type == \"Image Upload\":\n",
    "        uploaded_file = st.sidebar.file_uploader(\"Upload Image\", type=['jpg', 'jpeg', 'png'])\n",
    "        \n",
    "    # Control buttons\n",
    "    col1, col2 = st.sidebar.columns(2)\n",
    "    with col1:\n",
    "        if st.button(\"‚ñ∂Ô∏è Start\"):\n",
    "            st.session_state.is_running = True\n",
    "    with col2:\n",
    "        if st.button(\"‚è∏Ô∏è Stop\"):\n",
    "            st.session_state.is_running = False\n",
    "    \n",
    "    # Main content\n",
    "    if st.session_state.is_running:\n",
    "        col1, col2 = st.columns([2, 1])\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"üìπ Live Analysis\")\n",
    "            \n",
    "            if source_type == \"Image Upload\" and 'uploaded_file' in locals() and uploaded_file:\n",
    "                image = Image.open(uploaded_file)\n",
    "                image_array = np.array(image)\n",
    "                \n",
    "                # Process image\n",
    "                results = st.session_state.pipeline.process_frame(image_array)\n",
    "                \n",
    "                # Update dashboard\n",
    "                st.session_state.dashboard.update_performance_data(\n",
    "                    results['performance']['fps'],\n",
    "                    results['performance']['processing_time'],\n",
    "                    len(results['detections'])\n",
    "                )\n",
    "                st.session_state.dashboard.update_corrosion_analysis(results['analysis'])\n",
    "                \n",
    "                # Display results\n",
    "                st.image(results['annotated_frame'], channels=\"RGB\")\n",
    "                \n",
    "                if results['detections']:\n",
    "                    st.success(f\"Found {len(results['detections'])} corrosion areas\")\n",
    "                    for det in results['detections']:\n",
    "                        st.write(f\"‚Ä¢ {det['class_name']} (confidence: {det['confidence']:.2f})\")\n",
    "                else:\n",
    "                    st.info(\"No corrosion detected\")\n",
    "            \n",
    "            else:  # Demo mode\n",
    "                demo_image = np.random.randint(0, 255, (400, 600, 3), dtype=np.uint8)\n",
    "                results = st.session_state.pipeline.process_frame(demo_image)\n",
    "                \n",
    "                st.session_state.dashboard.update_performance_data(\n",
    "                    results['performance']['fps'],\n",
    "                    results['performance']['processing_time'],\n",
    "                    len(results['detections'])\n",
    "                )\n",
    "                st.session_state.dashboard.update_corrosion_analysis(results['analysis'])\n",
    "                \n",
    "                st.image(demo_image, channels=\"RGB\", caption=\"Demo Mode - Synthetic Data\")\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"üìä System Status\")\n",
    "            \n",
    "            stats = st.session_state.dashboard.get_current_stats()\n",
    "            \n",
    "            # Metrics\n",
    "            col_a, col_b = st.columns(2)\n",
    "            with col_a:\n",
    "                st.metric(\"FPS\", f\"{stats['current_fps']:.1f}\")\n",
    "                st.metric(\"Coverage %\", f\"{stats['current_coverage']:.1f}%\")\n",
    "            with col_b:\n",
    "                st.metric(\"Health Score\", stats['health_score'])\n",
    "                st.metric(\"Risk Level\", stats['current_risk'].upper())\n",
    "        \n",
    "        # Performance charts\n",
    "        st.subheader(\"üìà Performance Dashboard\")\n",
    "        \n",
    "        if st.session_state.dashboard.performance_data:\n",
    "            # Create performance plot\n",
    "            df = pd.DataFrame(st.session_state.dashboard.performance_data)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x=df['timestamp'], y=df['fps'], name='FPS'))\n",
    "            fig.update_layout(title='Real-time FPS', xaxis_title='Time', yaxis_title='FPS')\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # Auto-refresh every 2 seconds in demo mode\n",
    "        if source_type == \"Demo Mode\":\n",
    "            time.sleep(2)\n",
    "            st.rerun()\n",
    "    \n",
    "    else:\n",
    "        st.info(\"üëÜ Click 'Start' to begin monitoring\")\n",
    "        \n",
    "        # Show features\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        with col1:\n",
    "            st.markdown(\"\"\"\n",
    "            ### üîß Detection Pipeline\n",
    "            - RF-DETR transformer model\n",
    "            - YOLOv11 real-time detection\n",
    "            - SAM2 precise segmentation\n",
    "            \"\"\")\n",
    "        with col2:\n",
    "            st.markdown(\"\"\"\n",
    "            ### üìä Analytics\n",
    "            - Real-time performance metrics\n",
    "            - Corrosion trend analysis\n",
    "            - Risk assessment scoring\n",
    "            \"\"\")\n",
    "        with col3:\n",
    "            st.markdown(\"\"\"\n",
    "            ### üß™ R&D Benefits\n",
    "            - Early detection capabilities\n",
    "            - Automated monitoring\n",
    "            - Data-driven insights\n",
    "            \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "    \n",
    "    # Save the app file\n",
    "    with open('streamlit_corrosion_app.py', 'w') as f:\n",
    "        f.write(app_code)\n",
    "    \n",
    "    print(\"üì± Streamlit app created: streamlit_corrosion_app.py\")\n",
    "    print(\"üöÄ To launch the dashboard, run:\")\n",
    "    print(\"   streamlit run streamlit_corrosion_app.py\")\n",
    "    print(\"\\nüåê The app will open in your web browser at http://localhost:8501\")\n",
    "\n",
    "# Create the Streamlit app\n",
    "launch_streamlit_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3423858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export and Deployment Functions\n",
    "def export_model_for_production(model, model_name=\"rfdetr_corrosion\"):\n",
    "    \"\"\"Export trained model for production deployment\"\"\"\n",
    "    \n",
    "    print(f\"üì¶ Exporting {model_name} for production...\")\n",
    "    \n",
    "    # Save PyTorch model\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "    print(f\"‚úÖ PyTorch model saved: {model_name}.pth\")\n",
    "    \n",
    "    # Export to ONNX for cross-platform deployment\n",
    "    try:\n",
    "        dummy_input = torch.randn(1, 3, 512, 512).to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            f\"{model_name}.onnx\",\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['class_logits', 'bbox_coords', 'severity_logits'],\n",
    "            dynamic_axes={\n",
    "                'input': {0: 'batch_size'},\n",
    "                'class_logits': {0: 'batch_size'},\n",
    "                'bbox_coords': {0: 'batch_size'},\n",
    "                'severity_logits': {0: 'batch_size'}\n",
    "            }\n",
    "        )\n",
    "        print(f\"‚úÖ ONNX model saved: {model_name}.onnx\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è ONNX export failed: {e}\")\n",
    "    \n",
    "    # Create model info file\n",
    "    model_info = {\n",
    "        'model_name': model_name,\n",
    "        'model_type': 'RF-DETR',\n",
    "        'num_classes': 6,\n",
    "        'input_size': [512, 512],\n",
    "        'classes': [\n",
    "            'uniform_corrosion', 'pitting_corrosion', 'crevice_corrosion',\n",
    "            'stress_corrosion', 'galvanic_corrosion', 'erosion_corrosion'\n",
    "        ],\n",
    "        'severity_levels': ['none', 'mild', 'moderate', 'severe', 'critical'],\n",
    "        'preprocessing': {\n",
    "            'normalize': True,\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225]\n",
    "        },\n",
    "        'postprocessing': {\n",
    "            'confidence_threshold': 0.5,\n",
    "            'nms_threshold': 0.4\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(f\"{model_name}_info.json\", 'w') as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Model info saved: {model_name}_info.json\")\n",
    "    print(f\"üì¶ Export completed for {model_name}\")\n",
    "\n",
    "def create_deployment_package():\n",
    "    \"\"\"Create deployment package with all necessary files\"\"\"\n",
    "    \n",
    "    print(\"üì¶ Creating deployment package...\")\n",
    "    \n",
    "    # Create requirements.txt\n",
    "    requirements = \"\"\"\n",
    "torch>=1.9.0\n",
    "torchvision>=0.10.0\n",
    "opencv-python>=4.5.0\n",
    "numpy>=1.21.0\n",
    "pillow>=8.3.0\n",
    "matplotlib>=3.4.0\n",
    "seaborn>=0.11.0\n",
    "pandas>=1.3.0\n",
    "scikit-learn>=1.0.0\n",
    "ultralytics>=8.0.0\n",
    "streamlit>=1.28.0\n",
    "plotly>=5.0.0\n",
    "supervision>=0.16.0\n",
    "albumentations>=1.3.0\n",
    "segment-anything>=1.0\n",
    "scipy>=1.7.0\n",
    "\"\"\".strip()\n",
    "    \n",
    "    with open('requirements.txt', 'w') as f:\n",
    "        f.write(requirements)\n",
    "    \n",
    "    # Create deployment script\n",
    "    deploy_script = '''\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Corrosion Detection System Deployment Script\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Setup the deployment environment\"\"\"\n",
    "    print(\"üîß Setting up deployment environment...\")\n",
    "    \n",
    "    # Install requirements\n",
    "    os.system(f\"{sys.executable} -m pip install -r requirements.txt\")\n",
    "    \n",
    "    print(\"‚úÖ Environment setup completed\")\n",
    "\n",
    "def deploy_models():\n",
    "    \"\"\"Deploy models for inference\"\"\"\n",
    "    print(\"üöÄ Deploying models...\")\n",
    "    \n",
    "    # Check for model files\n",
    "    required_files = [\n",
    "        'rfdetr_corrosion.pth',\n",
    "        'rfdetr_corrosion_info.json'\n",
    "    ]\n",
    "    \n",
    "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "    if missing_files:\n",
    "        print(f\"‚ùå Missing model files: {missing_files}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úÖ All model files found\")\n",
    "    return True\n",
    "\n",
    "def run_inference_server(port=8000):\n",
    "    \"\"\"Run inference server\"\"\"\n",
    "    print(f\"üåê Starting inference server on port {port}...\")\n",
    "    \n",
    "    # This would start your inference server\n",
    "    # For now, we'll just show the command\n",
    "    print(f\"üìù Run: python inference_server.py --port {port}\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Deploy Corrosion Detection System')\n",
    "    parser.add_argument('--setup', action='store_true', help='Setup environment')\n",
    "    parser.add_argument('--deploy', action='store_true', help='Deploy models')\n",
    "    parser.add_argument('--serve', action='store_true', help='Start inference server')\n",
    "    parser.add_argument('--port', type=int, default=8000, help='Server port')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.setup:\n",
    "        setup_environment()\n",
    "    \n",
    "    if args.deploy:\n",
    "        deploy_models()\n",
    "    \n",
    "    if args.serve:\n",
    "        run_inference_server(args.port)\n",
    "    \n",
    "    if not any([args.setup, args.deploy, args.serve]):\n",
    "        print(\"üî¨ Corrosion Detection System\")\n",
    "        print(\"Usage: python deploy.py [--setup] [--deploy] [--serve]\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''.strip()\n",
    "    \n",
    "    with open('deploy.py', 'w') as f:\n",
    "        f.write(deploy_script)\n",
    "    \n",
    "    # Create Docker configuration\n",
    "    dockerfile = '''\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    libglib2.0-0 \\\\\n",
    "    libsm6 \\\\\n",
    "    libxext6 \\\\\n",
    "    libxrender-dev \\\\\n",
    "    libgomp1 \\\\\n",
    "    libglib2.0-0 \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy requirements and install Python dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application files\n",
    "COPY . .\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 8501\n",
    "\n",
    "# Run Streamlit app\n",
    "CMD [\"streamlit\", \"run\", \"streamlit_corrosion_app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n",
    "'''.strip()\n",
    "    \n",
    "    with open('Dockerfile', 'w') as f:\n",
    "        f.write(dockerfile)\n",
    "    \n",
    "    # Create docker-compose.yml\n",
    "    docker_compose = '''\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  corrosion-detection:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    volumes:\n",
    "      - \"./models:/app/models\"\n",
    "      - \"./data:/app/data\"\n",
    "    environment:\n",
    "      - PYTHONUNBUFFERED=1\n",
    "    restart: unless-stopped\n",
    "\n",
    "  inference-api:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\" \n",
    "    volumes:\n",
    "      - \"./models:/app/models\"\n",
    "    command: [\"python\", \"inference_server.py\", \"--port\", \"8000\"]\n",
    "    restart: unless-stopped\n",
    "'''.strip()\n",
    "    \n",
    "    with open('docker-compose.yml', 'w') as f:\n",
    "        f.write(docker_compose)\n",
    "    \n",
    "    print(\"‚úÖ Requirements.txt created\")\n",
    "    print(\"‚úÖ Deployment script created: deploy.py\")\n",
    "    print(\"‚úÖ Dockerfile created\")\n",
    "    print(\"‚úÖ Docker Compose configuration created\")\n",
    "    print(\"\\nüöÄ Deployment package ready!\")\n",
    "    print(\"üìã Next steps:\")\n",
    "    print(\"  1. Train your models and export them\")\n",
    "    print(\"  2. Run: python deploy.py --setup\")\n",
    "    print(\"  3. Run: python deploy.py --deploy\")\n",
    "    print(\"  4. Run: docker-compose up (for containerized deployment)\")\n",
    "\n",
    "# Create deployment package\n",
    "create_deployment_package()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eab8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Benchmarking and Optimization\n",
    "class PerformanceBenchmark:\n",
    "    \"\"\"Benchmark system performance and optimization metrics\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.benchmark_results = {}\n",
    "    \n",
    "    def benchmark_inference_speed(self, test_images, num_runs=10):\n",
    "        \"\"\"Benchmark inference speed across different image sizes\"\"\"\n",
    "        \n",
    "        print(\"‚è±Ô∏è Benchmarking Inference Speed...\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        image_sizes = [(320, 240), (640, 480), (1024, 768), (1920, 1080)]\n",
    "        results = {}\n",
    "        \n",
    "        for size in image_sizes:\n",
    "            print(f\"Testing size {size[0]}x{size[1]}...\")\n",
    "            times = []\n",
    "            \n",
    "            for _ in range(num_runs):\n",
    "                # Create test image\n",
    "                test_image = cv2.resize(test_images[0], size)\n",
    "                \n",
    "                # Measure inference time\n",
    "                start_time = time.time()\n",
    "                _ = self.pipeline.process_frame(test_image)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                times.append(end_time - start_time)\n",
    "            \n",
    "            avg_time = np.mean(times)\n",
    "            std_time = np.std(times)\n",
    "            fps = 1.0 / avg_time\n",
    "            \n",
    "            results[f\"{size[0]}x{size[1]}\"] = {\n",
    "                'avg_time': avg_time,\n",
    "                'std_time': std_time,\n",
    "                'fps': fps,\n",
    "                'min_time': np.min(times),\n",
    "                'max_time': np.max(times)\n",
    "            }\n",
    "            \n",
    "            print(f\"  Average: {avg_time:.3f}s ¬± {std_time:.3f}s ({fps:.1f} FPS)\")\n",
    "        \n",
    "        self.benchmark_results['inference_speed'] = results\n",
    "        return results\n",
    "    \n",
    "    def benchmark_memory_usage(self, test_image):\n",
    "        \"\"\"Benchmark memory usage during inference\"\"\"\n",
    "        \n",
    "        import psutil\n",
    "        import gc\n",
    "        \n",
    "        print(\"üß† Benchmarking Memory Usage...\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Get initial memory\n",
    "        process = psutil.Process()\n",
    "        initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "        \n",
    "        # Run inference and measure peak memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        start_memory = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        # Process multiple frames to get peak usage\n",
    "        for _ in range(10):\n",
    "            _ = self.pipeline.process_frame(test_image)\n",
    "        \n",
    "        peak_memory = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        # GPU memory if available\n",
    "        gpu_memory = 0\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory = torch.cuda.max_memory_allocated() / 1024 / 1024  # MB\n",
    "        \n",
    "        memory_results = {\n",
    "            'initial_memory_mb': initial_memory,\n",
    "            'start_memory_mb': start_memory,\n",
    "            'peak_memory_mb': peak_memory,\n",
    "            'memory_increase_mb': peak_memory - start_memory,\n",
    "            'gpu_memory_mb': gpu_memory\n",
    "        }\n",
    "        \n",
    "        print(f\"Initial memory: {initial_memory:.1f} MB\")\n",
    "        print(f\"Peak memory: {peak_memory:.1f} MB\")\n",
    "        print(f\"Memory increase: {memory_results['memory_increase_mb']:.1f} MB\")\n",
    "        if gpu_memory > 0:\n",
    "            print(f\"GPU memory: {gpu_memory:.1f} MB\")\n",
    "        \n",
    "        self.benchmark_results['memory_usage'] = memory_results\n",
    "        return memory_results\n",
    "    \n",
    "    def benchmark_accuracy_vs_speed(self, test_dataset, confidence_thresholds):\n",
    "        \"\"\"Benchmark accuracy vs speed tradeoff\"\"\"\n",
    "        \n",
    "        print(\"üéØ Benchmarking Accuracy vs Speed...\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for threshold in confidence_thresholds:\n",
    "            print(f\"Testing confidence threshold: {threshold}\")\n",
    "            \n",
    "            # Update threshold\n",
    "            self.pipeline.yolo_detector.conf_threshold = threshold\n",
    "            \n",
    "            # Measure speed and accuracy\n",
    "            inference_times = []\n",
    "            detection_counts = []\n",
    "            \n",
    "            for test_image, _ in test_dataset[:10]:  # Test on subset\n",
    "                start_time = time.time()\n",
    "                result = self.pipeline.process_frame(test_image)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                inference_times.append(end_time - start_time)\n",
    "                detection_counts.append(len(result['detections']))\n",
    "            \n",
    "            avg_time = np.mean(inference_times)\n",
    "            avg_detections = np.mean(detection_counts)\n",
    "            fps = 1.0 / avg_time\n",
    "            \n",
    "            results[threshold] = {\n",
    "                'avg_inference_time': avg_time,\n",
    "                'fps': fps,\n",
    "                'avg_detections': avg_detections,\n",
    "                'total_detections': np.sum(detection_counts)\n",
    "            }\n",
    "            \n",
    "            print(f\"  FPS: {fps:.1f}, Avg detections: {avg_detections:.1f}\")\n",
    "        \n",
    "        self.benchmark_results['accuracy_vs_speed'] = results\n",
    "        return results\n",
    "    \n",
    "    def generate_benchmark_report(self):\n",
    "        \"\"\"Generate comprehensive benchmark report\"\"\"\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"PERFORMANCE BENCHMARK REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Inference Speed Report\n",
    "        if 'inference_speed' in self.benchmark_results:\n",
    "            print(\"\\\\nüìä INFERENCE SPEED ANALYSIS\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            for size, metrics in self.benchmark_results['inference_speed'].items():\n",
    "                print(f\"Resolution {size}:\")\n",
    "                print(f\"  ‚Ä¢ Average Time: {metrics['avg_time']:.3f}s\")\n",
    "                print(f\"  ‚Ä¢ FPS: {metrics['fps']:.1f}\")\n",
    "                print(f\"  ‚Ä¢ Time Range: {metrics['min_time']:.3f}s - {metrics['max_time']:.3f}s\")\n",
    "        \n",
    "        # Memory Usage Report\n",
    "        if 'memory_usage' in self.benchmark_results:\n",
    "            print(\"\\\\nüß† MEMORY USAGE ANALYSIS\")\n",
    "            print(\"-\" * 25)\n",
    "            \n",
    "            mem = self.benchmark_results['memory_usage']\n",
    "            print(f\"  ‚Ä¢ Initial Memory: {mem['initial_memory_mb']:.1f} MB\")\n",
    "            print(f\"  ‚Ä¢ Peak Memory: {mem['peak_memory_mb']:.1f} MB\")\n",
    "            print(f\"  ‚Ä¢ Memory Increase: {mem['memory_increase_mb']:.1f} MB\")\n",
    "            if mem['gpu_memory_mb'] > 0:\n",
    "                print(f\"  ‚Ä¢ GPU Memory: {mem['gpu_memory_mb']:.1f} MB\")\n",
    "        \n",
    "        # Accuracy vs Speed Report  \n",
    "        if 'accuracy_vs_speed' in self.benchmark_results:\n",
    "            print(\"\\\\n‚öñÔ∏è ACCURACY vs SPEED TRADEOFF\")\n",
    "            print(\"-\" * 32)\n",
    "            \n",
    "            for threshold, metrics in self.benchmark_results['accuracy_vs_speed'].items():\n",
    "                print(f\"Confidence {threshold}:\")\n",
    "                print(f\"  ‚Ä¢ FPS: {metrics['fps']:.1f}\")\n",
    "                print(f\"  ‚Ä¢ Avg Detections: {metrics['avg_detections']:.1f}\")\n",
    "        \n",
    "        # Optimization Recommendations\n",
    "        print(\"\\\\nüöÄ OPTIMIZATION RECOMMENDATIONS\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        if 'inference_speed' in self.benchmark_results:\n",
    "            fps_values = [m['fps'] for m in self.benchmark_results['inference_speed'].values()]\n",
    "            max_fps = max(fps_values)\n",
    "            \n",
    "            if max_fps < 15:\n",
    "                print(\"  ‚Ä¢ Consider using a smaller model variant (YOLOv11n)\")\n",
    "                print(\"  ‚Ä¢ Reduce input resolution for better performance\")\n",
    "                print(\"  ‚Ä¢ Implement model quantization\")\n",
    "            elif max_fps < 25:\n",
    "                print(\"  ‚Ä¢ Good performance, consider GPU acceleration if not used\")\n",
    "                print(\"  ‚Ä¢ Optimize preprocessing pipeline\")\n",
    "            else:\n",
    "                print(\"  ‚Ä¢ Excellent performance achieved!\")\n",
    "                print(\"  ‚Ä¢ Consider increasing model complexity for better accuracy\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "\n",
    "# Run performance benchmark\n",
    "def run_performance_benchmark():\n",
    "    \"\"\"Run comprehensive performance benchmark\"\"\"\n",
    "    \n",
    "    print(\"üèÉ Starting Performance Benchmark...\")\n",
    "    \n",
    "    # Initialize system\n",
    "    pipeline = RealTimeCorrosionPipeline()\n",
    "    benchmark = PerformanceBenchmark(pipeline)\n",
    "    \n",
    "    # Create test data\n",
    "    test_images, _ = create_demo_data()\n",
    "    \n",
    "    # Run benchmarks\n",
    "    benchmark.benchmark_inference_speed(test_images, num_runs=5)\n",
    "    benchmark.benchmark_memory_usage(test_images[0])\n",
    "    \n",
    "    # Test different confidence thresholds\n",
    "    confidence_thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "    benchmark.benchmark_accuracy_vs_speed(test_images, confidence_thresholds)\n",
    "    \n",
    "    # Generate report\n",
    "    benchmark.generate_benchmark_report()\n",
    "    \n",
    "    return benchmark\n",
    "\n",
    "# Uncomment to run benchmark\n",
    "# benchmark = run_performance_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5afa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Analytics and Reporting\n",
    "class CorrosionAnalytics:\n",
    "    \"\"\"Advanced analytics for corrosion monitoring and reporting\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.detection_history = []\n",
    "        self.material_database = {}\n",
    "        self.alert_history = []\n",
    "        \n",
    "    def add_detection_record(self, timestamp, detections, image_metadata=None):\n",
    "        \"\"\"Add detection record to history\"\"\"\n",
    "        record = {\n",
    "            'timestamp': timestamp,\n",
    "            'detections': detections,\n",
    "            'metadata': image_metadata or {},\n",
    "            'total_areas': len(detections),\n",
    "            'severity_scores': []\n",
    "        }\n",
    "        \n",
    "        # Calculate severity scores\n",
    "        for detection in detections:\n",
    "            severity_score = self.calculate_severity_score(detection)\n",
    "            record['severity_scores'].append(severity_score)\n",
    "        \n",
    "        self.detection_history.append(record)\n",
    "    \n",
    "    def calculate_severity_score(self, detection):\n",
    "        \"\"\"Calculate severity score based on corrosion type and characteristics\"\"\"\n",
    "        base_scores = {\n",
    "            'uniform_corrosion': 3,\n",
    "            'pitting_corrosion': 7,\n",
    "            'crevice_corrosion': 6,\n",
    "            'stress_corrosion': 9,\n",
    "            'galvanic_corrosion': 5,\n",
    "            'erosion_corrosion': 8\n",
    "        }\n",
    "        \n",
    "        base_score = base_scores.get(detection['class_name'], 5)\n",
    "        confidence_factor = detection['confidence']\n",
    "        \n",
    "        # Adjust based on detection area (if available)\n",
    "        area_factor = 1.0\n",
    "        if 'area' in detection:\n",
    "            # Larger areas are more severe\n",
    "            area_factor = min(1.5, 1.0 + detection['area'] / 10000)\n",
    "        \n",
    "        severity_score = base_score * confidence_factor * area_factor\n",
    "        return min(10, severity_score)  # Cap at 10\n",
    "    \n",
    "    def generate_trend_analysis(self, days=30):\n",
    "        \"\"\"Generate trend analysis for corrosion progression\"\"\"\n",
    "        \n",
    "        if not self.detection_history:\n",
    "            return None\n",
    "        \n",
    "        # Filter records by time period\n",
    "        cutoff_time = time.time() - (days * 24 * 3600)\n",
    "        recent_records = [r for r in self.detection_history if r['timestamp'] >= cutoff_time]\n",
    "        \n",
    "        if not recent_records:\n",
    "            return None\n",
    "        \n",
    "        # Calculate trends\n",
    "        timestamps = [r['timestamp'] for r in recent_records]\n",
    "        total_detections = [r['total_areas'] for r in recent_records]\n",
    "        avg_severity = [np.mean(r['severity_scores']) if r['severity_scores'] else 0 \n",
    "                       for r in recent_records]\n",
    "        \n",
    "        # Linear regression for trends\n",
    "        x = np.array(range(len(timestamps)))\n",
    "        \n",
    "        detection_trend = np.polyfit(x, total_detections, 1)[0] if len(x) > 1 else 0\n",
    "        severity_trend = np.polyfit(x, avg_severity, 1)[0] if len(x) > 1 else 0\n",
    "        \n",
    "        # Corrosion type distribution\n",
    "        type_counts = {}\n",
    "        for record in recent_records:\n",
    "            for detection in record['detections']:\n",
    "                ctype = detection['class_name']\n",
    "                type_counts[ctype] = type_counts.get(ctype, 0) + 1\n",
    "        \n",
    "        trend_analysis = {\n",
    "            'period_days': days,\n",
    "            'total_records': len(recent_records),\n",
    "            'detection_trend': detection_trend,  # per day\n",
    "            'severity_trend': severity_trend,    # per day\n",
    "            'avg_detections_per_day': len(total_detections) / days,\n",
    "            'current_avg_severity': np.mean(avg_severity[-7:]) if len(avg_severity) >= 7 else 0,\n",
    "            'type_distribution': type_counts,\n",
    "            'trend_direction': 'increasing' if detection_trend > 0.1 else 'decreasing' if detection_trend < -0.1 else 'stable'\n",
    "        }\n",
    "        \n",
    "        return trend_analysis\n",
    "    \n",
    "    def predict_maintenance_needs(self, trend_analysis):\n",
    "        \"\"\"Predict maintenance needs based on trend analysis\"\"\"\n",
    "        \n",
    "        if not trend_analysis:\n",
    "            return {'priority': 'low', 'recommendations': ['Continue monitoring']}\n",
    "        \n",
    "        predictions = {\n",
    "            'priority': 'low',\n",
    "            'urgency_score': 0,\n",
    "            'predicted_failure_days': None,\n",
    "            'recommendations': [],\n",
    "            'risk_factors': []\n",
    "        }\n",
    "        \n",
    "        urgency_score = 0\n",
    "        \n",
    "        # Analyze detection trends\n",
    "        if trend_analysis['detection_trend'] > 0.5:\n",
    "            urgency_score += 3\n",
    "            predictions['risk_factors'].append('Rapidly increasing corrosion rate')\n",
    "        elif trend_analysis['detection_trend'] > 0.1:\n",
    "            urgency_score += 1\n",
    "            predictions['risk_factors'].append('Gradual increase in corrosion')\n",
    "        \n",
    "        # Analyze severity trends\n",
    "        if trend_analysis['severity_trend'] > 0.2:\n",
    "            urgency_score += 2\n",
    "            predictions['risk_factors'].append('Increasing corrosion severity')\n",
    "        \n",
    "        # Analyze current severity\n",
    "        if trend_analysis['current_avg_severity'] > 8:\n",
    "            urgency_score += 3\n",
    "            predictions['risk_factors'].append('High current severity levels')\n",
    "        elif trend_analysis['current_avg_severity'] > 6:\n",
    "            urgency_score += 2\n",
    "            predictions['risk_factors'].append('Moderate current severity levels')\n",
    "        \n",
    "        # Check for critical corrosion types\n",
    "        critical_types = ['stress_corrosion', 'erosion_corrosion']\n",
    "        for ctype in critical_types:\n",
    "            if ctype in trend_analysis['type_distribution'] and trend_analysis['type_distribution'][ctype] > 2:\n",
    "                urgency_score += 2\n",
    "                predictions['risk_factors'].append(f'Multiple {ctype.replace(\"_\", \" \")} instances detected')\n",
    "        \n",
    "        # Determine priority and recommendations\n",
    "        if urgency_score >= 8:\n",
    "            predictions['priority'] = 'critical'\n",
    "            predictions['predicted_failure_days'] = 7\n",
    "            predictions['recommendations'] = [\n",
    "                'Immediate inspection and intervention required',\n",
    "                'Consider emergency maintenance procedures',\n",
    "                'Implement temporary protective measures'\n",
    "            ]\n",
    "        elif urgency_score >= 5:\n",
    "            predictions['priority'] = 'high'\n",
    "            predictions['predicted_failure_days'] = 30\n",
    "            predictions['recommendations'] = [\n",
    "                'Schedule maintenance within 1-2 weeks',\n",
    "                'Increase monitoring frequency',\n",
    "                'Prepare maintenance materials and resources'\n",
    "            ]\n",
    "        elif urgency_score >= 3:\n",
    "            predictions['priority'] = 'medium'\n",
    "            predictions['predicted_failure_days'] = 90\n",
    "            predictions['recommendations'] = [\n",
    "                'Schedule maintenance within 1-2 months',\n",
    "                'Continue regular monitoring',\n",
    "                'Consider preventive treatments'\n",
    "            ]\n",
    "        else:\n",
    "            predictions['priority'] = 'low'\n",
    "            predictions['recommendations'] = [\n",
    "                'Continue regular monitoring',\n",
    "                'Follow standard maintenance schedule',\n",
    "                'Document current condition for baseline'\n",
    "            ]\n",
    "        \n",
    "        predictions['urgency_score'] = urgency_score\n",
    "        return predictions\n",
    "    \n",
    "    def generate_comprehensive_report(self, material_id=None):\n",
    "        \"\"\"Generate comprehensive corrosion analysis report\"\"\"\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*80)\n",
    "        print(\"COMPREHENSIVE CORROSION ANALYSIS REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if material_id:\n",
    "            print(f\"Material ID: {material_id}\")\n",
    "        \n",
    "        print(f\"Report Generated: {pd.Timestamp.now()}\")\n",
    "        print(f\"Total Detection Records: {len(self.detection_history)}\")\n",
    "        \n",
    "        # Current Status\n",
    "        if self.detection_history:\n",
    "            latest_record = self.detection_history[-1]\n",
    "            print(f\"\\\\nüîç CURRENT STATUS\")\n",
    "            print(\"-\" * 20)\n",
    "            print(f\"Last Inspection: {pd.to_datetime(latest_record['timestamp'], unit='s')}\")\n",
    "            print(f\"Active Corrosion Areas: {latest_record['total_areas']}\")\n",
    "            if latest_record['severity_scores']:\n",
    "                avg_severity = np.mean(latest_record['severity_scores'])\n",
    "                max_severity = np.max(latest_record['severity_scores'])\n",
    "                print(f\"Average Severity: {avg_severity:.1f}/10\")\n",
    "                print(f\"Maximum Severity: {max_severity:.1f}/10\")\n",
    "        \n",
    "        # Trend Analysis\n",
    "        trend_30d = self.generate_trend_analysis(30)\n",
    "        if trend_30d:\n",
    "            print(f\"\\\\nüìà 30-DAY TREND ANALYSIS\")\n",
    "            print(\"-\" * 25)\n",
    "            print(f\"Trend Direction: {trend_30d['trend_direction'].upper()}\")\n",
    "            print(f\"Detection Rate Change: {trend_30d['detection_trend']:+.2f} areas/day\")\n",
    "            print(f\"Severity Trend: {trend_30d['severity_trend']:+.2f} points/day\")\n",
    "            \n",
    "            print(f\"\\\\nüß¨ CORROSION TYPE DISTRIBUTION\")\n",
    "            print(\"-\" * 30)\n",
    "            for ctype, count in sorted(trend_30d['type_distribution'].items(), \n",
    "                                     key=lambda x: x[1], reverse=True):\n",
    "                percentage = (count / sum(trend_30d['type_distribution'].values())) * 100\n",
    "                print(f\"  ‚Ä¢ {ctype.replace('_', ' ').title()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Maintenance Predictions\n",
    "        predictions = self.predict_maintenance_needs(trend_30d)\n",
    "        print(f\"\\\\nüîß MAINTENANCE PREDICTIONS\")\n",
    "        print(\"-\" * 25)\n",
    "        print(f\"Priority Level: {predictions['priority'].upper()}\")\n",
    "        print(f\"Urgency Score: {predictions['urgency_score']}/10\")\n",
    "        \n",
    "        if predictions['predicted_failure_days']:\n",
    "            print(f\"Predicted Action Needed Within: {predictions['predicted_failure_days']} days\")\n",
    "        \n",
    "        if predictions['risk_factors']:\n",
    "            print(f\"\\\\n‚ö†Ô∏è RISK FACTORS:\")\n",
    "            for factor in predictions['risk_factors']:\n",
    "                print(f\"  ‚Ä¢ {factor}\")\n",
    "        \n",
    "        print(f\"\\\\nüí° RECOMMENDATIONS:\")\n",
    "        for rec in predictions['recommendations']:\n",
    "            print(f\"  ‚Ä¢ {rec}\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*80)\n",
    "        \n",
    "        return {\n",
    "            'current_status': latest_record if self.detection_history else None,\n",
    "            'trend_analysis': trend_30d,\n",
    "            'predictions': predictions,\n",
    "            'report_timestamp': time.time()\n",
    "        }\n",
    "\n",
    "# Demo analytics usage\n",
    "def demo_analytics():\n",
    "    \"\"\"Demonstrate analytics capabilities\"\"\"\n",
    "    \n",
    "    print(\"üìä Demonstrating Advanced Analytics...\")\n",
    "    \n",
    "    analytics = CorrosionAnalytics()\n",
    "    \n",
    "    # Simulate detection history over 30 days\n",
    "    base_time = time.time() - (30 * 24 * 3600)\n",
    "    \n",
    "    for day in range(30):\n",
    "        for session in range(np.random.randint(1, 4)):  # 1-3 sessions per day\n",
    "            timestamp = base_time + day * 24 * 3600 + session * 8 * 3600\n",
    "            \n",
    "            # Generate random detections with increasing trend\n",
    "            num_detections = max(0, np.random.poisson(2 + day * 0.1))\n",
    "            detections = []\n",
    "            \n",
    "            for _ in range(num_detections):\n",
    "                detection = {\n",
    "                    'class_name': np.random.choice([\n",
    "                        'uniform_corrosion', 'pitting_corrosion', 'stress_corrosion'\n",
    "                    ]),\n",
    "                    'confidence': np.random.uniform(0.6, 0.95),\n",
    "                    'area': np.random.uniform(100, 1000)\n",
    "                }\n",
    "                detections.append(detection)\n",
    "            \n",
    "            analytics.add_detection_record(timestamp, detections)\n",
    "    \n",
    "    # Generate comprehensive report\n",
    "    report = analytics.generate_comprehensive_report(\"DEMO_MATERIAL_001\")\n",
    "    \n",
    "    return analytics, report\n",
    "\n",
    "# Run analytics demo\n",
    "analytics_demo, demo_report = demo_analytics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration with Laboratory Equipment\n",
    "class LabEquipmentInterface:\n",
    "    \"\"\"Interface for integrating with laboratory equipment and sensors\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.connected_devices = {}\n",
    "        self.sensor_readings = {}\n",
    "        self.calibration_data = {}\n",
    "    \n",
    "    def connect_microscope(self, microscope_id, connection_params):\n",
    "        \"\"\"Connect to digital microscope for high-resolution imaging\"\"\"\n",
    "        \n",
    "        print(f\"üî¨ Connecting to microscope {microscope_id}...\")\n",
    "        \n",
    "        # Simulate microscope connection\n",
    "        self.connected_devices[microscope_id] = {\n",
    "            'type': 'digital_microscope',\n",
    "            'status': 'connected',\n",
    "            'max_resolution': connection_params.get('resolution', '4K'),\n",
    "            'magnification_range': connection_params.get('magnification', '10x-1000x'),\n",
    "            'last_calibration': time.time()\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Microscope {microscope_id} connected successfully\")\n",
    "        return True\n",
    "    \n",
    "    def connect_environmental_sensors(self, sensor_ids):\n",
    "        \"\"\"Connect to environmental monitoring sensors\"\"\"\n",
    "        \n",
    "        for sensor_id in sensor_ids:\n",
    "            print(f\"üå°Ô∏è Connecting to environmental sensor {sensor_id}...\")\n",
    "            \n",
    "            self.connected_devices[sensor_id] = {\n",
    "                'type': 'environmental_sensor',\n",
    "                'status': 'connected',\n",
    "                'parameters': ['temperature', 'humidity', 'pH', 'conductivity'],\n",
    "                'last_reading': time.time()\n",
    "            }\n",
    "        \n",
    "        print(f\"‚úÖ Connected {len(sensor_ids)} environmental sensors\")\n",
    "    \n",
    "    def capture_high_res_image(self, microscope_id, magnification='100x'):\n",
    "        \"\"\"Capture high-resolution image from microscope\"\"\"\n",
    "        \n",
    "        if microscope_id not in self.connected_devices:\n",
    "            raise ValueError(f\"Microscope {microscope_id} not connected\")\n",
    "        \n",
    "        # Simulate high-resolution image capture\n",
    "        print(f\"üì∏ Capturing image at {magnification} magnification...\")\n",
    "        \n",
    "        # Generate synthetic high-res corrosion image\n",
    "        image_size = (2048, 2048) if magnification.endswith('x') and int(magnification[:-1]) > 50 else (1024, 1024)\n",
    "        image = np.random.randint(80, 120, (*image_size, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add realistic corrosion features\n",
    "        center_x, center_y = image_size[0] // 2, image_size[1] // 2\n",
    "        \n",
    "        # Add corrosion spot\n",
    "        corrosion_radius = np.random.randint(50, 200)\n",
    "        y, x = np.ogrid[:image_size[0], :image_size[1]]\n",
    "        mask = (x - center_x)**2 + (y - center_y)**2 <= corrosion_radius**2\n",
    "        \n",
    "        # Apply corrosion coloring\n",
    "        image[mask] = [139, 69, 19]  # Brown corrosion color\n",
    "        \n",
    "        # Add noise for realism\n",
    "        noise = np.random.normal(0, 10, image.shape).astype(np.int16)\n",
    "        image = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        metadata = {\n",
    "            'microscope_id': microscope_id,\n",
    "            'magnification': magnification,\n",
    "            'resolution': image_size,\n",
    "            'timestamp': time.time(),\n",
    "            'exposure_time': '1/60s',\n",
    "            'lighting': 'LED white light'\n",
    "        }\n",
    "        \n",
    "        return image, metadata\n",
    "    \n",
    "    def read_environmental_data(self):\n",
    "        \"\"\"Read data from all connected environmental sensors\"\"\"\n",
    "        \n",
    "        readings = {}\n",
    "        \n",
    "        for device_id, device_info in self.connected_devices.items():\n",
    "            if device_info['type'] == 'environmental_sensor':\n",
    "                \n",
    "                # Simulate sensor readings\n",
    "                reading = {\n",
    "                    'temperature': np.random.normal(23, 2),  # ¬∞C\n",
    "                    'humidity': np.random.normal(55, 10),    # %\n",
    "                    'pH': np.random.normal(7.2, 0.5),       # pH units\n",
    "                    'conductivity': np.random.normal(500, 50), # ŒºS/cm\n",
    "                    'timestamp': time.time()\n",
    "                }\n",
    "                \n",
    "                readings[device_id] = reading\n",
    "                self.sensor_readings[device_id] = reading\n",
    "        \n",
    "        return readings\n",
    "    \n",
    "    def correlate_corrosion_with_environment(self, corrosion_data, environmental_data):\n",
    "        \"\"\"Correlate corrosion detection with environmental conditions\"\"\"\n",
    "        \n",
    "        print(\"üîó Correlating corrosion with environmental conditions...\")\n",
    "        \n",
    "        correlations = {}\n",
    "        \n",
    "        if not environmental_data:\n",
    "            return correlations\n",
    "        \n",
    "        # Calculate average environmental conditions\n",
    "        avg_temp = np.mean([data['temperature'] for data in environmental_data.values()])\n",
    "        avg_humidity = np.mean([data['humidity'] for data in environmental_data.values()])\n",
    "        avg_ph = np.mean([data['pH'] for data in environmental_data.values()])\n",
    "        avg_conductivity = np.mean([data['conductivity'] for data in environmental_data.values()])\n",
    "        \n",
    "        # Determine risk factors based on environmental conditions\n",
    "        risk_factors = []\n",
    "        \n",
    "        if avg_temp > 30:\n",
    "            risk_factors.append('High temperature accelerates corrosion')\n",
    "        if avg_humidity > 70:\n",
    "            risk_factors.append('High humidity promotes corrosion')\n",
    "        if avg_ph < 6.5 or avg_ph > 8.5:\n",
    "            risk_factors.append('Non-neutral pH increases corrosion risk')\n",
    "        if avg_conductivity > 800:\n",
    "            risk_factors.append('High conductivity indicates corrosive environment')\n",
    "        \n",
    "        # Calculate corrosion severity based on environmental factors\n",
    "        severity_multiplier = 1.0\n",
    "        \n",
    "        if avg_temp > 25:\n",
    "            severity_multiplier *= 1 + (avg_temp - 25) * 0.02\n",
    "        if avg_humidity > 60:\n",
    "            severity_multiplier *= 1 + (avg_humidity - 60) * 0.01\n",
    "        if avg_ph < 7:\n",
    "            severity_multiplier *= 1 + (7 - avg_ph) * 0.1\n",
    "        elif avg_ph > 7.5:\n",
    "            severity_multiplier *= 1 + (avg_ph - 7.5) * 0.05\n",
    "        if avg_conductivity > 500:\n",
    "            severity_multiplier *= 1 + (avg_conductivity - 500) * 0.0005\n",
    "        \n",
    "        correlations = {\n",
    "            'environmental_conditions': {\n",
    "                'temperature': avg_temp,\n",
    "                'humidity': avg_humidity,\n",
    "                'pH': avg_ph,\n",
    "                'conductivity': avg_conductivity\n",
    "            },\n",
    "            'risk_factors': risk_factors,\n",
    "            'severity_multiplier': severity_multiplier,\n",
    "            'corrosion_acceleration_factor': severity_multiplier,\n",
    "            'recommendations': self._generate_environmental_recommendations(\n",
    "                avg_temp, avg_humidity, avg_ph, avg_conductivity\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        return correlations\n",
    "    \n",
    "    def _generate_environmental_recommendations(self, temp, humidity, ph, conductivity):\n",
    "        \"\"\"Generate recommendations based on environmental conditions\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        if temp > 30:\n",
    "            recommendations.append('Implement cooling system to reduce temperature')\n",
    "        if humidity > 70:\n",
    "            recommendations.append('Install dehumidification system')\n",
    "        if ph < 6.5:\n",
    "            recommendations.append('Apply alkaline treatment to neutralize acidity')\n",
    "        elif ph > 8.5:\n",
    "            recommendations.append('Apply acid treatment to reduce alkalinity')\n",
    "        if conductivity > 800:\n",
    "            recommendations.append('Reduce ionic concentration in environment')\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations.append('Environmental conditions are within acceptable range')\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Laboratory Data Management\n",
    "class LabDataManager:\n",
    "    \"\"\"Manage laboratory data, samples, and experimental records\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sample_database = {}\n",
    "        self.experiment_logs = []\n",
    "        self.analysis_history = {}\n",
    "    \n",
    "    def register_sample(self, sample_id, material_info, preparation_details):\n",
    "        \"\"\"Register a new sample for analysis\"\"\"\n",
    "        \n",
    "        sample_record = {\n",
    "            'sample_id': sample_id,\n",
    "            'registration_date': time.time(),\n",
    "            'material_type': material_info.get('type', 'unknown'),\n",
    "            'composition': material_info.get('composition', {}),\n",
    "            'dimensions': material_info.get('dimensions', {}),\n",
    "            'preparation': preparation_details,\n",
    "            'analysis_history': [],\n",
    "            'status': 'active'\n",
    "        }\n",
    "        \n",
    "        self.sample_database[sample_id] = sample_record\n",
    "        \n",
    "        print(f\"üìù Sample {sample_id} registered successfully\")\n",
    "        return sample_record\n",
    "    \n",
    "    def log_analysis_session(self, sample_id, analysis_results, equipment_used):\n",
    "        \"\"\"Log an analysis session for a sample\"\"\"\n",
    "        \n",
    "        if sample_id not in self.sample_database:\n",
    "            raise ValueError(f\"Sample {sample_id} not found in database\")\n",
    "        \n",
    "        session_log = {\n",
    "            'session_id': f\"{sample_id}_{int(time.time())}\",\n",
    "            'timestamp': time.time(),\n",
    "            'sample_id': sample_id,\n",
    "            'equipment_used': equipment_used,\n",
    "            'analysis_results': analysis_results,\n",
    "            'analyst': 'AI_System',\n",
    "            'session_duration': analysis_results.get('processing_time', 0)\n",
    "        }\n",
    "        \n",
    "        self.experiment_logs.append(session_log)\n",
    "        self.sample_database[sample_id]['analysis_history'].append(session_log['session_id'])\n",
    "        \n",
    "        print(f\"üìä Analysis session logged for sample {sample_id}\")\n",
    "        return session_log\n",
    "    \n",
    "    def export_lab_report(self, sample_id, format='PDF'):\n",
    "        \"\"\"Export comprehensive laboratory report\"\"\"\n",
    "        \n",
    "        if sample_id not in self.sample_database:\n",
    "            raise ValueError(f\"Sample {sample_id} not found\")\n",
    "        \n",
    "        sample = self.sample_database[sample_id]\n",
    "        \n",
    "        # Gather all analysis sessions for this sample\n",
    "        sample_sessions = [log for log in self.experiment_logs \n",
    "                          if log['sample_id'] == sample_id]\n",
    "        \n",
    "        report = {\n",
    "            'report_title': f'Corrosion Analysis Report - Sample {sample_id}',\n",
    "            'report_date': pd.Timestamp.now().isoformat(),\n",
    "            'sample_information': sample,\n",
    "            'analysis_sessions': sample_sessions,\n",
    "            'summary': self._generate_sample_summary(sample_sessions),\n",
    "            'format': format\n",
    "        }\n",
    "        \n",
    "        # Save report\n",
    "        import json\n",
    "        filename = f\"lab_report_{sample_id}_{int(time.time())}.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(report, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"üìã Lab report exported: {filename}\")\n",
    "        return report\n",
    "    \n",
    "    def _generate_sample_summary(self, sessions):\n",
    "        \"\"\"Generate summary statistics for sample analysis\"\"\"\n",
    "        \n",
    "        if not sessions:\n",
    "            return {'total_sessions': 0, 'analysis_summary': 'No analysis performed'}\n",
    "        \n",
    "        total_detections = []\n",
    "        severity_scores = []\n",
    "        \n",
    "        for session in sessions:\n",
    "            results = session['analysis_results']\n",
    "            if 'detections' in results:\n",
    "                total_detections.append(len(results['detections']))\n",
    "            if 'analysis' in results and 'coverage_percentage' in results['analysis']:\n",
    "                severity_scores.append(results['analysis']['coverage_percentage'])\n",
    "        \n",
    "        summary = {\n",
    "            'total_sessions': len(sessions),\n",
    "            'first_analysis': min(session['timestamp'] for session in sessions),\n",
    "            'last_analysis': max(session['timestamp'] for session in sessions),\n",
    "            'avg_detections_per_session': np.mean(total_detections) if total_detections else 0,\n",
    "            'max_coverage_observed': max(severity_scores) if severity_scores else 0,\n",
    "            'corrosion_progression': 'increasing' if len(severity_scores) > 1 and \n",
    "                                   severity_scores[-1] > severity_scores[0] else 'stable'\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Demo laboratory integration\n",
    "def demo_lab_integration():\n",
    "    \"\"\"Demonstrate laboratory equipment integration\"\"\"\n",
    "    \n",
    "    print(\"üß™ Demonstrating Laboratory Integration...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize lab interface and data manager\n",
    "    lab_interface = LabEquipmentInterface()\n",
    "    data_manager = LabDataManager()\n",
    "    \n",
    "    # Connect equipment\n",
    "    lab_interface.connect_microscope('MICROSCOPE_001', {\n",
    "        'resolution': '4K',\n",
    "        'magnification': '10x-1000x'\n",
    "    })\n",
    "    \n",
    "    lab_interface.connect_environmental_sensors([\n",
    "        'ENV_SENSOR_001', 'ENV_SENSOR_002'\n",
    "    ])\n",
    "    \n",
    "    # Register a sample\n",
    "    sample_info = {\n",
    "        'type': 'carbon_steel',\n",
    "        'composition': {'Fe': 0.98, 'C': 0.02},\n",
    "        'dimensions': {'length': 50, 'width': 25, 'thickness': 5}  # mm\n",
    "    }\n",
    "    \n",
    "    preparation_details = {\n",
    "        'surface_preparation': 'polished',\n",
    "        'exposure_conditions': 'salt spray 24h',\n",
    "        'preparation_date': time.time() - 86400  # 24h ago\n",
    "    }\n",
    "    \n",
    "    sample_record = data_manager.register_sample(\n",
    "        'SAMPLE_001', sample_info, preparation_details\n",
    "    )\n",
    "    \n",
    "    # Capture high-resolution image\n",
    "    image, metadata = lab_interface.capture_high_res_image('MICROSCOPE_001', '200x')\n",
    "    \n",
    "    # Read environmental data\n",
    "    env_data = lab_interface.read_environmental_data()\n",
    "    \n",
    "    # Process image through corrosion detection\n",
    "    pipeline = RealTimeCorrosionPipeline()\n",
    "    analysis_results = pipeline.process_frame(image)\n",
    "    \n",
    "    # Add metadata to results\n",
    "    analysis_results['image_metadata'] = metadata\n",
    "    analysis_results['environmental_data'] = env_data\n",
    "    \n",
    "    # Correlate with environmental conditions\n",
    "    correlation = lab_interface.correlate_corrosion_with_environment(\n",
    "        analysis_results, env_data\n",
    "    )\n",
    "    analysis_results['environmental_correlation'] = correlation\n",
    "    \n",
    "    # Log analysis session\n",
    "    session_log = data_manager.log_analysis_session(\n",
    "        'SAMPLE_001',\n",
    "        analysis_results,\n",
    "        ['MICROSCOPE_001', 'ENV_SENSOR_001', 'ENV_SENSOR_002']\n",
    "    )\n",
    "    \n",
    "    # Export lab report\n",
    "    report = data_manager.export_lab_report('SAMPLE_001')\n",
    "    \n",
    "    print(\"\\\\n‚úÖ Laboratory integration demo completed!\")\n",
    "    print(f\"üì∏ Captured image: {metadata['resolution']} at {metadata['magnification']}\")\n",
    "    print(f\"üå°Ô∏è Environmental readings: {len(env_data)} sensors\")\n",
    "    print(f\"üîç Detected {len(analysis_results['detections'])} corrosion areas\")\n",
    "    print(f\"üìã Lab report generated with {len(report['analysis_sessions'])} sessions\")\n",
    "    \n",
    "    return lab_interface, data_manager, report\n",
    "\n",
    "# Run laboratory integration demo\n",
    "lab_demo_results = demo_lab_integration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c597d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Service for Remote Access\n",
    "class CorrosionDetectionAPI:\n",
    "    \"\"\"REST API service for remote corrosion detection access\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline, analytics):\n",
    "        self.pipeline = pipeline\n",
    "        self.analytics = analytics\n",
    "        self.api_keys = {}\n",
    "        self.usage_logs = []\n",
    "    \n",
    "    def generate_api_key(self, user_id, permissions=['read']):\n",
    "        \"\"\"Generate API key for user access\"\"\"\n",
    "        import secrets\n",
    "        api_key = secrets.token_urlsafe(32)\n",
    "        \n",
    "        self.api_keys[api_key] = {\n",
    "            'user_id': user_id,\n",
    "            'permissions': permissions,\n",
    "            'created_at': time.time(),\n",
    "            'last_used': None,\n",
    "            'usage_count': 0\n",
    "        }\n",
    "        \n",
    "        return api_key\n",
    "    \n",
    "    def validate_api_key(self, api_key, required_permission='read'):\n",
    "        \"\"\"Validate API key and permissions\"\"\"\n",
    "        \n",
    "        if api_key not in self.api_keys:\n",
    "            return False, \"Invalid API key\"\n",
    "        \n",
    "        key_info = self.api_keys[api_key]\n",
    "        \n",
    "        if required_permission not in key_info['permissions']:\n",
    "            return False, f\"Permission '{required_permission}' not granted\"\n",
    "        \n",
    "        # Update usage\n",
    "        key_info['last_used'] = time.time()\n",
    "        key_info['usage_count'] += 1\n",
    "        \n",
    "        return True, \"Valid API key\"\n",
    "    \n",
    "    def process_image_endpoint(self, image_data, api_key, analysis_options=None):\n",
    "        \"\"\"API endpoint for image processing\"\"\"\n",
    "        \n",
    "        # Validate API key\n",
    "        valid, message = self.validate_api_key(api_key, 'read')\n",
    "        if not valid:\n",
    "            return {'error': message, 'status': 401}\n",
    "        \n",
    "        try:\n",
    "            # Decode image data (assuming base64 encoded)\n",
    "            import base64\n",
    "            from io import BytesIO\n",
    "            \n",
    "            if isinstance(image_data, str):\n",
    "                image_bytes = base64.b64decode(image_data)\n",
    "                image = cv2.imdecode(\n",
    "                    np.frombuffer(image_bytes, np.uint8), \n",
    "                    cv2.IMREAD_COLOR\n",
    "                )\n",
    "            else:\n",
    "                image = image_data\n",
    "            \n",
    "            # Process image\n",
    "            results = self.pipeline.process_frame(image)\n",
    "            \n",
    "            # Log API usage\n",
    "            self.usage_logs.append({\n",
    "                'timestamp': time.time(),\n",
    "                'api_key': api_key,\n",
    "                'endpoint': 'process_image',\n",
    "                'success': True,\n",
    "                'detections_found': len(results['detections'])\n",
    "            })\n",
    "            \n",
    "            # Prepare response\n",
    "            response = {\n",
    "                'status': 200,\n",
    "                'timestamp': time.time(),\n",
    "                'detections': results['detections'],\n",
    "                'analysis': results['analysis'],\n",
    "                'performance': results['performance']\n",
    "            }\n",
    "            \n",
    "            # Add additional analysis if requested\n",
    "            if analysis_options:\n",
    "                if analysis_options.get('include_trends', False):\n",
    "                    trends = self.analytics.generate_trend_analysis(7)  # 7-day trends\n",
    "                    response['trend_analysis'] = trends\n",
    "                \n",
    "                if analysis_options.get('include_predictions', False):\n",
    "                    trends = self.analytics.generate_trend_analysis(7)\n",
    "                    predictions = self.analytics.predict_maintenance_needs(trends)\n",
    "                    response['predictions'] = predictions\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log error\n",
    "            self.usage_logs.append({\n",
    "                'timestamp': time.time(),\n",
    "                'api_key': api_key,\n",
    "                'endpoint': 'process_image',\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            \n",
    "            return {'error': f'Processing failed: {str(e)}', 'status': 500}\n",
    "    \n",
    "    def get_system_status_endpoint(self, api_key):\n",
    "        \"\"\"API endpoint for system status\"\"\"\n",
    "        \n",
    "        valid, message = self.validate_api_key(api_key, 'read')\n",
    "        if not valid:\n",
    "            return {'error': message, 'status': 401}\n",
    "        \n",
    "        # System status information\n",
    "        status = {\n",
    "            'status': 200,\n",
    "            'timestamp': time.time(),\n",
    "            'system_status': 'operational',\n",
    "            'models_loaded': {\n",
    "                'yolo': self.pipeline.yolo_detector is not None,\n",
    "                'sam': self.pipeline.sam_segmenter.predictor is not None,\n",
    "                'rfdetr': self.pipeline.rfdetr is not None\n",
    "            },\n",
    "            'performance_stats': {\n",
    "                'avg_processing_time': np.mean(self.pipeline.processing_times[-10:]) if self.pipeline.processing_times else 0,\n",
    "                'current_fps': len(self.pipeline.processing_times) / (time.time() - self.pipeline.start_time) if self.pipeline.processing_times else 0\n",
    "            },\n",
    "            'api_usage': {\n",
    "                'total_requests': len(self.usage_logs),\n",
    "                'successful_requests': len([log for log in self.usage_logs if log['success']]),\n",
    "                'failed_requests': len([log for log in self.usage_logs if not log['success']])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return status\n",
    "    \n",
    "    def get_analytics_endpoint(self, api_key, time_range='7d'):\n",
    "        \"\"\"API endpoint for analytics data\"\"\"\n",
    "        \n",
    "        valid, message = self.validate_api_key(api_key, 'read')\n",
    "        if not valid:\n",
    "            return {'error': message, 'status': 401}\n",
    "        \n",
    "        # Parse time range\n",
    "        if time_range == '7d':\n",
    "            days = 7\n",
    "        elif time_range == '30d':\n",
    "            days = 30\n",
    "        elif time_range == '90d':\n",
    "            days = 90\n",
    "        else:\n",
    "            days = 7\n",
    "        \n",
    "        # Generate analytics\n",
    "        trend_analysis = self.analytics.generate_trend_analysis(days)\n",
    "        predictions = self.analytics.predict_maintenance_needs(trend_analysis)\n",
    "        \n",
    "        response = {\n",
    "            'status': 200,\n",
    "            'timestamp': time.time(),\n",
    "            'time_range': f'{days} days',\n",
    "            'trend_analysis': trend_analysis,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Create Flask Web Service\n",
    "def create_flask_service():\n",
    "    \"\"\"Create Flask web service for API deployment\"\"\"\n",
    "    \n",
    "    service_code = '''\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Import our detection system\n",
    "# from corrosion_detection import RealTimeCorrosionPipeline, CorrosionAnalytics, CorrosionDetectionAPI\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Initialize system (in production, load from saved models)\n",
    "# pipeline = RealTimeCorrosionPipeline()\n",
    "# analytics = CorrosionAnalytics()\n",
    "# api_service = CorrosionDetectionAPI(pipeline, analytics)\n",
    "\n",
    "# For demo purposes, create a simple mock API\n",
    "class MockAPI:\n",
    "    def __init__(self):\n",
    "        self.api_keys = {'demo_key_123': {'user_id': 'demo_user', 'permissions': ['read']}}\n",
    "    \n",
    "    def validate_api_key(self, api_key, permission='read'):\n",
    "        return api_key in self.api_keys, \"Valid\" if api_key in self.api_keys else \"Invalid\"\n",
    "    \n",
    "    def process_image_endpoint(self, image_data, api_key, analysis_options=None):\n",
    "        valid, msg = self.validate_api_key(api_key)\n",
    "        if not valid:\n",
    "            return {'error': 'Invalid API key', 'status': 401}\n",
    "        \n",
    "        return {\n",
    "            'status': 200,\n",
    "            'timestamp': time.time(),\n",
    "            'detections': [\n",
    "                {'class_name': 'pitting_corrosion', 'confidence': 0.85, 'bbox': [100, 100, 200, 200]}\n",
    "            ],\n",
    "            'analysis': {\n",
    "                'total_corrosion_areas': 1,\n",
    "                'coverage_percentage': 5.2,\n",
    "                'risk_assessment': 'medium'\n",
    "            },\n",
    "            'performance': {'fps': 25.3, 'processing_time': 0.039}\n",
    "        }\n",
    "\n",
    "api_service = MockAPI()\n",
    "\n",
    "@app.route('/api/v1/detect', methods=['POST'])\n",
    "def detect_corrosion():\n",
    "    \"\"\"Process image for corrosion detection\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Get API key from headers\n",
    "        api_key = request.headers.get('Authorization', '').replace('Bearer ', '')\n",
    "        if not api_key:\n",
    "            return jsonify({'error': 'API key required'}), 401\n",
    "        \n",
    "        # Get image data\n",
    "        data = request.get_json()\n",
    "        if 'image' not in data:\n",
    "            return jsonify({'error': 'Image data required'}), 400\n",
    "        \n",
    "        # Get analysis options\n",
    "        analysis_options = data.get('options', {})\n",
    "        \n",
    "        # Process image\n",
    "        result = api_service.process_image_endpoint(\n",
    "            data['image'], api_key, analysis_options\n",
    "        )\n",
    "        \n",
    "        return jsonify(result), result.get('status', 200)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/v1/status', methods=['GET'])\n",
    "def get_status():\n",
    "    \"\"\"Get system status\"\"\"\n",
    "    \n",
    "    api_key = request.headers.get('Authorization', '').replace('Bearer ', '')\n",
    "    if not api_key:\n",
    "        return jsonify({'error': 'API key required'}), 401\n",
    "    \n",
    "    # Mock status response\n",
    "    status = {\n",
    "        'status': 200,\n",
    "        'timestamp': time.time(),\n",
    "        'system_status': 'operational',\n",
    "        'models_loaded': {'yolo': True, 'sam': True, 'rfdetr': True},\n",
    "        'version': '1.0.0'\n",
    "    }\n",
    "    \n",
    "    return jsonify(status)\n",
    "\n",
    "@app.route('/api/v1/analytics', methods=['GET'])\n",
    "def get_analytics():\n",
    "    \"\"\"Get analytics data\"\"\"\n",
    "    \n",
    "    api_key = request.headers.get('Authorization', '').replace('Bearer ', '')\n",
    "    if not api_key:\n",
    "        return jsonify({'error': 'API key required'}), 401\n",
    "    \n",
    "    time_range = request.args.get('range', '7d')\n",
    "    \n",
    "    # Mock analytics response\n",
    "    analytics = {\n",
    "        'status': 200,\n",
    "        'timestamp': time.time(),\n",
    "        'time_range': time_range,\n",
    "        'trend_analysis': {\n",
    "            'detection_trend': 0.1,\n",
    "            'severity_trend': 0.05,\n",
    "            'trend_direction': 'stable'\n",
    "        },\n",
    "        'predictions': {\n",
    "            'priority': 'medium',\n",
    "            'recommendations': ['Continue monitoring', 'Schedule inspection']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return jsonify(analytics)\n",
    "\n",
    "@app.route('/api/v1/docs', methods=['GET'])\n",
    "def api_documentation():\n",
    "    \"\"\"API documentation\"\"\"\n",
    "    \n",
    "    docs = {\n",
    "        'title': 'Corrosion Detection API',\n",
    "        'version': '1.0.0',\n",
    "        'endpoints': {\n",
    "            'POST /api/v1/detect': {\n",
    "                'description': 'Process image for corrosion detection',\n",
    "                'headers': {'Authorization': 'Bearer YOUR_API_KEY'},\n",
    "                'body': {\n",
    "                    'image': 'base64 encoded image data',\n",
    "                    'options': {\n",
    "                        'include_trends': 'boolean',\n",
    "                        'include_predictions': 'boolean'\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'GET /api/v1/status': {\n",
    "                'description': 'Get system status',\n",
    "                'headers': {'Authorization': 'Bearer YOUR_API_KEY'}\n",
    "            },\n",
    "            'GET /api/v1/analytics?range=7d': {\n",
    "                'description': 'Get analytics data',\n",
    "                'headers': {'Authorization': 'Bearer YOUR_API_KEY'},\n",
    "                'parameters': {'range': '7d, 30d, or 90d'}\n",
    "            }\n",
    "        },\n",
    "        'authentication': {\n",
    "            'type': 'API Key',\n",
    "            'header': 'Authorization: Bearer YOUR_API_KEY',\n",
    "            'demo_key': 'demo_key_123'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return jsonify(docs)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    \"\"\"API home page\"\"\"\n",
    "    return jsonify({\n",
    "        'message': 'Corrosion Detection API',\n",
    "        'version': '1.0.0',\n",
    "        'documentation': '/api/v1/docs',\n",
    "        'status': 'operational'\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "'''.strip()\n",
    "    \n",
    "    # Save Flask service\n",
    "    with open('flask_api_service.py', 'w') as f:\n",
    "        f.write(service_code)\n",
    "    \n",
    "    print(\"üåê Flask API service created: flask_api_service.py\")\n",
    "    print(\"üöÄ To start the API server, run:\")\n",
    "    print(\"   python flask_api_service.py\")\n",
    "    print(\"üìñ API documentation will be available at: http://localhost:5000/api/v1/docs\")\n",
    "    print(\"üîë Demo API key: demo_key_123\")\n",
    "\n",
    "# Create the Flask service\n",
    "create_flask_service()\n",
    "\n",
    "# Demo API usage\n",
    "def demo_api_usage():\n",
    "    \"\"\"Demonstrate API usage with example requests\"\"\"\n",
    "    \n",
    "    print(\"\\\\nüì° API Usage Examples:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Example curl commands\n",
    "    examples = '''\n",
    "# 1. Get API documentation\n",
    "curl -X GET http://localhost:5000/api/v1/docs\n",
    "\n",
    "# 2. Check system status\n",
    "curl -X GET http://localhost:5000/api/v1/status \\\\\n",
    "  -H \"Authorization: Bearer demo_key_123\"\n",
    "\n",
    "# 3. Process image for corrosion detection\n",
    "curl -X POST http://localhost:5000/api/v1/detect \\\\\n",
    "  -H \"Authorization: Bearer demo_key_123\" \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{\n",
    "    \"image\": \"base64_encoded_image_data_here\",\n",
    "    \"options\": {\n",
    "      \"include_trends\": true,\n",
    "      \"include_predictions\": true\n",
    "    }\n",
    "  }'\n",
    "\n",
    "# 4. Get analytics data\n",
    "curl -X GET \"http://localhost:5000/api/v1/analytics?range=7d\" \\\\\n",
    "  -H \"Authorization: Bearer demo_key_123\"\n",
    "'''.strip()\n",
    "    \n",
    "    print(examples)\n",
    "    \n",
    "    # Python client example\n",
    "    python_client = '''\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# API configuration\n",
    "API_BASE_URL = \"http://localhost:5000/api/v1\"\n",
    "API_KEY = \"demo_key_123\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "\n",
    "# Example 1: Check system status\n",
    "response = requests.get(f\"{API_BASE_URL}/status\", headers=HEADERS)\n",
    "print(\"Status:\", response.json())\n",
    "\n",
    "# Example 2: Process image\n",
    "with open(\"image.jpg\", \"rb\") as f:\n",
    "    image_data = base64.b64encode(f.read()).decode()\n",
    "\n",
    "detection_request = {\n",
    "    \"image\": image_data,\n",
    "    \"options\": {\"include_trends\": True, \"include_predictions\": True}\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_BASE_URL}/detect\", \n",
    "    json=detection_request, \n",
    "    headers={**HEADERS, \"Content-Type\": \"application/json\"}\n",
    ")\n",
    "print(\"Detection results:\", response.json())\n",
    "\n",
    "# Example 3: Get analytics\n",
    "response = requests.get(f\"{API_BASE_URL}/analytics?range=30d\", headers=HEADERS)\n",
    "print(\"Analytics:\", response.json())\n",
    "'''.strip()\n",
    "    \n",
    "    print(\"\\\\nüêç Python Client Example:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(python_client)\n",
    "    \n",
    "    # Save Python client example\n",
    "    with open('api_client_example.py', 'w') as f:\n",
    "        f.write(python_client)\n",
    "    \n",
    "    print(\"\\\\nüíæ Python client example saved: api_client_example.py\")\n",
    "\n",
    "demo_api_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c76d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b2c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd1f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7925f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d609b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea70eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aabe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d2ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
