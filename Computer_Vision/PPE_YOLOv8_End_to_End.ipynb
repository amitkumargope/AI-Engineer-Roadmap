{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f97cab",
   "metadata": {},
   "source": [
    "# PPE Detection with YOLOv8 — End-to-End\n",
    "\n",
    "This notebook trains and tests a YOLOv8 model for PPE (Personal Protective Equipment) detection on a **local Windows dataset**, and includes **real‑time** testing (webcam / video).\n",
    "\n",
    "### What you need\n",
    "- A dataset in **YOLO format** (images + labels) at the path you gave:\n",
    "- `C:\\Users\\gopeami\\OneDrive - Vesuvius\\Desktop\\PhD13- 2025-2026\\ML Practice\\PPE-Detection\\YOLO_V8`\n",
    "  - Expected structure (adjust if yours differs):\n",
    "    ```text\n",
    "    YOLO_V8/\n",
    "      images/\n",
    "        train/ ... .jpg|.png\n",
    "        val/   ... .jpg|.png\n",
    "        # (optional) test/ ... .jpg|.png\n",
    "      labels/\n",
    "        train/ ... .txt   # YOLO labels\n",
    "        val/   ... .txt\n",
    "        # (optional) test/ ... .txt\n",
    "    ```\n",
    "\n",
    "> If your folders or class names are different, just edit the **Data YAML** cell in this notebook before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc324121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Install dependencies (run once)\n",
    "%pip -q install ultralytics opencv-python==4.* roboflow  # roboflow optional; handy utils\n",
    "\n",
    "import os, sys, shutil, textwrap, yaml, glob\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"Ultralytics version:\", YOLO.__version__ if hasattr(YOLO, \"__version__\") else \"OK\")\n",
    "print(\"Python:\", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7fc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define paths and create data.yaml\n",
    "\n",
    "# Use a raw string for Windows path to avoid issues with spaces and backslashes\n",
    "WINDOWS_DATASET_ROOT = r\"\"\"C:\\Users\\gopeami\\OneDrive - Vesuvius\\Desktop\\PhD13- 2025-2026\\ML Practice\\PPE-Detection\\YOLO_V8\"\"\"\n",
    "\n",
    "# We'll mirror that path as a string inside the YAML. YOLO accepts absolute Windows paths.\n",
    "images_train = str(Path(WINDOWS_DATASET_ROOT) / \"images\" / \"train\")\n",
    "images_val   = str(Path(WINDOWS_DATASET_ROOT) / \"images\" / \"val\")\n",
    "images_test  = str(Path(WINDOWS_DATASET_ROOT) / \"images\" / \"test\")  # optional\n",
    "\n",
    "# Make a temp working directory (local to the notebook runtime) where we put the YAML, runs, etc.\n",
    "WORKDIR = Path.cwd() / \"yolo_ppe_work\"\n",
    "WORKDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# === EDIT YOUR CLASS NAMES HERE IF NEEDED ===\n",
    "names = ['person', 'helmet', 'vest', 'gloves', 'boots', 'mask']\n",
    "\n",
    "data_yaml = {\n",
    "    \"path\": None,                      # not used when absolute paths provided\n",
    "    \"train\": images_train,\n",
    "    \"val\": images_val,\n",
    "    \"test\": images_test if Path(images_test).exists() else None,\n",
    "    \"names\": names\n",
    "}\n",
    "\n",
    "data_yaml_path = WORKDIR / \"ppe_data.yaml\"\n",
    "with open(data_yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(data_yaml, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"Wrote data YAML ->\", data_yaml_path)\n",
    "print(\"\\nYAML preview:\\n\", Path(data_yaml_path).read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3528c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Quick dataset sanity checks\n",
    "from pathlib import Path\n",
    "\n",
    "def count_files(folder, exts={\".jpg\",\".jpeg\",\".png\",\".bmp\"}):\n",
    "    p = Path(folder)\n",
    "    if not p.exists():\n",
    "        return 0\n",
    "    return sum(1 for x in p.rglob(\"*\") if x.suffix.lower() in exts)\n",
    "\n",
    "def count_labels(folder):\n",
    "    p = Path(folder)\n",
    "    if not p.exists():\n",
    "        return 0\n",
    "    return sum(1 for x in p.rglob(\"*.txt\"))\n",
    "\n",
    "print(\"Train images:\", count_files(Path(data_yaml[\"train\"])))\n",
    "print(\"Val images  :\", count_files(Path(data_yaml[\"val\"])))\n",
    "if data_yaml.get(\"test\"):\n",
    "    print(\"Test images :\", count_files(Path(data_yaml[\"test\"])))\n",
    "\n",
    "lbl_train = count_labels(Path(data_yaml[\"train\"]).with_name(\"labels\") / \"train\")\n",
    "lbl_val   = count_labels(Path(data_yaml[\"val\"]).with_name(\"labels\") / \"val\")\n",
    "print(\"Train labels:\", lbl_train)\n",
    "print(\"Val labels  :\", lbl_val)\n",
    "\n",
    "assert count_files(Path(data_yaml[\"train\"])) > 0, \"No training images found — check the path in data.yaml\"\n",
    "assert lbl_train > 0, \"No training labels found — check YOLO `labels/train` files\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Train YOLOv8 (choose model size: n, s, m, l, x)\n",
    "model = YOLO(f\"yolov8n.pt\")  # pre-trained COCO backbone\n",
    "\n",
    "results = model.train(\n",
    "    data=str(data_yaml_path),\n",
    "    epochs=50,            # adjust based on dataset size\n",
    "    imgsz=640,            # 640 is standard; increase for more accuracy / more VRAM\n",
    "    batch=16,             # tune for your GPU VRAM; on CPU keep smaller\n",
    "    device=0 if (not os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\")) else \"cpu\",  # try GPU if available\n",
    "    patience=20,          # early stopping\n",
    "    name=\"ppe_yolov8\",\n",
    "    project=str(WORKDIR / \"runs\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167038be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Validate / metrics\n",
    "metrics = model.val(data=str(data_yaml_path), imgsz=640)\n",
    "print(metrics.results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Predict on a few validation images and show results\n",
    "import random, shutil\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "val_images = list(Path(data_yaml[\"val\"]).rglob(\"*\"))\n",
    "sample_images = [str(p) for p in val_images if p.suffix.lower() in {\".jpg\",\".jpeg\",\".png\"}]\n",
    "random.shuffle(sample_images)\n",
    "sample_images = sample_images[:6]  # pick a few\n",
    "\n",
    "pred = model.predict(\n",
    "    source=sample_images,\n",
    "    imgsz=640,\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    project=str(WORKDIR / \"runs\"),\n",
    "    name=\"ppe_preds\",\n",
    ")\n",
    "\n",
    "# Display first few results inline\n",
    "pred_dir = Path(pred[0].save_dir)\n",
    "display_images = sorted([p for p in pred_dir.glob(\"*\") if p.suffix.lower() in {\".jpg\",\".png\",\".jpeg\"}])[:6]\n",
    "for p in display_images:\n",
    "    display(Image.open(p))\n",
    "print(\"Predictions saved in:\", pred_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Real‑time detection — Webcam (source=0)\n",
    "# NOTE: This opens a native OpenCV window; press 'q' to quit.\n",
    "# If running on a remote notebook without a camera, skip this cell.\n",
    "import cv2\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "def webcam_inference(model, source=0, conf=0.25):\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open video source (webcam).\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            results = model.predict(frame, imgsz=640, conf=conf, verbose=False)\n",
    "            res = results[0]\n",
    "            annotator = Annotator(frame, line_width=2)\n",
    "            if res.boxes is not None and len(res.boxes) > 0:\n",
    "                for box in res.boxes:\n",
    "                    b = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    cls_id = int(box.cls[0].item())\n",
    "                    confv = float(box.conf[0].item())\n",
    "                    label = f\"{model.names.get(cls_id, cls_id)} {confv:.2f}\"\n",
    "                    annotator.box_label(b, label, color=colors(cls_id, True))\n",
    "\n",
    "            cv2.imshow(\"YOLOv8 PPE — Webcam (press q to quit)\", annotator.result())\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Uncomment to run locally:\n",
    "# webcam_inference(model, source=0, conf=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ce352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Real‑time from video file or RTSP stream\n",
    "# Examples:\n",
    "#   video_path = r\"C:\\path\\to\\your\\ppe_video.mp4\"\n",
    "#   video_path = \"rtsp://user:pass@<ip>:<port>/stream\"\n",
    "# Uncomment and set your source below, then run.\n",
    "\n",
    "# video_path = r\"C:\\path\\to\\your\\ppe_video.mp4\"\n",
    "# webcam_inference(model, source=video_path, conf=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Export model (ONNX, TensorRT, etc.) — optional\n",
    "# See https://docs.ultralytics.com/modes/export/\n",
    "# Example: ONNX export\n",
    "# model.export(format=\"onnx\", opset=12, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e967f",
   "metadata": {},
   "source": [
    "### Tips & Gotchas\n",
    "- **Class order** in `names` **must match** your label IDs in the `.txt` files.\n",
    "- For spaces in Windows paths, use **raw strings** like `r\"C:\\Users\\...\\OneDrive - Vesuvius\\...\"`.\n",
    "- If your dataset folders differ, **edit** the `data_yaml` cell to point to the correct `images/*` and `labels/*` roots.\n",
    "- Start with `yolov8n.pt` for quick feedback; then try `yolov8s.pt` / `yolov8m.pt` for higher accuracy.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
